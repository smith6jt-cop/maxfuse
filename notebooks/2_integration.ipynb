{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration: MARIO and MaxFuse\n",
    "\n",
    "This notebook performs cross-modal integration using:\n",
    "1. MARIO - Matchability testing and bipartite matching\n",
    "2. MaxFuse - Graph-based fuzzy smoothed embedding\n",
    "\n",
    "**Prerequisites**: Run `preprocessing.ipynb` first\n",
    "\n",
    "**Outputs**: Matching results saved to `../results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_matching' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m os.makedirs(results_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Save matching results\u001b[39;00m\n\u001b[32m     11\u001b[39m matching_data = {\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrna_indices\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mfull_matching\u001b[49m[\u001b[32m0\u001b[39m],\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprotein_indices\u001b[39m\u001b[33m'\u001b[39m: full_matching[\u001b[32m1\u001b[39m],\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m'\u001b[39m: full_matching[\u001b[32m2\u001b[39m]\n\u001b[32m     15\u001b[39m }\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/maxfuse_matching.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m     pickle.dump(matching_data, f)\n",
      "\u001b[31mNameError\u001b[39m: name 'full_matching' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "from maxfuse import Fusor, Mario\n",
    "from maxfuse.mario import pipelined_mario\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plotting defaults\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 8]\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from 1_preprocessing.ipynb\n",
    "# Run 1_preprocessing.ipynb first to generate these files\n",
    "\n",
    "import os\n",
    "\n",
    "results_dir = 'results/1_preprocessing'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Results directory '{results_dir}' not found. \"\n",
    "        f\"Run 1_preprocessing.ipynb first to generate the input files.\"\n",
    "    )\n",
    "\n",
    "# Load processed AnnData objects\n",
    "protein_adata = sc.read_h5ad(f'{results_dir}/protein_adata.h5ad')\n",
    "rna_adata = sc.read_h5ad(f'{results_dir}/rna_adata.h5ad')\n",
    "rna_adata_lognorm = sc.read_h5ad(f'{results_dir}/rna_adata_lognorm.h5ad')\n",
    "\n",
    "print(f\"Loaded from {results_dir}/\")\n",
    "print(f\"  Protein data: {protein_adata.shape}\")\n",
    "print(f\"  RNA data: {rna_adata.shape}\")\n",
    "print(f\"  RNA log-normalized: {rna_adata_lognorm.shape}\")\n",
    "\n",
    "# Load preprocessing parameters\n",
    "with open(f'{results_dir}/preprocessing_params.json', 'r') as f:\n",
    "    preprocess_params = json.load(f)\n",
    "print(f\"\\nPreprocessing timestamp: {preprocess_params['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Protein-Gene Correspondence\n",
    "\n",
    "Map CODEX protein markers to their corresponding gene names in the RNA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correspondence table\n",
    "correspondence = pd.read_csv('data/protein_gene_conversion.csv', encoding='utf-8-sig')\n",
    "print(f\"Correspondence table: {correspondence.shape[0]} entries\")\n",
    "correspondence.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matching features between CODEX markers and RNA genes\n",
    "rna_protein_correspondence = []\n",
    "unmatched_proteins = []\n",
    "\n",
    "for marker in protein_adata.var_names:\n",
    "    # Skip DAPI and ECAD (not useful for cell type matching)\n",
    "    if marker in ['DAPI', 'ECAD']:\n",
    "        continue\n",
    "    \n",
    "    # Look up in correspondence table\n",
    "    matches = correspondence[correspondence['Protein name'].str.lower() == marker.lower()]\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        # Try alternative names\n",
    "        alt_names = {\n",
    "            'CD3e': 'CD3',\n",
    "            'FoxP3': 'FOXP3',\n",
    "            'HLADR': 'HLA-DR',\n",
    "            'Lyve1': 'LYVE1',\n",
    "            'SMActin': 'aSMA',\n",
    "            'CollagenIV': 'collagen IV',\n",
    "        }\n",
    "        alt_marker = alt_names.get(marker, marker)\n",
    "        matches = correspondence[correspondence['Protein name'].str.lower() == alt_marker.lower()]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        rna_names_str = matches.iloc[0]['RNA name']\n",
    "        if 'Ignore' in str(rna_names_str):\n",
    "            unmatched_proteins.append((marker, 'Ignored'))\n",
    "            continue\n",
    "        \n",
    "        # Try each RNA name option\n",
    "        found = False\n",
    "        for rna_name in str(rna_names_str).split('/'):\n",
    "            if rna_name in rna_adata.var_names:\n",
    "                rna_protein_correspondence.append([rna_name, marker])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            unmatched_proteins.append((marker, rna_names_str))\n",
    "    else:\n",
    "        unmatched_proteins.append((marker, 'Not in table'))\n",
    "\n",
    "rna_protein_correspondence = np.array(rna_protein_correspondence)\n",
    "print(f\"Found {len(rna_protein_correspondence)} protein-gene pairs\")\n",
    "\n",
    "if unmatched_proteins:\n",
    "    print(f\"\\nUnmatched proteins ({len(unmatched_proteins)}):\")\n",
    "    for prot, reason in unmatched_proteins:\n",
    "        print(f\"  {prot}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates (same RNA mapping to multiple proteins)\n",
    "# Keep first occurrence\n",
    "seen_rna = set()\n",
    "unique_pairs = []\n",
    "for rna, prot in rna_protein_correspondence:\n",
    "    if rna not in seen_rna:\n",
    "        seen_rna.add(rna)\n",
    "        unique_pairs.append([rna, prot])\n",
    "    else:\n",
    "        print(f\"Removing duplicate RNA mapping: {rna} -> {prot}\")\n",
    "\n",
    "rna_protein_correspondence = np.array(unique_pairs)\n",
    "print(f\"\\nFinal correspondence: {len(rna_protein_correspondence)} pairs\")\n",
    "\n",
    "print(\"\\nMatched features:\")\n",
    "for rna, prot in rna_protein_correspondence:\n",
    "    print(f\"  {rna:15} <-> {prot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Arrays for Integration\n",
    "\n",
    "Extract and normalize:\n",
    "- **Shared arrays**: Corresponding protein/gene features (used for initial matching)\n",
    "- **Active arrays**: All features (used for refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract shared features from FILTERED data\n",
    "rna_shared_adata = rna_adata[:, rna_protein_correspondence[:, 0]].copy()\n",
    "protein_shared_adata = protein_adata[:, rna_protein_correspondence[:, 1]].copy()\n",
    "\n",
    "print(f\"rna_shared_adata: {rna_shared_adata.shape}\")\n",
    "print(f\"protein_shared_adata: {protein_shared_adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize shared features - DETECTION-AWARE PIPELINE\n",
    "# \n",
    "# Key insight: RNA (~9K cells) and Protein (~170K cells) have different cell counts.\n",
    "# This causes the SAME biological \"zero\" to get different quantile values after\n",
    "# rank normalization because the proportion of zeros differs.\n",
    "#\n",
    "# Solution: Detection-aware normalization\n",
    "# 1. Transform each modality appropriately (log1p for RNA, arcsinh for protein)\n",
    "# 2. For each feature, normalize NON-ZERO values separately to [0, 1] range\n",
    "# 3. Set all zeros to a consistent negative value (e.g., -1 or the min of non-zeros)\n",
    "# 4. This ensures zeros are treated equivalently regardless of how many exist\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Store raw values before normalization\n",
    "rna_shared_raw = rna_shared_adata.X.copy()\n",
    "if sparse.issparse(rna_shared_raw):\n",
    "    rna_shared_raw = rna_shared_raw.toarray()\n",
    "protein_shared_raw = protein_shared_adata.X.copy()\n",
    "if sparse.issparse(protein_shared_raw):\n",
    "    protein_shared_raw = protein_shared_raw.toarray()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DETECTION-AWARE NORMALIZATION PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nCell counts: RNA = {rna_shared_raw.shape[0]:,}, Protein = {protein_shared_raw.shape[0]:,}\")\n",
    "print(\"\\nProblem: Different cell counts cause different zero proportions,\")\n",
    "print(\"         leading to misaligned distributions after standard normalization.\")\n",
    "print(\"\\nSolution: Normalize non-zero values separately, treat zeros consistently.\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: MODALITY-SPECIFIC TRANSFORMATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: Modality-specific transformations\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- RNA: Standard scanpy pipeline ---\n",
    "print(\"\\nRNA transformation:\")\n",
    "print(f\"  Raw - shape: {rna_shared_raw.shape}\")\n",
    "print(f\"       mean: {rna_shared_raw.mean():.3f}, zeros: {(rna_shared_raw == 0).mean()*100:.1f}%\")\n",
    "\n",
    "# Library size normalization\n",
    "sc.pp.normalize_total(rna_shared_adata, target_sum=1e4)\n",
    "rna_after_norm = rna_shared_adata.X.copy()\n",
    "if sparse.issparse(rna_after_norm):\n",
    "    rna_after_norm = rna_after_norm.toarray()\n",
    "\n",
    "# Log1p transformation\n",
    "sc.pp.log1p(rna_shared_adata)\n",
    "rna_after_log = rna_shared_adata.X.copy()\n",
    "if sparse.issparse(rna_after_log):\n",
    "    rna_after_log = rna_after_log.toarray()\n",
    "print(f\"  After normalize_total + log1p - mean: {rna_after_log.mean():.3f}\")\n",
    "\n",
    "# --- Protein: Arcsinh transformation (standard for cytometry) ---\n",
    "print(\"\\nProtein transformation (arcsinh with cofactor=5):\")\n",
    "print(f\"  Raw - shape: {protein_shared_raw.shape}\")\n",
    "print(f\"       mean: {protein_shared_raw.mean():.3f}, zeros: {(protein_shared_raw == 0).mean()*100:.1f}%\")\n",
    "\n",
    "COFACTOR = 5\n",
    "protein_after_arcsinh = np.arcsinh(protein_shared_raw / COFACTOR)\n",
    "print(f\"  After arcsinh(x/{COFACTOR}) - mean: {protein_after_arcsinh.mean():.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: DETECTION-AWARE NORMALIZATION (per feature)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Detection-aware normalization (per feature)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFor each feature:\")\n",
    "print(\"  1. Identify non-zero (detected) values\")\n",
    "print(\"  2. Rank-normalize only the non-zero values to (0, 1) range\")  \n",
    "print(\"  3. Map ranks to standard normal quantiles\")\n",
    "print(\"  4. Set zeros to a fixed negative value (below all non-zero values)\")\n",
    "print(\"\\nThis ensures 'not detected' means the same thing in both modalities.\")\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def detection_aware_normalize(X, zero_value=-2.0):\n",
    "    \"\"\"\n",
    "    Detection-aware normalization:\n",
    "    - Non-zero values are rank-normalized to standard normal\n",
    "    - Zero values are set to a consistent negative value\n",
    "    \n",
    "    This handles the case where modalities have different numbers of cells,\n",
    "    causing different proportions of zeros even for the same detection rate.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array (n_cells, n_features)\n",
    "    zero_value : float\n",
    "        Value to assign to zeros (should be below typical non-zero range)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_norm : normalized array\n",
    "    \"\"\"\n",
    "    X_norm = np.zeros_like(X, dtype=np.float64)\n",
    "    \n",
    "    for j in range(X.shape[1]):\n",
    "        col = X[:, j]\n",
    "        nonzero_mask = col > 0\n",
    "        n_nonzero = nonzero_mask.sum()\n",
    "        \n",
    "        if n_nonzero > 1:\n",
    "            # Rank only the non-zero values\n",
    "            nonzero_vals = col[nonzero_mask]\n",
    "            ranks = rankdata(nonzero_vals, method='average')\n",
    "            # Convert to quantiles (0, 1), avoiding extremes\n",
    "            quantiles = (ranks - 0.5) / n_nonzero\n",
    "            # Map to standard normal (will be positive since quantiles > 0.5 for higher ranks)\n",
    "            # Shift so median non-zero is at 0\n",
    "            normal_vals = norm.ppf(quantiles)\n",
    "            X_norm[nonzero_mask, j] = normal_vals\n",
    "        elif n_nonzero == 1:\n",
    "            # Single non-zero value: set to 0 (median)\n",
    "            X_norm[nonzero_mask, j] = 0.0\n",
    "        \n",
    "        # Set zeros to consistent negative value\n",
    "        X_norm[~nonzero_mask, j] = zero_value\n",
    "    \n",
    "    return X_norm\n",
    "\n",
    "# Apply detection-aware normalization\n",
    "ZERO_VALUE = -2.5  # Below typical non-zero range after normalization\n",
    "rna_shared_normalized = detection_aware_normalize(rna_after_log, zero_value=ZERO_VALUE)\n",
    "protein_shared_normalized = detection_aware_normalize(protein_after_arcsinh, zero_value=ZERO_VALUE)\n",
    "\n",
    "print(f\"\\nZero value set to: {ZERO_VALUE}\")\n",
    "\n",
    "# ============================================================\n",
    "# STORE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "# Store intermediate results for visualization\n",
    "rna_shared_after_log = rna_after_log\n",
    "protein_shared_after_arcsinh = protein_after_arcsinh\n",
    "\n",
    "# Final normalized arrays\n",
    "rna_shared_after_scale = rna_shared_normalized\n",
    "protein_shared_after = protein_shared_normalized\n",
    "\n",
    "# Store means/stds of non-zero values (for reference)\n",
    "rna_means = np.array([rna_after_log[rna_after_log[:, j] > 0, j].mean() if (rna_after_log[:, j] > 0).any() else 0 \n",
    "                      for j in range(rna_after_log.shape[1])])\n",
    "rna_stds = np.array([rna_after_log[rna_after_log[:, j] > 0, j].std() if (rna_after_log[:, j] > 0).any() else 1 \n",
    "                     for j in range(rna_after_log.shape[1])])\n",
    "prot_means = np.array([protein_after_arcsinh[protein_after_arcsinh[:, j] > 0, j].mean() if (protein_after_arcsinh[:, j] > 0).any() else 0 \n",
    "                       for j in range(protein_after_arcsinh.shape[1])])\n",
    "prot_stds = np.array([protein_after_arcsinh[protein_after_arcsinh[:, j] > 0, j].std() if (protein_after_arcsinh[:, j] > 0).any() else 1 \n",
    "                      for j in range(protein_after_arcsinh.shape[1])])\n",
    "\n",
    "# Update AnnData objects\n",
    "rna_shared_adata.X = rna_shared_normalized.astype(np.float32)\n",
    "protein_shared_adata.X = protein_shared_normalized.astype(np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFICATION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check non-zero distributions\n",
    "for name, data in [(\"RNA\", rna_shared_normalized), (\"Protein\", protein_shared_normalized)]:\n",
    "    nonzero_vals = data[data > ZERO_VALUE + 0.1]  # Exclude the zero-value spike\n",
    "    print(f\"\\n{name} (non-zero values only):\")\n",
    "    print(f\"  N values: {len(nonzero_vals):,}\")\n",
    "    print(f\"  Mean: {nonzero_vals.mean():.4f}\")\n",
    "    print(f\"  Std:  {nonzero_vals.std():.4f}\")\n",
    "    print(f\"  Range: [{nonzero_vals.min():.2f}, {nonzero_vals.max():.2f}]\")\n",
    "\n",
    "# Per-feature detection rates\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Per-feature detection rates:\")\n",
    "print(f\"{'Feature':<12} {'RNA %':>8} {'Prot %':>8} {'Difference':>12}\")\n",
    "print(\"-\"*42)\n",
    "for i, (rna_name, prot_name) in enumerate(rna_protein_correspondence):\n",
    "    rna_det = (rna_shared_raw[:, i] > 0).mean() * 100\n",
    "    prot_det = (protein_shared_raw[:, i] > 0).mean() * 100\n",
    "    print(f\"{rna_name[:11]:<12} {rna_det:>7.1f}% {prot_det:>7.1f}% {prot_det - rna_det:>+11.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUCCESS: Detection-aware normalization complete!\")\n",
    "print(\"- Non-zero values are rank-normalized (comparable distributions)\")\n",
    "print(\"- Zero values are set to consistent value (no cell-count bias)\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CODEX data for diagnostic cells (background detection analysis)\n",
    "# This requires the original TSV file from preprocessing\n",
    "\n",
    "import os\n",
    "codex_tsv_path = 'data/1904CC2B_cells.tsv'\n",
    "\n",
    "if os.path.exists(codex_tsv_path):\n",
    "    codex_df = pd.read_csv(codex_tsv_path, sep='\\t')\n",
    "    print(f\"Loaded raw CODEX data: {codex_df.shape}\")\n",
    "    print(f\"Columns: {len(codex_df.columns)}\")\n",
    "    CODEX_RAW_AVAILABLE = True\n",
    "else:\n",
    "    print(f\"Raw CODEX file not found at: {codex_tsv_path}\")\n",
    "    print(\"Skipping background detection diagnostic cells.\")\n",
    "    print(\"These cells are optional - the integration will work without them.\")\n",
    "    codex_df = None\n",
    "    CODEX_RAW_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Background detection using Cell Median\n",
    "# Skip if raw CODEX data not available\n",
    "\n",
    "if not CODEX_RAW_AVAILABLE:\n",
    "    print(\"Skipping: Raw CODEX data not available (run from preprocessing to analyze)\")\n",
    "else:\n",
    "    # Diagnostic: Background detection using Cell Median\n",
    "    # After histogram matching, background pixels cluster at 0\n",
    "    # If a cell's MEDIAN pixel value is 0, the cell is background (not detected)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PROTEIN BACKGROUND DETECTION (using Cell Median)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    protein_names = list(rna_protein_correspondence[:, 1])\n",
    "    n_features = len(protein_names)\n",
    "    \n",
    "    # We need the median values from the original CODEX dataframe\n",
    "    # Build mapping from protein name to column\n",
    "    protein_to_median_col = {}\n",
    "    for prot in protein_names:\n",
    "        # Find the matching column in codex_df\n",
    "        for col in codex_df.columns:\n",
    "            if prot in col and 'Cell:' in col and 'Median' in col:\n",
    "                protein_to_median_col[prot] = col\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nAnalyzing {n_features} shared protein features...\")\n",
    "    print(f\"Using Cell Median to classify background cells (Median=0 \u2192 not detected)\")\n",
    "    \n",
    "    # Store detection info\n",
    "    detection_stats = {}\n",
    "    \n",
    "    # Create figure: each protein gets a panel with Mean and Median histograms\n",
    "    plots_per_row = 4\n",
    "    n_feature_rows = int(np.ceil(n_features / plots_per_row))\n",
    "    fig, axes = plt.subplots(n_feature_rows, plots_per_row, figsize=(16, 3.5*n_feature_rows))\n",
    "    if n_feature_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(f\"\\n{'Protein':<12} {'Median=0':>12} {'Median>0':>12} {'% Detected':>12}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        prot_name = protein_names[i]\n",
    "        ax = axes[i]\n",
    "        \n",
    "        if prot_name in protein_to_median_col:\n",
    "            median_col = protein_to_median_col[prot_name]\n",
    "            median_vals = codex_df[median_col].values\n",
    "            \n",
    "            # Get corresponding mean column for comparison\n",
    "            mean_col = median_col.replace('Median', 'Mean')\n",
    "            mean_vals = codex_df[mean_col].values if mean_col in codex_df.columns else None\n",
    "            \n",
    "            # Classification: Median=0 is background\n",
    "            is_background = median_vals <= 0.5  # Using 0.5 to catch floating point 0s\n",
    "            is_detected = ~is_background\n",
    "            \n",
    "            n_background = is_background.sum()\n",
    "            n_detected = is_detected.sum()\n",
    "            pct_detected = 100 * n_detected / len(median_vals)\n",
    "            \n",
    "            detection_stats[prot_name] = {\n",
    "                'n_background': n_background,\n",
    "                'n_detected': n_detected,\n",
    "                'pct_detected': pct_detected\n",
    "            }\n",
    "            \n",
    "            print(f\"{prot_name:<12} {n_background:>12,} {n_detected:>12,} {pct_detected:>11.1f}%\")\n",
    "            \n",
    "            # Plot: Histogram of Median values zoomed to 0-20\n",
    "            median_zoomed = median_vals[median_vals <= 20]\n",
    "            ax.hist(median_zoomed, bins=np.arange(-0.5, 21.5, 1), alpha=0.7, \n",
    "                    color='darkorange', edgecolor='white', linewidth=0.5)\n",
    "            ax.axvline(x=0.5, color='green', linestyle='--', linewidth=2, label='threshold')\n",
    "            ax.set_title(f'{prot_name} ({pct_detected:.0f}% det)', fontsize=10)\n",
    "            ax.set_xlabel('Cell Median')\n",
    "            ax.set_xlim(left=-0.5, right=20)\n",
    "            ax.legend(fontsize=7)\n",
    "        else:\n",
    "            print(f\"{prot_name:<12} {'column not found':>36}\")\n",
    "            ax.set_visible(False)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for j in range(n_features, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Cell Median Distributions (cells with Median=0 are background)', fontsize=12, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBackground criterion: Cell Median \u2264 0.5\")\n",
    "    print(f\"\\nThis aligns with histogram matching: background pixels \u2192 0, signal pixels \u2192 higher values\")\n",
    "    print(f\"A cell with Median=0 has majority background pixels, even if Mean > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DETECTION-AWARE normalization\n",
    "# Skip if raw CODEX data not available\n",
    "\n",
    "if not CODEX_RAW_AVAILABLE:\n",
    "    print(\"Skipping: Raw CODEX data not available (run from preprocessing to analyze)\")\n",
    "else:\n",
    "    # Visualize DETECTION-AWARE normalization\n",
    "    # Updated to use Cell Median-based detection for protein data\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
    "    \n",
    "    feature_names = list(rna_protein_correspondence[:, 0])\n",
    "    protein_names = list(rna_protein_correspondence[:, 1])\n",
    "    n_features = rna_shared_raw.shape[1]\n",
    "    \n",
    "    # Define x_pos and width for bar charts\n",
    "    x_pos = np.arange(n_features)\n",
    "    width = 0.35\n",
    "    \n",
    "    # Pick a feature with moderate expression\n",
    "    detection_rates_rna = [(rna_shared_raw[:, i] > 0).mean() for i in range(n_features)]\n",
    "    good_features = [i for i, d in enumerate(detection_rates_rna) if 0.2 < d < 0.8]\n",
    "    if good_features:\n",
    "        best_feat_idx = good_features[len(good_features)//2]\n",
    "    else:\n",
    "        best_feat_idx = np.argmax(detection_rates_rna)\n",
    "    feat_name = feature_names[best_feat_idx]\n",
    "    prot_name = protein_names[best_feat_idx]\n",
    "    \n",
    "    # For protein, use Cell Median-based detection (from cell 26)\n",
    "    # Build protein detection rates from Cell Median\n",
    "    protein_to_median_col = {}\n",
    "    for prot in protein_names:\n",
    "        for col in codex_df.columns:\n",
    "            if prot in col and 'Cell:' in col and 'Median' in col:\n",
    "                protein_to_median_col[prot] = col\n",
    "                break\n",
    "    \n",
    "    # Calculate detection rates: RNA uses >0, Protein uses Cell Median > 0.5\n",
    "    rna_det_rates = [(rna_shared_raw[:, i] > 0).mean() * 100 for i in range(n_features)]\n",
    "    prot_det_rates = []\n",
    "    for i, pname in enumerate(protein_names):\n",
    "        if pname in protein_to_median_col:\n",
    "            median_vals = codex_df[protein_to_median_col[pname]].values\n",
    "            prot_det_rates.append((median_vals > 0.5).mean() * 100)\n",
    "        else:\n",
    "            # Fallback to raw >0\n",
    "            prot_det_rates.append((protein_shared_raw[:, i] > 0).mean() * 100)\n",
    "    \n",
    "    rna_det = rna_det_rates[best_feat_idx]\n",
    "    prot_det = prot_det_rates[best_feat_idx]\n",
    "    \n",
    "    print(f\"Example feature: {feat_name} / {prot_name}\")\n",
    "    print(f\"  RNA detection: {rna_det:.1f}% ({int(rna_det/100 * rna_shared_raw.shape[0]):,} cells)\")\n",
    "    print(f\"  Protein detection (Cell Median > 0): {prot_det:.1f}% ({int(prot_det/100 * protein_shared_raw.shape[0]):,} cells)\")\n",
    "    \n",
    "    ZERO_VALUE = -2.5  # Must match value used in normalization\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 1: RNA transformation pipeline\n",
    "    # ============================================================\n",
    "    ax = axes[0, 0]\n",
    "    raw_vals = rna_shared_raw[:, best_feat_idx]\n",
    "    ax.hist(raw_vals, bins=50, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "    ax.set_title(f'RNA: Raw Counts\\n(zeros: {(raw_vals==0).mean()*100:.0f}%)', fontsize=10)\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Cells')\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    log_vals = rna_shared_after_log[:, best_feat_idx]\n",
    "    zeros = log_vals == 0\n",
    "    nonzeros = ~zeros\n",
    "    ax.hist(log_vals[nonzeros], bins=30, alpha=0.7, color='coral', edgecolor='white', label=f'Non-zero ({nonzeros.sum():,})')\n",
    "    if zeros.sum() > 0:\n",
    "        ax.axvline(x=0, color='gray', linestyle='--', linewidth=2, label=f'Zeros ({zeros.sum():,})')\n",
    "    ax.set_title('RNA: After log1p\\n(zeros at 0)', fontsize=10)\n",
    "    ax.set_xlabel('log1p(count)')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[0, 2]\n",
    "    norm_vals = rna_shared_after_scale[:, best_feat_idx]\n",
    "    nonzero_mask = norm_vals > ZERO_VALUE + 0.1\n",
    "    ax.hist(norm_vals[nonzero_mask], bins=30, alpha=0.7, color='forestgreen', edgecolor='white', \n",
    "            label=f'Detected ({nonzero_mask.sum():,})')\n",
    "    ax.axvline(x=ZERO_VALUE, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Not detected ({(~nonzero_mask).sum():,})')\n",
    "    ax.set_title('RNA: Detection-Aware Normalized\\n(zeros \u2192 fixed value)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[0, 3]\n",
    "    ax.axis('off')\n",
    "    ax.text(0.1, 0.85, 'RNA Pipeline:', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.70, '1. normalize_total (library size)', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.58, '2. log1p (variance stabilization)', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.46, '3. Detection-aware normalization:', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.34, '\u2022 Non-zeros \u2192 rank \u2192 normal quantiles', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.22, f'\u2022 Zeros \u2192 fixed value ({ZERO_VALUE})', fontsize=9, transform=ax.transAxes)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 2: Protein transformation pipeline\n",
    "    # ============================================================\n",
    "    ax = axes[1, 0]\n",
    "    raw_vals = protein_shared_raw[:, best_feat_idx]\n",
    "    # Show Cell Median-based detection\n",
    "    if prot_name in protein_to_median_col:\n",
    "        median_vals = codex_df[protein_to_median_col[prot_name]].values\n",
    "        is_bg = median_vals <= 0.5\n",
    "        pct_bg = is_bg.mean() * 100\n",
    "    else:\n",
    "        pct_bg = (raw_vals == 0).mean() * 100\n",
    "    ax.hist(raw_vals, bins=50, alpha=0.7, color='darkorange', edgecolor='white')\n",
    "    ax.set_title(f'Protein: Raw MFI\\n(background: {pct_bg:.0f}% via Cell Median)', fontsize=10)\n",
    "    ax.set_xlabel('Mean Fluorescence Intensity')\n",
    "    ax.set_ylabel('Cells')\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    arcsinh_vals = protein_shared_after_arcsinh[:, best_feat_idx]\n",
    "    # Use Cell Median for zero classification\n",
    "    if prot_name in protein_to_median_col:\n",
    "        median_vals = codex_df[protein_to_median_col[prot_name]].values\n",
    "        zeros = median_vals <= 0.5\n",
    "    else:\n",
    "        zeros = protein_shared_raw[:, best_feat_idx] == 0\n",
    "    nonzeros = ~zeros\n",
    "    ax.hist(arcsinh_vals[nonzeros], bins=30, alpha=0.7, color='purple', edgecolor='white', label=f'Detected ({nonzeros.sum():,})')\n",
    "    if zeros.sum() > 0:\n",
    "        # Show background cells as a separate histogram\n",
    "        ax.hist(arcsinh_vals[zeros], bins=30, alpha=0.5, color='gray', edgecolor='white', label=f'Background ({zeros.sum():,})')\n",
    "    ax.set_title('Protein: After arcsinh(x/5)\\n(Cell Median-based detection)', fontsize=10)\n",
    "    ax.set_xlabel('arcsinh(MFI/5)')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[1, 2]\n",
    "    norm_vals = protein_shared_after[:, best_feat_idx]\n",
    "    nonzero_mask = norm_vals > ZERO_VALUE + 0.1\n",
    "    ax.hist(norm_vals[nonzero_mask], bins=30, alpha=0.7, color='forestgreen', edgecolor='white',\n",
    "            label=f'Detected ({nonzero_mask.sum():,})')\n",
    "    ax.axvline(x=ZERO_VALUE, color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Not detected ({(~nonzero_mask).sum():,})')\n",
    "    ax.set_title('Protein: Detection-Aware Normalized\\n(background \u2192 fixed value)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[1, 3]\n",
    "    ax.axis('off')\n",
    "    ax.text(0.1, 0.85, 'Protein Pipeline:', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.70, '1. arcsinh(x/5) (standard for cytometry)', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.58, '\u2022 Linear near zero, log-like at high', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.46, '2. Detection via Cell Median:', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.34, '\u2022 Median > 0 \u2192 detected', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.22, '\u2022 Median = 0 \u2192 background', fontsize=9, transform=ax.transAxes)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 3: Distribution comparison - NON-ZERO VALUES ONLY\n",
    "    # ============================================================\n",
    "    \n",
    "    # Get non-zero values only\n",
    "    rna_nonzero = rna_shared_after_scale[rna_shared_after_scale > ZERO_VALUE + 0.1]\n",
    "    prot_nonzero = protein_shared_after[protein_shared_after > ZERO_VALUE + 0.1]\n",
    "    \n",
    "    ax = axes[2, 0]\n",
    "    bins = np.linspace(-3, 3, 50)\n",
    "    ax.hist(rna_nonzero, bins=bins, alpha=0.6, density=True, label=f'RNA ({len(rna_nonzero):,})', color='steelblue')\n",
    "    ax.hist(prot_nonzero, bins=bins, alpha=0.6, density=True, label=f'Protein ({len(prot_nonzero):,})', color='darkorange')\n",
    "    ax.set_title('Non-Zero Values Only\\n(should overlap well)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    # Box plot of non-zero values\n",
    "    ax = axes[2, 1]\n",
    "    rna_sample = rna_nonzero[::max(1, len(rna_nonzero)//5000)]\n",
    "    prot_sample = prot_nonzero[::max(1, len(prot_nonzero)//5000)]\n",
    "    bp = ax.boxplot([rna_sample, prot_sample], labels=['RNA', 'Protein'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('steelblue')\n",
    "    bp['boxes'][1].set_facecolor('darkorange')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylabel('Normalized value (non-zero only)')\n",
    "    ax.set_title('Overall Distribution (Non-Zero Values)', fontsize=10)\n",
    "    \n",
    "    # Per-feature mean of NON-ZERO values (should be ~0)\n",
    "    ax = axes[2, 2]\n",
    "    rna_means_nz = []\n",
    "    prot_means_nz = []\n",
    "    for i in range(n_features):\n",
    "        rna_nz = rna_shared_after_scale[:, i][rna_shared_after_scale[:, i] > ZERO_VALUE + 0.1]\n",
    "        prot_nz = protein_shared_after[:, i][protein_shared_after[:, i] > ZERO_VALUE + 0.1]\n",
    "        rna_means_nz.append(rna_nz.mean() if len(rna_nz) > 0 else 0)\n",
    "        prot_means_nz.append(prot_nz.mean() if len(prot_nz) > 0 else 0)\n",
    "    \n",
    "    ax.bar(x_pos - width/2, rna_means_nz, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_means_nz, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Mean (non-zero only)')\n",
    "    ax.set_title('Per-Feature Mean (Non-Zero Values)', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    \n",
    "    # Per-feature std of NON-ZERO values (should be ~1)\n",
    "    ax = axes[2, 3]\n",
    "    rna_stds_nz = []\n",
    "    prot_stds_nz = []\n",
    "    for i in range(n_features):\n",
    "        rna_nz = rna_shared_after_scale[:, i][rna_shared_after_scale[:, i] > ZERO_VALUE + 0.1]\n",
    "        prot_nz = protein_shared_after[:, i][protein_shared_after[:, i] > ZERO_VALUE + 0.1]\n",
    "        rna_stds_nz.append(rna_nz.std() if len(rna_nz) > 1 else 0)\n",
    "        prot_stds_nz.append(prot_nz.std() if len(prot_nz) > 1 else 0)\n",
    "    \n",
    "    ax.bar(x_pos - width/2, rna_stds_nz, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_stds_nz, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.axhline(y=1, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Std Dev (non-zero only)')\n",
    "    ax.set_title('Per-Feature Std Dev (Non-Zero Values)', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 4: Detection rates and summary\n",
    "    # ============================================================\n",
    "    \n",
    "    # Detection rate comparison\n",
    "    ax = axes[3, 0]\n",
    "    ax.bar(x_pos - width/2, rna_det_rates, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_det_rates, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Detection rate (%)')\n",
    "    ax.set_title('Per-Feature Detection Rate', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f[:6] for f in feature_names], rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    # Detection rate scatter\n",
    "    ax = axes[3, 1]\n",
    "    ax.scatter(rna_det_rates, prot_det_rates, s=50, alpha=0.7)\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        ax.annotate(fname[:6], (rna_det_rates[i], prot_det_rates[i]), fontsize=7)\n",
    "    ax.plot([0, 100], [0, 100], 'r--', alpha=0.5)\n",
    "    ax.set_xlabel('RNA detection rate (%)')\n",
    "    ax.set_ylabel('Protein detection rate (%)')\n",
    "    ax.set_title('Detection Rate Comparison', fontsize=10)\n",
    "    \n",
    "    # Empty placeholder\n",
    "    ax = axes[3, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Summary text\n",
    "    ax = axes[3, 3]\n",
    "    ax.axis('off')\n",
    "    summary = f\"\"\"DETECTION-AWARE NORMALIZATION SUMMARY\n",
    "    {\"=\"*45}\n",
    "    \n",
    "    Cell counts:\n",
    "      RNA:     {rna_shared_raw.shape[0]:>10,} cells\n",
    "      Protein: {protein_shared_raw.shape[0]:>10,} cells\n",
    "    \n",
    "    Detection method:\n",
    "      RNA: count > 0\n",
    "      Protein: Cell Median > 0 (histogram matching)\n",
    "    \n",
    "    Non-zero values after normalization:\n",
    "      RNA:     mean={np.mean(rna_means_nz):.3f}, std={np.mean(rna_stds_nz):.3f}\n",
    "      Protein: mean={np.mean(prot_means_nz):.3f}, std={np.mean(prot_stds_nz):.3f}\n",
    "    \n",
    "    Zero handling:\n",
    "      All \"not detected\" set to: {ZERO_VALUE}\n",
    "      (Below all detected values)\n",
    "    \"\"\"\n",
    "    ax.text(0.0, 0.95, summary, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Detection-Aware Normalization Results', fontsize=14, y=1.01)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KEY INSIGHT:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"RNA detection: count > 0\")\n",
    "    print(\"Protein detection: Cell Median > 0 (accounts for histogram matching)\")\n",
    "    print(\"This ensures 'not detected' is biologically meaningful in both modalities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "rna_shared = rna_shared_adata.X.copy()\n",
    "if sparse.issparse(rna_shared):\n",
    "    rna_shared = rna_shared.toarray()\n",
    "    \n",
    "protein_shared = protein_shared_adata.X.copy()\n",
    "if sparse.issparse(protein_shared):\n",
    "    protein_shared = protein_shared.toarray()\n",
    "\n",
    "# Remove zero-variance features\n",
    "rna_std = rna_shared.std(axis=0)\n",
    "prot_std = protein_shared.std(axis=0)\n",
    "valid_mask = (rna_std > 1e-6) & (prot_std > 1e-6)\n",
    "\n",
    "if not valid_mask.all():\n",
    "    print(f\"Removing {(~valid_mask).sum()} zero-variance features\")\n",
    "    rna_shared = rna_shared[:, valid_mask]\n",
    "    protein_shared = protein_shared[:, valid_mask]\n",
    "    # Update correspondence\n",
    "    rna_protein_correspondence = rna_protein_correspondence[valid_mask]\n",
    "\n",
    "print(f\"\\nFinal shared arrays:\")\n",
    "print(f\"  rna_shared: {rna_shared.shape}\")\n",
    "print(f\"  protein_shared: {protein_shared.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze shared feature quality\n",
    "print(\"=\" * 60)\n",
    "print(\"SHARED FEATURE QUALITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get raw counts for analysis (before normalization)\n",
    "rna_raw_shared = rna_adata[:, rna_protein_correspondence[:, 0]].X\n",
    "if sparse.issparse(rna_raw_shared):\n",
    "    rna_raw_shared = rna_raw_shared.toarray()\n",
    "\n",
    "protein_raw_shared = protein_adata[:, rna_protein_correspondence[:, 1]].X\n",
    "if sparse.issparse(protein_raw_shared):\n",
    "    protein_raw_shared = protein_raw_shared.toarray()\n",
    "\n",
    "# Calculate statistics for each feature\n",
    "feature_stats = []\n",
    "for i, (rna_gene, prot_marker) in enumerate(rna_protein_correspondence):\n",
    "    rna_col = rna_raw_shared[:, i]\n",
    "    prot_col = protein_raw_shared[:, i]\n",
    "    \n",
    "    # % cells expressing\n",
    "    rna_pct_expressing = (rna_col > 0).sum() / len(rna_col) * 100\n",
    "    prot_pct_expressing = (prot_col > 0).sum() / len(prot_col) * 100\n",
    "    \n",
    "    feature_stats.append({\n",
    "        'RNA_gene': rna_gene,\n",
    "        'Protein': prot_marker,\n",
    "        'RNA_%_expressing': rna_pct_expressing,\n",
    "        'Prot_%_expressing': prot_pct_expressing,\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(feature_stats)\n",
    "stats_df = stats_df.sort_values('RNA_%_expressing', ascending=True)\n",
    "\n",
    "print(\"\\nFeature-by-feature statistics (sorted by RNA detection rate):\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY:\")\n",
    "avg_rna_detection = stats_df['RNA_%_expressing'].mean()\n",
    "avg_prot_detection = stats_df['Prot_%_expressing'].mean()\n",
    "print(f\"  Average RNA detection rate: {avg_rna_detection:.1f}% of cells\")\n",
    "print(f\"  Average Protein detection rate: {avg_prot_detection:.1f}% of cells\")\n",
    "\n",
    "# Warning for sparse features\n",
    "rare_features = stats_df[stats_df['RNA_%_expressing'] < 10]\n",
    "if len(rare_features) > 0:\n",
    "    print(f\"\\n  NOTE: {len(rare_features)} features detected in <10% of RNA cells\")\n",
    "    print(\"  These provide weaker signal for matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein active - use all markers (except DAPI)\n",
    "protein_markers_active = [m for m in protein_adata.var_names if m != 'DAPI']\n",
    "protein_adata_active = protein_adata[:, protein_markers_active].copy()\n",
    "\n",
    "# Scale if needed\n",
    "prot_mean = protein_adata_active.X.mean()\n",
    "if abs(prot_mean) > 0.1:\n",
    "    sc.pp.scale(protein_adata_active)\n",
    "    \n",
    "print(f\"Protein active: {protein_adata_active.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numpy arrays\n",
    "rna_active = rna_adata.X.copy()\n",
    "if sparse.issparse(rna_active):\n",
    "    rna_active = rna_active.toarray()\n",
    "\n",
    "protein_active = protein_adata_active.X.copy()\n",
    "if sparse.issparse(protein_active):\n",
    "    protein_active = protein_active.toarray()\n",
    "\n",
    "# Remove zero-variance features\n",
    "rna_active = rna_active[:, rna_active.std(axis=0) > 1e-6]\n",
    "protein_active = protein_active[:, protein_active.std(axis=0) > 1e-6]\n",
    "\n",
    "print(f\"\\nFinal active arrays:\")\n",
    "print(f\"  rna_active (HVGs): {rna_active.shape}\")\n",
    "print(f\"  protein_active: {protein_active.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL VALIDATION: Check array dimensions match\n",
    "print(\"=\" * 50)\n",
    "print(\"DIMENSION VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RNA shared cells:     {rna_shared.shape[0]}\")\n",
    "print(f\"RNA active cells:     {rna_active.shape[0]}\")\n",
    "print(f\"Protein shared cells: {protein_shared.shape[0]}\")\n",
    "print(f\"Protein active cells: {protein_active.shape[0]}\")\n",
    "print()\n",
    "\n",
    "assert rna_shared.shape[0] == rna_active.shape[0], \\\n",
    "    f\"RNA mismatch: shared={rna_shared.shape[0]}, active={rna_active.shape[0]}\"\n",
    "assert protein_shared.shape[0] == protein_active.shape[0], \\\n",
    "    f\"Protein mismatch: shared={protein_shared.shape[0]}, active={protein_active.shape[0]}\"\n",
    "assert rna_shared.shape[1] == protein_shared.shape[1], \\\n",
    "    f\"Shared feature mismatch: RNA={rna_shared.shape[1]}, Protein={protein_shared.shape[1]}\"\n",
    "\n",
    "print(\"All dimensions validated!\")\n",
    "print(f\"\\nIntegrating {rna_active.shape[0]} RNA cells with {protein_active.shape[0]} protein cells\")\n",
    "print(f\"Using {rna_shared.shape[1]} shared features for initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MARIO Integration\n",
    "\n",
    "MARIO (Matching And Refinement of Integration Operations) provides:\n",
    "1. **Matchability test**: Statistical test to validate datasets can be integrated\n",
    "2. **Interpolation**: Automatic search for optimal weight between overlap and all features\n",
    "3. **Joint regularized clustering**: Clusters both modalities simultaneously\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: MARIO - Matchability Test (Pre-Integration Diagnostic)\n",
    "\n",
    "Before running integration, we test whether the two datasets have meaningful correspondence.\n",
    "MARIO uses random sign flips to create a null distribution and computes p-values.\n",
    "\n",
    "- **Low p-value** (< 0.05): Datasets are matchable\n",
    "- **High p-value** (> 0.05): No significant correspondence detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Check for and handle NaN/Inf values that may result from normalization of sparse features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and handle NaN/Inf values before MARIO\n",
    "# Detection-aware normalization can produce NaN for problematic features\n",
    "\n",
    "print(\"Checking for NaN/Inf values in shared arrays...\")\n",
    "print(f\"  rna_shared: NaN={np.isnan(rna_shared).sum()}, Inf={np.isinf(rna_shared).sum()}\")\n",
    "print(f\"  protein_shared: NaN={np.isnan(protein_shared).sum()}, Inf={np.isinf(protein_shared).sum()}\")\n",
    "\n",
    "# Replace NaN/Inf with 0 (these are likely failed normalizations for sparse features)\n",
    "if np.isnan(rna_shared).any() or np.isinf(rna_shared).any():\n",
    "    print(\"\\nCleaning rna_shared...\")\n",
    "    rna_shared = np.nan_to_num(rna_shared, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "if np.isnan(protein_shared).any() or np.isinf(protein_shared).any():\n",
    "    print(\"Cleaning protein_shared...\")\n",
    "    protein_shared = np.nan_to_num(protein_shared, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Also check active arrays\n",
    "print(f\"\\n  rna_active: NaN={np.isnan(rna_active).sum()}, Inf={np.isinf(rna_active).sum()}\")\n",
    "print(f\"  protein_active: NaN={np.isnan(protein_active).sum()}, Inf={np.isinf(protein_active).sum()}\")\n",
    "\n",
    "if np.isnan(rna_active).any() or np.isinf(rna_active).any():\n",
    "    print(\"\\nCleaning rna_active...\")\n",
    "    rna_active = np.nan_to_num(rna_active, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "if np.isnan(protein_active).any() or np.isinf(protein_active).any():\n",
    "    print(\"Cleaning protein_active...\")\n",
    "    protein_active = np.nan_to_num(protein_active, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"\\nArrays cleaned and ready for integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample for MARIO (MARIO requires n1 <= n2, and for speed we subsample)\n",
    "np.random.seed(42)\n",
    "\n",
    "# MARIO needs RNA (smaller) to be df1 and Protein (larger) to be df2\n",
    "n_rna_subsample = min(2000, rna_shared.shape[0])\n",
    "n_prot_subsample = min(10000, protein_shared.shape[0])\n",
    "\n",
    "rna_idx_subsample = np.random.choice(rna_shared.shape[0], n_rna_subsample, replace=False)\n",
    "prot_idx_subsample = np.random.choice(protein_shared.shape[0], n_prot_subsample, replace=False)\n",
    "\n",
    "# Create DataFrames with overlapping column names (required by MARIO)\n",
    "shared_feature_names = [f\"feat_{i}\" for i in range(rna_shared.shape[1])]\n",
    "\n",
    "# Extract subsamples and ensure no NaN values\n",
    "rna_subsample = rna_shared[rna_idx_subsample].copy()\n",
    "prot_subsample = protein_shared[prot_idx_subsample].copy()\n",
    "\n",
    "# Final NaN check on subsamples\n",
    "rna_subsample = np.nan_to_num(rna_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "prot_subsample = np.nan_to_num(prot_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "rna_df_mario = pd.DataFrame(rna_subsample, columns=shared_feature_names)\n",
    "prot_df_mario = pd.DataFrame(prot_subsample, columns=shared_feature_names)\n",
    "\n",
    "print(f\"MARIO subsample sizes:\")\n",
    "print(f\"  RNA: {rna_df_mario.shape}\")\n",
    "print(f\"  Protein: {prot_df_mario.shape}\")\n",
    "print(f\"  NaN in RNA df: {rna_df_mario.isna().sum().sum()}\")\n",
    "print(f\"  NaN in Protein df: {prot_df_mario.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MARIO\n",
    "mario = Mario(rna_df_mario, prot_df_mario, normalization=True)\n",
    "\n",
    "# Specify matching parameters\n",
    "# n_matched_per_cell: how many protein cells to match with each RNA cell\n",
    "n_matched = max(1, n_prot_subsample // n_rna_subsample)\n",
    "mario.specify_matching_params(n_matched_per_cell=n_matched)\n",
    "\n",
    "print(f\"Matching {n_matched} protein cells per RNA cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance using overlapping features\n",
    "n_ovlp_components = min(15, rna_shared.shape[1] - 1)\n",
    "dist_ovlp, singular_vals = mario.compute_dist_ovlp(n_components=n_ovlp_components)\n",
    "\n",
    "print(f\"Distance matrix shape: {dist_ovlp.shape}\")\n",
    "print(f\"Singular values: {singular_vals[:5]}...\")\n",
    "\n",
    "# Plot singular values\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(singular_vals, 'bo-')\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Singular Value')\n",
    "plt.title('MARIO: Singular Values of Stacked Overlap Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial matching using overlap features\n",
    "print(\"Finding initial matching using overlap features...\")\n",
    "matching_ovlp = mario.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "# Count matched cells\n",
    "n_matched_cells = sum(1 for m in matching_ovlp if len(m) > 0)\n",
    "print(f\"Matched {n_matched_cells}/{len(matching_ovlp)} RNA cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add active features (all HVGs) for refined matching\n",
    "# For MARIO, we need DataFrames with:\n",
    "# - Overlapping columns (shared features) with same names\n",
    "# - Non-overlapping columns (active features) with different names\n",
    "\n",
    "# RNA: shared features + active features\n",
    "rna_active_subsample = rna_active[rna_idx_subsample].copy()\n",
    "rna_active_subsample = np.nan_to_num(rna_active_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "rna_active_names = [f\"rna_feat_{i}\" for i in range(rna_active_subsample.shape[1])]\n",
    "\n",
    "rna_df_full = pd.DataFrame(\n",
    "    np.hstack([rna_subsample, rna_active_subsample]),\n",
    "    columns=shared_feature_names + rna_active_names\n",
    ")\n",
    "\n",
    "# Protein: shared features + active features\n",
    "prot_active_subsample = protein_active[prot_idx_subsample].copy()\n",
    "prot_active_subsample = np.nan_to_num(prot_active_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "prot_active_names = [f\"prot_feat_{i}\" for i in range(prot_active_subsample.shape[1])]\n",
    "\n",
    "prot_df_full = pd.DataFrame(\n",
    "    np.hstack([prot_subsample, prot_active_subsample]),\n",
    "    columns=shared_feature_names + prot_active_names\n",
    ")\n",
    "\n",
    "print(f\"Full DataFrames for MARIO:\")\n",
    "print(f\"  RNA: {rna_df_full.shape} ({len(shared_feature_names)} shared + {len(rna_active_names)} active)\")\n",
    "print(f\"  Protein: {prot_df_full.shape} ({len(shared_feature_names)} shared + {len(prot_active_names)} active)\")\n",
    "print(f\"  NaN check - RNA: {rna_df_full.isna().sum().sum()}, Protein: {prot_df_full.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new MARIO object with full features\n",
    "mario_full = Mario(rna_df_full, prot_df_full, normalization=False)\n",
    "mario_full.specify_matching_params(n_matched_per_cell=n_matched)\n",
    "\n",
    "# Compute distance using overlap features\n",
    "_ = mario_full.compute_dist_ovlp(n_components=n_ovlp_components)\n",
    "\n",
    "# Initial matching\n",
    "_ = mario_full.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "# Compute distance using ALL features (CCA refinement)\n",
    "n_cca_components = min(20, min(rna_df_full.shape[1], prot_df_full.shape[1]) - 1)\n",
    "dist_all, cancor = mario_full.compute_dist_all('ovlp', n_components=n_cca_components)\n",
    "\n",
    "print(f\"Canonical correlations: {cancor[:5]}...\")\n",
    "\n",
    "# Plot canonical correlations\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(len(cancor)), cancor)\n",
    "plt.xlabel('CCA Component')\n",
    "plt.ylabel('Canonical Correlation')\n",
    "plt.title('MARIO: Canonical Correlations (higher = better alignment)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match using all features\n",
    "matching_all = mario_full.match_cells('all', sparsity=None, mode='auto')\n",
    "\n",
    "n_matched_all = sum(1 for m in matching_all if len(m) > 0)\n",
    "print(f\"Matched {n_matched_all}/{len(matching_all)} RNA cells using all features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check canonical correlations before matchability test\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MATCHABILITY DIAGNOSTIC\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check the canonical correlations from the existing matching\n",
    "print(\"\\n1. OBSERVED CANONICAL CORRELATIONS:\")\n",
    "print(f\"   From compute_dist_all (stored): {cancor[:5] if 'cancor' in dir() else 'Not computed'}\")\n",
    "\n",
    "# Check data properties\n",
    "print(\"\\n2. DATA PROPERTIES:\")\n",
    "print(f\"   mario_full.df1 shape: {mario_full.df1.shape}\")\n",
    "print(f\"   mario_full.df2 shape: {mario_full.df2.shape}\")\n",
    "print(f\"   Overlap features: {len(mario_full.ovlp_features)}\")\n",
    "\n",
    "# Check for zero-variance features\n",
    "df1_std = mario_full.df1.std()\n",
    "df2_std = mario_full.df2.std()\n",
    "print(f\"\\n   df1 zero-variance features: {(df1_std < 1e-10).sum()}\")\n",
    "print(f\"   df2 zero-variance features: {(df2_std < 1e-10).sum()}\")\n",
    "\n",
    "# Check data scale\n",
    "print(\"\\n3. DATA SCALE:\")\n",
    "print(f\"   df1 mean: {mario_full.df1.values.mean():.4f}, std: {mario_full.df1.values.std():.4f}\")\n",
    "print(f\"   df2 mean: {mario_full.df2.values.mean():.4f}, std: {mario_full.df2.values.std():.4f}\")\n",
    "\n",
    "# CHECK MATCHING - this is critical\n",
    "print(\"\\n4. MATCHING STATISTICS:\")\n",
    "n_matched_ovlp = sum(1 for m in mario_full.matching['ovlp'] if len(m) > 0)\n",
    "n_matched_all = sum(1 for m in mario_full.matching['all'] if len(m) > 0)\n",
    "print(f\"   Cells matched (overlap): {n_matched_ovlp} / {mario_full.n1}\")\n",
    "print(f\"   Cells matched (all):     {n_matched_all} / {mario_full.n1}\")\n",
    "\n",
    "# Check the aligned data dimensions for CCA\n",
    "from mario import embed\n",
    "X_aligned = []\n",
    "Y_aligned = []\n",
    "for ii in range(mario_full.n1):\n",
    "    if len(mario_full.matching['ovlp'][ii]) > 0:\n",
    "        X_aligned.append(mario_full.df1.iloc[ii, :].values)\n",
    "        Y_aligned.append(mario_full.df2.iloc[mario_full.matching['ovlp'][ii]].mean(axis=0).values)\n",
    "\n",
    "X_aligned = np.array(X_aligned)\n",
    "Y_aligned = np.array(Y_aligned)\n",
    "print(f\"\\n5. CCA INPUT DIMENSIONS:\")\n",
    "print(f\"   X (RNA) aligned: {X_aligned.shape}\")\n",
    "print(f\"   Y (Protein) aligned: {Y_aligned.shape}\")\n",
    "print(f\"   Ratio features/samples (RNA): {X_aligned.shape[1]/X_aligned.shape[0]:.1f}\")\n",
    "\n",
    "# THE PROBLEM: CCA with features >> samples gives trivial perfect correlations!\n",
    "if X_aligned.shape[1] > X_aligned.shape[0]:\n",
    "    print(\"\\n   \u26a0\ufe0f  WARNING: More features than samples!\")\n",
    "    print(\"   CCA will overfit and give meaningless correlations of 1.0\")\n",
    "    print(\"   This is why matchability test returns p=1\")\n",
    "\n",
    "# Test CCA with ONLY overlap features\n",
    "print(\"\\n6. CCA WITH OVERLAP FEATURES ONLY:\")\n",
    "X_ovlp = mario_full.df1[mario_full.ovlp_features].iloc[[i for i in range(mario_full.n1) if len(mario_full.matching['ovlp'][i]) > 0]].values\n",
    "Y_ovlp = np.array([mario_full.df2[mario_full.ovlp_features].iloc[mario_full.matching['ovlp'][i]].mean(axis=0).values \n",
    "                   for i in range(mario_full.n1) if len(mario_full.matching['ovlp'][i]) > 0])\n",
    "print(f\"   X_ovlp shape: {X_ovlp.shape}\")\n",
    "print(f\"   Y_ovlp shape: {Y_ovlp.shape}\")\n",
    "\n",
    "try:\n",
    "    n_comp = min(5, X_ovlp.shape[1]-1, X_ovlp.shape[0]-1)\n",
    "    cancor_ovlp_only, _ = embed.get_cancor(X_ovlp, Y_ovlp, n_components=n_comp)\n",
    "    print(f\"   Canonical correlations (overlap only): {cancor_ovlp_only}\")\n",
    "    print(f\"   Mean: {np.mean(cancor_ovlp_only):.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run matchability test\n",
    "print(\"=\" * 60)\n",
    "print(\"MARIO MATCHABILITY TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nRunning statistical test for dataset matchability...\")\n",
    "print(\"(This uses random sign flips to create null distribution)\")\n",
    "print()\n",
    "\n",
    "# CRITICAL FIX: Clean NaN/Inf values in MARIO dataframes before matchability test\n",
    "# The matchability test internally uses CCA which cannot handle NaN values\n",
    "print(\"Cleaning MARIO dataframes for CCA compatibility...\")\n",
    "\n",
    "# Clean df1 (RNA) - aggressive column-by-column approach\n",
    "mario_full.df1 = mario_full.df1.copy()\n",
    "for col in mario_full.df1.columns:\n",
    "    mario_full.df1[col] = np.nan_to_num(mario_full.df1[col].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Clean df2 (Protein) - aggressive column-by-column approach\n",
    "mario_full.df2 = mario_full.df2.copy()\n",
    "for col in mario_full.df2.columns:\n",
    "    mario_full.df2[col] = np.nan_to_num(mario_full.df2[col].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Verify no NaN/Inf remain\n",
    "df1_clean = not (np.isnan(mario_full.df1.values).any() or np.isinf(mario_full.df1.values).any())\n",
    "df2_clean = not (np.isnan(mario_full.df2.values).any() or np.isinf(mario_full.df2.values).any())\n",
    "print(f\"  df1 clean: {df1_clean} (NaN: {np.isnan(mario_full.df1.values).sum()}, Inf: {np.isinf(mario_full.df1.values).sum()})\")\n",
    "print(f\"  df2 clean: {df2_clean} (NaN: {np.isnan(mario_full.df2.values).sum()}, Inf: {np.isinf(mario_full.df2.values).sum()})\")\n",
    "assert df1_clean and df2_clean, \"Failed to clean NaN/Inf values\"\n",
    "\n",
    "# Ensure both initial (ovlp) and refined (all) matching are complete\n",
    "print(\"Verifying initial and refined matching are complete...\")\n",
    "\n",
    "# Check if matching has been done, if not redo it\n",
    "if not hasattr(mario_full, 'matching_ovlp') or mario_full.matching_ovlp is None:\n",
    "    print(\"  Re-running initial matching (overlap features)...\")\n",
    "    mario_full.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "if not hasattr(mario_full, 'matching_all') or mario_full.matching_all is None:\n",
    "    print(\"  Re-running refined matching (all features)...\")\n",
    "    mario_full.match_cells('all', sparsity=None, mode='auto')\n",
    "\n",
    "print(\"  Both matchings confirmed. Proceeding with matchability test...\\n\")\n",
    "\n",
    "# Note: This can take a few minutes\n",
    "# Reduce n_sim if it takes too long\n",
    "pval_ovlp, pval_all = mario_full.matchable(\n",
    "    n_sim=10,           # Number of simulations (increase for more accuracy)\n",
    "    top_k=5,            # Use top-k canonical correlations\n",
    "    flip_prob=0.3,      # Probability of sign flip\n",
    "    subsample_prop=1,   # Subsample for speed\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MATCHABILITY TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"P-value (overlap features only): {pval_ovlp:.4f}\")\n",
    "print(f\"P-value (all features):          {pval_all:.4f}\")\n",
    "print()\n",
    "\n",
    "if pval_ovlp < 0.05 or pval_all < 0.05:\n",
    "    print(\"RESULT: Datasets appear to be MATCHABLE (p < 0.05)\")\n",
    "    print(\"  The correspondence between modalities is statistically significant.\")\n",
    "else:\n",
    "    print(\"RESULT: Datasets may NOT be well-matched (p >= 0.05)\")\n",
    "    print(\"  Proceed with caution - results may be unreliable.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: MARIO - Interpolation (Optimal Weight Search)\n",
    "\n",
    "MARIO searches for the optimal weight between:\n",
    "- Distance from **overlap features only**\n",
    "- Distance from **all features** (via CCA)\n",
    "\n",
    "The optimal weight is selected based on canonical correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interpolation to find optimal weight\n",
    "print(\"Searching for optimal interpolation weight...\")\n",
    "print(\"(Testing weights from 0 to 1)\")\n",
    "print()\n",
    "\n",
    "best_wt, best_matching = mario_full.interpolate(\n",
    "    n_wts=10,     # Number of weights to try\n",
    "    top_k=5,      # Use top-k canonical correlations to evaluate\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal weight: {best_wt:.2f}\")\n",
    "print(f\"  (0 = use only overlap features, 1 = use only CCA features)\")\n",
    "\n",
    "n_matched_best = sum(1 for m in best_matching if len(m) > 0)\n",
    "print(f\"\\nMatched {n_matched_best}/{len(best_matching)} RNA cells with optimal weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bad matches using joint regularized clustering\n",
    "print(\"\\nFiltering bad matches using joint regularized clustering...\")\n",
    "\n",
    "n_clusters_filter = min(15, n_rna_subsample // 50)  # Aim for ~50 cells per cluster\n",
    "n_clusters_filter = max(5, n_clusters_filter)\n",
    "\n",
    "filtered_matching = mario_full.filter_bad_matches(\n",
    "    matching='wted',           # Use the interpolated matching\n",
    "    n_clusters=n_clusters_filter,\n",
    "    n_components=min(15, n_cca_components),\n",
    "    bad_prop=0.1,              # Remove ~10% of worst matches\n",
    "    max_iter=30,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "n_matched_filtered = sum(1 for m in filtered_matching if len(m) > 0)\n",
    "print(f\"\\nAfter filtering: {n_matched_filtered}/{len(filtered_matching)} RNA cells matched\")\n",
    "print(f\"Removed {n_matched_best - n_matched_filtered} bad matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: KNN matching for softer assignments\n",
    "knn_matching = mario_full.knn_matching(dist_mat='wted', k=5)\n",
    "\n",
    "print(f\"KNN matching: each RNA cell matched to {5} nearest protein cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CCA embedding for visualization\n",
    "from mario import embed\n",
    "\n",
    "# Align the datasets using the filtered matching\n",
    "X_aligned = []\n",
    "Y_aligned = []\n",
    "matched_rna_indices_mario = []\n",
    "matched_prot_indices_mario = []\n",
    "\n",
    "for i, matches in enumerate(filtered_matching):\n",
    "    if len(matches) > 0:\n",
    "        X_aligned.append(rna_df_full.iloc[i].values)\n",
    "        # Average the matched protein cells\n",
    "        Y_aligned.append(prot_df_full.iloc[matches].mean(axis=0).values)\n",
    "        matched_rna_indices_mario.append(rna_idx_subsample[i])\n",
    "        matched_prot_indices_mario.append(prot_idx_subsample[matches[0]])  # Take first match\n",
    "\n",
    "X_aligned = np.array(X_aligned)\n",
    "Y_aligned = np.array(Y_aligned)\n",
    "\n",
    "print(f\"Aligned arrays: RNA {X_aligned.shape}, Protein {Y_aligned.shape}\")\n",
    "\n",
    "# Fit CCA for embedding\n",
    "embed_dim = min(20, X_aligned.shape[1], Y_aligned.shape[1])\n",
    "cancor_embed, cca = embed.get_cancor(X_aligned, Y_aligned, n_components=embed_dim)\n",
    "\n",
    "# Get CCA scores\n",
    "rna_cca_mario, prot_cca_mario = cca.transform(X_aligned, Y_aligned)\n",
    "\n",
    "print(f\"MARIO CCA embedding: {rna_cca_mario.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MARIO results\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Combine embeddings\n",
    "combined_mario = np.vstack([rna_cca_mario, prot_cca_mario])\n",
    "labels_mario = ['RNA'] * len(rna_cca_mario) + ['Protein'] * len(prot_cca_mario)\n",
    "\n",
    "# Run t-SNE (faster than UMAP for small datasets)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "embedding_2d = tsne.fit_transform(combined_mario[:, :10])  # Use first 10 CCA components\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in ['RNA', 'Protein']:\n",
    "    mask = np.array(labels_mario) == label\n",
    "    plt.scatter(embedding_2d[mask, 0], embedding_2d[mask, 1], \n",
    "                label=label, alpha=0.5, s=10)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('MARIO: Joint Embedding (t-SNE of CCA scores)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MaxFuse Integration\n",
    "\n",
    "MaxFuse uses:\n",
    "1. Graph-based smoothing for noise reduction\n",
    "2. Iterative CCA refinement\n",
    "3. Pivot-based propagation for scalability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: MaxFuse Integration\n",
    "\n",
    "MaxFuse performs the integration in several stages:\n",
    "1. Split data into batches for scalability\n",
    "2. Construct k-NN graphs and cluster cells\n",
    "3. Find initial pivot matches using shared features\n",
    "4. Refine pivots using CCA on all features\n",
    "5. Propagate matching to all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fusor - let MaxFuse cluster automatically\n",
    "fusor = mf.model.Fusor(\n",
    "    shared_arr1=rna_shared,\n",
    "    shared_arr2=protein_shared,\n",
    "    active_arr1=rna_active,\n",
    "    active_arr2=protein_active,\n",
    "    labels1=None,  # Let MaxFuse cluster\n",
    "    labels2=None,\n",
    "    method='centroid_shrinkage'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate appropriate batching parameters\n",
    "n_rna = rna_active.shape[0]\n",
    "n_prot = protein_active.shape[0]\n",
    "ratio = n_prot / n_rna\n",
    "\n",
    "print(f\"RNA cells: {n_rna}\")\n",
    "print(f\"Protein cells: {n_prot}\")\n",
    "print(f\"Ratio (protein/RNA): {ratio:.1f}\")\n",
    "\n",
    "# Batching parameters\n",
    "max_outward = min(8000, n_rna)\n",
    "matching_ratio = max(10, int(ratio) + 5)  # Adjusted for data ratio\n",
    "metacell_sz = 2  # Metacell aggregation helps with noise\n",
    "\n",
    "print(f\"\\nBatching parameters:\")\n",
    "print(f\"  max_outward_size: {max_outward}\")\n",
    "print(f\"  matching_ratio: {matching_ratio}\")\n",
    "print(f\"  metacell_size: {metacell_sz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusor.split_into_batches(\n",
    "    max_outward_size=max_outward,\n",
    "    matching_ratio=matching_ratio,\n",
    "    metacell_size=metacell_sz,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot singular values to determine SVD components\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "fusor.plot_singular_values(target='active_arr1', n_components=50)\n",
    "axes[0].set_title('RNA Active - Singular Values')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "fusor.plot_singular_values(target='active_arr2', n_components=min(23, protein_active.shape[1]-1))\n",
    "axes[1].set_title('Protein Active - Singular Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SVD components based on data dimensions\n",
    "n_prot_features = protein_active.shape[1]\n",
    "n_rna_features = rna_active.shape[1]\n",
    "n_shared = rna_shared.shape[1]\n",
    "\n",
    "svd_comp1_graph = min(40, n_rna_features - 1)\n",
    "svd_comp2_graph = min(15, n_prot_features - 1)\n",
    "\n",
    "print(f\"Graph construction SVD components:\")\n",
    "print(f\"  RNA: {svd_comp1_graph}\")\n",
    "print(f\"  Protein: {svd_comp2_graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct graphs with automatic clustering\n",
    "fusor.construct_graphs(\n",
    "    n_neighbors1=15,\n",
    "    n_neighbors2=15,\n",
    "    svd_components1=svd_comp1_graph,\n",
    "    svd_components2=svd_comp2_graph,\n",
    "    resolution1=2.0,   # Higher resolution = more clusters = finer smoothing\n",
    "    resolution2=2.0,\n",
    "    resolution_tol=0.1,\n",
    "    leiden_runs=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find initial pivots with smoothing for weak linkage\n",
    "svd_shared1 = min(25, n_shared - 1)\n",
    "svd_shared2 = min(20, n_shared - 1)\n",
    "print(f\"Using {svd_shared1}/{svd_shared2} SVD components for shared features\")\n",
    "\n",
    "fusor.find_initial_pivots(\n",
    "    wt1=0.3,  # Smoothing weight\n",
    "    wt2=0.3,\n",
    "    svd_components1=svd_shared1,\n",
    "    svd_components2=svd_shared2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check canonical correlations\n",
    "cca_comp_check = min(15, n_prot_features - 1)\n",
    "fusor.plot_canonical_correlations(\n",
    "    svd_components1=min(30, n_rna_features - 1),\n",
    "    svd_components2=None,\n",
    "    cca_components=cca_comp_check\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine pivots using CCA\n",
    "cca_components = min(25, n_prot_features - 1)\n",
    "\n",
    "fusor.refine_pivots(\n",
    "    wt1=0.3,\n",
    "    wt2=0.3,\n",
    "    svd_components1=min(40, n_rna_features - 1),\n",
    "    svd_components2=None,  # Keep all protein features\n",
    "    cca_components=cca_components,\n",
    "    n_iters=1,\n",
    "    filter_prop=0.0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bad pivots\n",
    "fusor.filter_bad_matches(\n",
    "    target='pivot',\n",
    "    filter_prop=0.5,  # Remove bottom 50%\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate to all cells\n",
    "fusor.propagate(\n",
    "    svd_components1=min(40, n_rna_features - 1),\n",
    "    svd_components2=None,\n",
    "    wt1=0.7,\n",
    "    wt2=0.7,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propagated matches\n",
    "fusor.filter_bad_matches(\n",
    "    target='propagated',\n",
    "    filter_prop=0.3,  # Remove bottom 30%\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full matching\n",
    "full_matching = fusor.get_matching(order=(2, 1), target='full_data')\n",
    "\n",
    "print(f\"\\nMaxFuse Full matching results:\")\n",
    "print(f\"  Total matches: {len(full_matching[0])}\")\n",
    "print(f\"  Unique RNA cells: {len(np.unique(full_matching[0]))}\")\n",
    "print(f\"  Unique Protein cells: {len(np.unique(full_matching[1]))}\")\n",
    "print(f\"  Score range: [{min(full_matching[2]):.3f}, {max(full_matching[2]):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Integration Results\n",
    "\n",
    "Save integration outputs for use in subsequent visualization notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save integration results to results directory\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results/2_integration'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save matching results\n",
    "matching_data = {\n",
    "    'rna_indices': full_matching[0],\n",
    "    'protein_indices': full_matching[1],\n",
    "    'scores': full_matching[2]\n",
    "}\n",
    "with open(f'{results_dir}/maxfuse_matching.pkl', 'wb') as f:\n",
    "    pickle.dump(matching_data, f)\n",
    "print(f\"Saved MaxFuse matching: {len(full_matching[0])} matches\")\n",
    "\n",
    "# Save as CSV for easy inspection\n",
    "matching_df = pd.DataFrame({\n",
    "    'rna_idx': full_matching[0],\n",
    "    'protein_idx': full_matching[1],\n",
    "    'score': full_matching[2]\n",
    "})\n",
    "matching_df.to_csv(f'{results_dir}/maxfuse_matching.csv', index=False)\n",
    "\n",
    "# Save normalized arrays used for integration\n",
    "np.save(f'{results_dir}/rna_shared.npy', rna_shared)\n",
    "np.save(f'{results_dir}/rna_active.npy', rna_active)\n",
    "np.save(f'{results_dir}/protein_shared.npy', protein_shared)\n",
    "np.save(f'{results_dir}/protein_active.npy', protein_active)\n",
    "print(f\"Saved normalized arrays\")\n",
    "\n",
    "# Save correspondence table\n",
    "correspondence_df = pd.DataFrame(unique_pairs, columns=['rna_gene', 'protein_marker'])\n",
    "correspondence_df.to_csv(f'{results_dir}/correspondence.csv', index=False)\n",
    "\n",
    "# Save integration parameters\n",
    "n_shared = rna_shared.shape[1]\n",
    "integration_params = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'fusor_params': {\n",
    "        'max_outward_size': max_outward,\n",
    "        'matching_ratio': matching_ratio,\n",
    "        'smoothing_method': 'graph_smoothing',\n",
    "        'n_shared_features': n_shared,\n",
    "        'cca_components': cca_components\n",
    "    },\n",
    "    'data_shapes': {\n",
    "        'rna_cells': rna_active.shape[0],\n",
    "        'protein_cells': protein_active.shape[0],\n",
    "        'rna_active_features': rna_active.shape[1],\n",
    "        'protein_active_features': protein_active.shape[1],\n",
    "        'shared_features': n_shared\n",
    "    },\n",
    "    'matching_stats': {\n",
    "        'total_matches': len(full_matching[0]),\n",
    "        'unique_rna_matched': len(np.unique(full_matching[0])),\n",
    "        'unique_protein_matched': len(np.unique(full_matching[1])),\n",
    "        'mean_score': float(np.mean(full_matching[2]))\n",
    "    }\n",
    "}\n",
    "with open(f'{results_dir}/integration_params.json', 'w') as f:\n",
    "    json.dump(integration_params, f, indent=2)\n",
    "\n",
    "print(f\"\\nAll outputs saved to {results_dir}/\")\n",
    "print(f\"  - maxfuse_matching.pkl (pickle)\")\n",
    "print(f\"  - maxfuse_matching.csv\")\n",
    "print(f\"  - rna_shared.npy, rna_active.npy\")\n",
    "print(f\"  - protein_shared.npy, protein_active.npy\")\n",
    "print(f\"  - correspondence.csv\")\n",
    "print(f\"  - integration_params.json\")\n",
    "print(f\"\\nRun 3_visualization.ipynb next.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kintegrate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}