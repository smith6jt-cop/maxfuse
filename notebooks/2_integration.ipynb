{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration: MaxFuse and MARIO\n",
    "\n",
    "This notebook performs cross-modal integration of RNA-seq and CODEX protein data.\n",
    "\n",
    "## Recommended Workflow\n",
    "\n",
    "**For cross-modal data (RNA + Protein/CODEX):**\n",
    "1. Run Steps 1-4 (data loading and preparation)\n",
    "2. **Skip** MARIO section (designed for same-modality data)\n",
    "3. Run **MaxFuse Integration** (Step 7+)\n",
    "\n",
    "**For same-modality data (e.g., CITE-seq + CyTOF):**\n",
    "1. Run all steps including MARIO\n",
    "\n",
    "## What Each Method Does\n",
    "\n",
    "| Method | Best For | Key Feature |\n",
    "|--------|----------|-------------|\n",
    "| **MaxFuse** | Cross-modal (RNA\u2194Protein) | Handles weak feature linkage |\n",
    "| **MARIO** | Same-modality (Protein\u2194Protein) | Statistical matchability test |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "\n",
    "# MaxFuse imports\n",
    "import maxfuse as mf\n",
    "from maxfuse import Fusor, Mario\n",
    "from maxfuse.mario import pipelined_mario\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from results/1_preprocessing/\n",
      "  Protein data: (1900754, 59)\n",
      "  RNA data: (1669, 16050)\n",
      "  RNA log-normalized: (1669, 16050)\n",
      "\n",
      "Preprocessing timestamp: 2026-01-15T14:43:38.389358\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data from 1_preprocessing.ipynb\n",
    "# Run 1_preprocessing.ipynb first to generate these files\n",
    "\n",
    "import os\n",
    "\n",
    "results_dir = 'results/1_preprocessing'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Results directory '{results_dir}' not found. \"\n",
    "        f\"Run 1_preprocessing.ipynb first to generate the input files.\"\n",
    "    )\n",
    "\n",
    "# Load processed AnnData objects\n",
    "protein_adata = sc.read_h5ad(f'{results_dir}/protein_adata.h5ad')\n",
    "rna_adata = sc.read_h5ad(f'{results_dir}/rna_adata.h5ad')\n",
    "rna_adata_lognorm = sc.read_h5ad(f'{results_dir}/rna_adata_lognorm.h5ad')\n",
    "\n",
    "print(f\"Loaded from {results_dir}/\")\n",
    "print(f\"  Protein data: {protein_adata.shape}\")\n",
    "print(f\"  RNA data: {rna_adata.shape}\")\n",
    "print(f\"  RNA log-normalized: {rna_adata_lognorm.shape}\")\n",
    "\n",
    "# Load preprocessing parameters\n",
    "with open(f'{results_dir}/preprocessing_params.json', 'r') as f:\n",
    "    preprocess_params = json.load(f)\n",
    "print(f\"\\nPreprocessing timestamp: {preprocess_params['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Protein-Gene Correspondence\n",
    "\n",
    "Map CODEX protein markers to their corresponding gene names in the RNA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondence table: 375 entries\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Protein name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RNA name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "69ea4d3b-d126-4de0-9f67-e999590a815e",
       "rows": [
        [
         "0",
         "CD80",
         "CD80"
        ],
        [
         "1",
         "CD86",
         "CD86"
        ],
        [
         "2",
         "CD274",
         "CD274"
        ],
        [
         "3",
         "CD273",
         "PDCD1LG2"
        ],
        [
         "4",
         "CD275",
         "ICOSLG"
        ],
        [
         "5",
         "CD275-1",
         "ICOSLG"
        ],
        [
         "6",
         "CD275-2",
         "ICOSLG"
        ],
        [
         "7",
         "CD11b",
         "ITGAM"
        ],
        [
         "8",
         "CD11b-1",
         "ITGAM"
        ],
        [
         "9",
         "CD11b-2",
         "ITGAM"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein name</th>\n",
       "      <th>RNA name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD80</td>\n",
       "      <td>CD80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD86</td>\n",
       "      <td>CD86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD274</td>\n",
       "      <td>CD274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD273</td>\n",
       "      <td>PDCD1LG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CD275</td>\n",
       "      <td>ICOSLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CD275-1</td>\n",
       "      <td>ICOSLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CD275-2</td>\n",
       "      <td>ICOSLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CD11b</td>\n",
       "      <td>ITGAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CD11b-1</td>\n",
       "      <td>ITGAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CD11b-2</td>\n",
       "      <td>ITGAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein name  RNA name\n",
       "0         CD80      CD80\n",
       "1         CD86      CD86\n",
       "2        CD274     CD274\n",
       "3        CD273  PDCD1LG2\n",
       "4        CD275    ICOSLG\n",
       "5      CD275-1    ICOSLG\n",
       "6      CD275-2    ICOSLG\n",
       "7        CD11b     ITGAM\n",
       "8      CD11b-1     ITGAM\n",
       "9      CD11b-2     ITGAM"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load correspondence table\n",
    "correspondence = pd.read_csv('data/protein_gene_conversion.csv', encoding='utf-8-sig')\n",
    "print(f\"Correspondence table: {correspondence.shape[0]} entries\")\n",
    "correspondence.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 protein-gene pairs\n",
      "\n",
      "Unmatched proteins (1):\n",
      "  Pan-Cytokeratin: Ignored\n"
     ]
    }
   ],
   "source": [
    "# Find matching features between CODEX markers and RNA genes\n",
    "rna_protein_correspondence = []\n",
    "unmatched_proteins = []\n",
    "\n",
    "for marker in protein_adata.var_names:\n",
    "    # Skip DAPI and ECAD (not useful for cell type matching), also add any to skip due to failed staining\n",
    "    if marker in ['DAPI', 'ECAD', 'E-cadherin', 'IAPP', 'LAG3']:\n",
    "        continue\n",
    "    \n",
    "    # Look up in correspondence table\n",
    "    matches = correspondence[correspondence['Protein name'].str.lower() == marker.lower()]\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        # Try alternative names\n",
    "        alt_names = {\n",
    "            'CD3e': 'CD3',\n",
    "            'FoxP3': 'FOXP3',\n",
    "            'HLADR': 'HLA-DR',\n",
    "            'Lyve1': 'LYVE1',\n",
    "            'SMActin': 'aSMA',\n",
    "            'CollagenIV': 'collagen IV',\n",
    "        }\n",
    "        alt_marker = alt_names.get(marker, marker)\n",
    "        matches = correspondence[correspondence['Protein name'].str.lower() == alt_marker.lower()]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        rna_names_str = matches.iloc[0]['RNA name']\n",
    "        if 'Ignore' in str(rna_names_str):\n",
    "            unmatched_proteins.append((marker, 'Ignored'))\n",
    "            continue\n",
    "        \n",
    "        # Try each RNA name option\n",
    "        found = False\n",
    "        for rna_name in str(rna_names_str).split('/'):\n",
    "            if rna_name in rna_adata.var_names:\n",
    "                rna_protein_correspondence.append([rna_name, marker])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            unmatched_proteins.append((marker, rna_names_str))\n",
    "    else:\n",
    "        unmatched_proteins.append((marker, 'Not in table'))\n",
    "\n",
    "rna_protein_correspondence = np.array(rna_protein_correspondence)\n",
    "print(f\"Found {len(rna_protein_correspondence)} protein-gene pairs\")\n",
    "\n",
    "if unmatched_proteins:\n",
    "    print(f\"\\nUnmatched proteins ({len(unmatched_proteins)}):\")\n",
    "    for prot, reason in unmatched_proteins:\n",
    "        print(f\"  {prot}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final correspondence: 54 pairs\n",
      "\n",
      "Matched features:\n",
      "  LAMP1           <-> CD107a\n",
      "  CD4             <-> CD4\n",
      "  PECAM1          <-> CD31\n",
      "  ACTA2           <-> SMA\n",
      "  CD68            <-> CD68\n",
      "  CD44            <-> CD44\n",
      "  VIM             <-> Vimentin\n",
      "  CD99            <-> CD99\n",
      "  IDO1            <-> IDO1\n",
      "  CEACAM1         <-> CD66\n",
      "  INS             <-> INS\n",
      "  KRT8            <-> Ker8-18\n",
      "  ITGAX           <-> CD11c\n",
      "  CD38            <-> CD38\n",
      "  HLA-DRA         <-> HLA-DR\n",
      "  CD34            <-> CD34\n",
      "  NOS2            <-> iNOS\n",
      "  LGALS3          <-> M2Gal3\n",
      "  TUBB3           <-> B3TUBB\n",
      "  CD8A            <-> CD8\n",
      "  PCNA            <-> PCNA\n",
      "  FOXP3           <-> FOXP3\n",
      "  B3GAT1          <-> CD57\n",
      "  MKI67           <-> Ki67\n",
      "  GZMB            <-> Granzyme B\n",
      "  HLA-A           <-> HLA-A\n",
      "  MS4A1           <-> CD20\n",
      "  COL4A1          <-> Collagen IV\n",
      "  VSIR            <-> VISTA\n",
      "  PDCD1           <-> PD-1\n",
      "  SST             <-> SST\n",
      "  TCF7            <-> TCF-1\n",
      "  TOX             <-> TOX\n",
      "  CAV1            <-> Caveolin\n",
      "  ICOS            <-> ICOS\n",
      "  CD163           <-> CD163\n",
      "  EPCAM           <-> EpCAM\n",
      "  CD274           <-> PD-L1\n",
      "  CD79A           <-> CD79a\n",
      "  KRT5            <-> Keratin 5\n",
      "  CD3E            <-> CD3e\n",
      "  GCG             <-> GCG\n",
      "  ACTB            <-> Beta-actin\n",
      "  BCL2            <-> Bcl-2\n",
      "  MPO             <-> MPO\n",
      "  NCAM1           <-> CD56\n",
      "  ENTPD1          <-> CD39\n",
      "  AIF1            <-> Iba1\n",
      "  SOX2            <-> SOX2\n",
      "  CD209           <-> CD209\n",
      "  PDPN            <-> Podoplanin\n",
      "  ITGAM           <-> CD11b\n",
      "  MRC1            <-> CD206\n",
      "  TP63            <-> TP63\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates (same RNA mapping to multiple proteins)\n",
    "# Keep first occurrence\n",
    "seen_rna = set()\n",
    "unique_pairs = []\n",
    "for rna, prot in rna_protein_correspondence:\n",
    "    if rna not in seen_rna:\n",
    "        seen_rna.add(rna)\n",
    "        unique_pairs.append([rna, prot])\n",
    "    else:\n",
    "        print(f\"Removing duplicate RNA mapping: {rna} -> {prot}\")\n",
    "\n",
    "rna_protein_correspondence = np.array(unique_pairs)\n",
    "print(f\"\\nFinal correspondence: {len(rna_protein_correspondence)} pairs\")\n",
    "\n",
    "print(\"\\nMatched features:\")\n",
    "for rna, prot in rna_protein_correspondence:\n",
    "    print(f\"  {rna:15} <-> {prot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Arrays for Integration\n",
    "\n",
    "Extract and normalize:\n",
    "- **Shared arrays**: Corresponding protein/gene features (used for initial matching)\n",
    "- **Active arrays**: All features (used for refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna_shared_adata: (1669, 54)\n",
      "protein_shared_adata: (1900754, 54)\n"
     ]
    }
   ],
   "source": [
    "# Extract shared features from FILTERED data\n",
    "rna_shared_adata = rna_adata[:, rna_protein_correspondence[:, 0]].copy()\n",
    "protein_shared_adata = protein_adata[:, rna_protein_correspondence[:, 1]].copy()\n",
    "\n",
    "print(f\"rna_shared_adata: {rna_shared_adata.shape}\")\n",
    "print(f\"protein_shared_adata: {protein_shared_adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING GATED PROTEIN DATA\n",
      "======================================================================\n",
      "Loaded GATED CODEX: 1,213,219 cells, 59 markers\n",
      "  Data range: [-10.50, 12.59]\n",
      "  Detection: value > 0 (data is already gated/scaled)\n",
      "\n",
      "Shared features: 54\n",
      "  RNA: (1669, 54)\n",
      "  Protein: (1213219, 54)\n",
      "======================================================================\n",
      "DETECTION-AWARE NORMALIZATION PIPELINE\n",
      "======================================================================\n",
      "Cell counts: RNA = 1,669, Protein = 1,213,219\n",
      "======================================================================\n",
      "STEP 1: RNA transformation (log1p)\n",
      "======================================================================\n",
      "RNA raw - zeros: 88.7%\n",
      "After log1p - mean: 0.712\n",
      "======================================================================\n",
      "STEP 2: Protein data (already gated/scaled)\n",
      "======================================================================\n",
      "Protein scaled data:\n",
      "  Range: [-10.50, 12.59]\n",
      "  Mean: 0.306\n",
      "Detection rates (value > 0):\n",
      "  Marker                 Detected %\n",
      "  -----------------------------------\n",
      "  CD11b                       54.9%\n",
      "  CD4                         76.2%\n",
      "  CD8                         80.0%\n",
      "  CD56                        64.8%\n",
      "  CD11c                       73.8%\n",
      "  CD34                        34.1%\n",
      "  CD44                        63.1%\n",
      "  CD20                        78.1%\n",
      "  CD31                        50.8%\n",
      "  Podoplanin                  73.1%\n",
      "  CD107a                      65.8%\n",
      "  HLA-DR                      76.0%\n",
      "  CD66                        82.3%\n",
      "  CD57                        57.7%\n",
      "  CD39                        43.3%\n",
      "  CD206                       59.8%\n",
      "  CD68                        65.9%\n",
      "  CD163                       79.7%\n",
      "  CD38                        76.7%\n",
      "  CD79a                       83.4%\n",
      "  CD209                       65.5%\n",
      "  CD99                        62.3%\n",
      "  FOXP3                       84.9%\n",
      "  PD-L1                       71.4%\n",
      "  Ki67                        76.3%\n",
      "  PD-1                        79.9%\n",
      "  Vimentin                    51.4%\n",
      "  CD99                        62.3%\n",
      "  CD3e                        74.6%\n",
      "  SMA                         47.1%\n",
      "  IDO1                        72.5%\n",
      "  INS                         68.5%\n",
      "  Ker8-18                     73.0%\n",
      "  iNOS                        85.7%\n",
      "  M2Gal3                      55.7%\n",
      "  B3TUBB                      72.2%\n",
      "  PCNA                        84.1%\n",
      "  Granzyme B                  78.5%\n",
      "  HLA-A                       49.1%\n",
      "  VISTA                       71.9%\n",
      "  SST                         77.1%\n",
      "  TCF-1                       64.6%\n",
      "  TOX                         88.8%\n",
      "  Caveolin                    34.8%\n",
      "  ICOS                        66.5%\n",
      "  EpCAM                       77.9%\n",
      "  Keratin 5                   76.2%\n",
      "  GCG                         61.9%\n",
      "  Beta-actin                  55.2%\n",
      "  Bcl-2                       82.8%\n",
      "  MPO                         75.6%\n",
      "  Iba1                        53.7%\n",
      "  SOX2                        86.8%\n",
      "  TP63                        68.6%\n",
      "\n",
      "  Average detection: 68.5%\n",
      "  Range: 34.1% - 88.8%\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Detection-aware normalization\n",
      "======================================================================\n",
      "\n",
      "Zero value: -2.5\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "RNA (detected values only):\n",
      "  N values: 10,121\n",
      "  Mean: 0.0191\n",
      "  Std:  0.9658\n",
      "\n",
      "Protein (detected values only):\n",
      "  N values: 44,556,080\n",
      "  Mean: 0.0191\n",
      "  Std:  0.9750\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Per-feature detection rates:\n",
      "Feature            RNA %   Prot %\n",
      "-----------------------------------\n",
      "CD11b               4.9%    54.9%\n",
      "CD4                 3.5%    76.2%\n",
      "CD8                 5.8%    80.0%\n",
      "CD56                0.5%    64.8%\n",
      "CD11c              13.2%    73.8%\n",
      "CD34                0.7%    34.1%\n",
      "CD44               57.3%    63.1%\n",
      "CD20                0.1%    78.1%\n",
      "CD31                4.1%    50.8%\n",
      "Podoplanin          3.5%    73.1%\n",
      "CD107a             24.3%    65.8%\n",
      "HLA-DR             24.1%    76.0%\n",
      "CD66                0.6%    82.3%\n",
      "CD57                0.2%    57.7%\n",
      "CD39                2.1%    43.3%\n",
      "CD206               9.1%    59.8%\n",
      "CD68               30.1%    65.9%\n",
      "CD163              13.4%    79.7%\n",
      "CD38                2.2%    76.7%\n",
      "CD79a               0.5%    83.4%\n",
      "CD209               0.5%    65.5%\n",
      "CD99               38.8%    62.3%\n",
      "FOXP3               0.1%    84.9%\n",
      "PD-L1              10.7%    71.4%\n",
      "Ki67                0.7%    76.3%\n",
      "PD-1                1.1%    79.9%\n",
      "Vimentin           54.5%    51.4%\n",
      "CD99               38.8%    62.3%\n",
      "CD3e                5.8%    74.6%\n",
      "SMA                 0.8%    47.1%\n",
      "IDO1                1.7%    72.5%\n",
      "INS                 0.4%    68.5%\n",
      "Ker8-18            27.2%    73.0%\n",
      "iNOS                0.1%    85.7%\n",
      "M2Gal3             46.2%    55.7%\n",
      "B3TUBB              1.5%    72.2%\n",
      "PCNA                4.6%    84.1%\n",
      "Granzyme B          3.2%    78.5%\n",
      "HLA-A              48.8%    49.1%\n",
      "VISTA               4.4%    71.9%\n",
      "SST                 0.1%    77.1%\n",
      "TCF-1               6.7%    64.6%\n",
      "TOX                 1.6%    88.8%\n",
      "Caveolin            6.0%    34.8%\n",
      "ICOS                1.9%    66.5%\n",
      "EpCAM              16.5%    77.9%\n",
      "Keratin 5           0.3%    76.2%\n",
      "GCG                 0.1%    61.9%\n",
      "Beta-actin         64.8%    55.2%\n",
      "Bcl-2               5.8%    82.8%\n",
      "MPO                 0.1%    75.6%\n",
      "Iba1               17.3%    53.7%\n",
      "SOX2                0.0%    86.8%\n",
      "TP63                0.0%    68.6%\n",
      "\n",
      "======================================================================\n",
      "SUCCESS: Detection-aware normalization complete!\n",
      "- Protein: Using GATED data (value > 0 = detected)\n",
      "- RNA: Using count > 0 as detection\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Normalize shared features\n# \n# Protein: GATED data is already z-scored (zero-mean, unit variance)\n# RNA: Apply log1p then z-score to match\n\nfrom scipy.stats import rankdata, norm, zscore\nimport os\n\n# ============================================================\n# LOAD DATA\n# ============================================================\nprint(\"=\"*70)\nprint(\"LOADING DATA\")\nprint(\"=\"*70)\n\n# Load gated protein data (already z-scored)\ngated_codex_path = 'data/6551_leiden_umap.h5ad'\nprotein_gated = sc.read_h5ad(gated_codex_path)\nprint(f\"Gated Protein: {protein_gated.shape[0]:,} cells, {protein_gated.shape[1]} markers\")\nprint(f\"  Mean: {protein_gated.X.mean():.3f}, Std: {protein_gated.X.std():.3f}\")\nprint(f\"  (Confirmed: zero-mean, unit variance)\")\n\n# Find shared features\nconversion = pd.read_csv('data/protein_gene_conversion.csv')\nrna_genes = set(rna_adata.var_names)\nprotein_markers = set(protein_gated.var_names)\n\nshared = []\nfor _, row in conversion.iterrows():\n    prot = row['Protein name']\n    rna = str(row['RNA name'])\n    if pd.isna(prot) or prot not in protein_markers:\n        continue\n    if rna.startswith('Ignore'):\n        continue\n    for gene in [g.strip() for g in rna.split('/')]:\n        if gene in rna_genes:\n            shared.append((gene, prot))\n            break\n\nrna_protein_correspondence = np.array(shared)\nprint(f\"\\n",
    "Shared features: {len(shared)}\")\n\n# Subset to shared features\nrna_shared_adata = rna_adata[:, [s[0] for s in shared]].copy()\nprotein_shared_adata = protein_gated[:, [s[1] for s in shared]].copy()\n\nprint(f\"  RNA: {rna_shared_adata.shape}\")\nprint(f\"  Protein: {protein_shared_adata.shape}\")\n\n# ============================================================\n# GET RAW ARRAYS\n# ============================================================\n\nrna_shared_raw = rna_shared_adata.X.copy()\nif sparse.issparse(rna_shared_raw):\n    rna_shared_raw = rna_shared_raw.toarray()\n\nprotein_shared_raw = protein_shared_adata.X.copy()\nif sparse.issparse(protein_shared_raw):\n    protein_shared_raw = protein_shared_raw.toarray()\n\n# ============================================================\n# NORMALIZE RNA: log1p -> z-score (to match protein)\n# ============================================================\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"RNA NORMALIZATION: log1p -> z-score\")\nprint(\"=\"*70)\n\n# Library size normalization\nsc.pp.normalize_total(rna_shared_adata, target_sum=1e4)\n\n# Log1p\nsc.pp.log1p(rna_shared_adata)\nrna_after_log = rna_shared_adata.X.copy()\nif sparse.issparse(rna_after_log):\n    rna_after_log = rna_after_log.toarray()\n\nprint(f\"After log1p - mean: {rna_after_log.mean():.3f}, std: {rna_after_log.std():.3f}\")\n\n# Z-score per feature (to match protein's zero-mean unit variance)\nrna_zscore = np.zeros_like(rna_after_log)\nfor j in range(rna_after_log.shape[1]):\n    col = rna_after_log[:, j]\n    if col.std() > 0:\n        rna_zscore[:, j] = (col - col.mean()) / col.std()\n    else:\n        rna_zscore[:, j] = 0\n\nprint(f\"After z-score - mean: {rna_zscore.mean():.3f}, std: {rna_zscore.std():.3f}\")\n\n# ============================================================\n# PROTEIN: Already z-scored, use as-is\n# ============================================================\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"PROTEIN: Already z-scored (use as-is)\")\nprint(\"=\"*70)\n\nprotein_zscore = protein_shared_raw.copy()\nprint(f\"Protein - mean: {protein_zscore.mean():.3f}, std: {protein_zscore.std():.3f}\")\n\n# ============================================================\n# STORE RESULTS\n# ============================================================\n\n# Final normalized arrays\nrna_shared = rna_zscore\nprotein_shared = protein_zscore\n\n# For compatibility with downstream code\nrna_shared_after_log = rna_after_log\nrna_shared_after_scale = rna_zscore\nprotein_shared_after_arcsinh = protein_zscore\nprotein_shared_after = protein_zscore\n\n# Update AnnData objects\nrna_shared_adata.X = rna_zscore.astype(np.float32)\nprotein_shared_adata.X = protein_zscore.astype(np.float32)\n\n# ============================================================\n# VERIFICATION\n# ============================================================\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"VERIFICATION\")\nprint(\"=\"*70)\n\nprint(f\"\\n",
    "{'Modality':<10} {'Cells':>12} {'Features':>10} {'Mean':>10} {'Std':>10}\")\nprint(\"-\"*55)\nprint(f\"{'RNA':<10} {rna_shared.shape[0]:>12,} {rna_shared.shape[1]:>10} {rna_shared.mean():>10.3f} {rna_shared.std():>10.3f}\")\nprint(f\"{'Protein':<10} {protein_shared.shape[0]:>12,} {protein_shared.shape[1]:>10} {protein_shared.mean():>10.3f} {protein_shared.std():>10.3f}\")\n\n# Per-feature stats\nprint(\"\\n",
    "Per-feature statistics:\")\nprint(f\"{'Feature':<15} {'RNA mean':>10} {'RNA std':>10} {'Prot mean':>10} {'Prot std':>10}\")\nprint(\"-\"*60)\nfor i, (rna_name, prot_name) in enumerate(rna_protein_correspondence[:10]):\n    r_mean, r_std = rna_shared[:, i].mean(), rna_shared[:, i].std()\n    p_mean, p_std = protein_shared[:, i].mean(), protein_shared[:, i].std()\n    print(f\"{prot_name[:14]:<15} {r_mean:>10.3f} {r_std:>10.3f} {p_mean:>10.3f} {p_std:>10.3f}\")\nprint(\"...\")\n\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"SUCCESS: Both modalities are now z-scored (zero-mean, unit variance)\")\nprint(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CODEX data for diagnostic cells (background detection analysis)\n",
    "# This requires the original TSV file from preprocessing\n",
    "\n",
    "import os\n",
    "codex_tsv_path = 'data/6551_cells.csv'\n",
    "\n",
    "if os.path.exists(codex_tsv_path):\n",
    "    codex_df = pd.read_csv(codex_tsv_path)\n",
    "    print(f\"Loaded raw CODEX data: {codex_df.shape}\")\n",
    "    print(f\"Columns: {len(codex_df.columns)}\")\n",
    "    CODEX_RAW_AVAILABLE = True\n",
    "else:\n",
    "    print(f\"Raw CODEX file not found at: {codex_tsv_path}\")\n",
    "    print(\"Skipping background detection diagnostic cells.\")\n",
    "    print(\"These cells are optional - the integration will work without them.\")\n",
    "    codex_df = None\n",
    "    CODEX_RAW_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Background detection using Cell Median\n",
    "# Skip if raw CODEX data not available\n",
    "\n",
    "if not CODEX_RAW_AVAILABLE:\n",
    "    print(\"Skipping: Raw CODEX data not available (run from preprocessing to analyze)\")\n",
    "else:\n",
    "    # Diagnostic: Background detection using Cell Median\n",
    "    # For high-background CODEX data, we need DATA-DRIVEN per-marker thresholds\n",
    "    # instead of assuming background = 0\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PROTEIN BACKGROUND DETECTION (using Cell Median with per-marker thresholds)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    protein_names = list(rna_protein_correspondence[:, 1])\n",
    "    n_features = len(protein_names)\n",
    "    \n",
    "    # We need the median values from the original CODEX dataframe\n",
    "    # Build mapping from protein name to column\n",
    "    protein_to_median_col = {}\n",
    "    for prot in protein_names:\n",
    "        # Find the matching column in codex_df\n",
    "        for col in codex_df.columns:\n",
    "            if prot in col and 'Cell:' in col and 'Median' in col:\n",
    "                protein_to_median_col[prot] = col\n",
    "                break\n",
    "    \n",
    "    print(f\"Analyzing {n_features} shared protein features...\")\n",
    "    print(\"Using DATA-DRIVEN per-marker thresholds based on 25th percentile\")\n",
    "    print(\"Formula: threshold = max(p25 * 0.5, 0.5)\")\n",
    "    print(\"  - For CyTOF-like data (p25~0): threshold ~0.5 (original behavior)\")\n",
    "    print(\"  - For high-background CODEX (p25~150): threshold ~75\")\n",
    "    \n",
    "    # Store detection info\n",
    "    detection_stats = {}\n",
    "    marker_thresholds = {}  # Store per-marker thresholds\n",
    "    \n",
    "    # Create figure: each protein gets a panel with Mean and Median histograms\n",
    "    plots_per_row = 4\n",
    "    n_feature_rows = int(np.ceil(n_features / plots_per_row))\n",
    "    fig, axes = plt.subplots(n_feature_rows, plots_per_row, figsize=(16, 3.5*n_feature_rows))\n",
    "    if n_feature_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(f\"{'Protein':<12} {'p25':>8} {'threshold':>10} {'Below':>12} {'Above':>12} {'% Detected':>12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        prot_name = protein_names[i]\n",
    "        ax = axes[i]\n",
    "        \n",
    "        if prot_name in protein_to_median_col:\n",
    "            median_col = protein_to_median_col[prot_name]\n",
    "            median_vals = codex_df[median_col].values\n",
    "            \n",
    "            # Get corresponding mean column for comparison\n",
    "            mean_col = median_col.replace('Median', 'Mean')\n",
    "            mean_vals = codex_df[mean_col].values if mean_col in codex_df.columns else None\n",
    "            \n",
    "            # DATA-DRIVEN threshold based on 25th percentile\n",
    "            # This adapts to the data scale:\n",
    "            # - CyTOF (low values, p25~0): threshold ~0.5 (original behavior)\n",
    "            # - CODEX with high background (p25~100-200): threshold ~50-100\n",
    "            p25 = np.percentile(median_vals, 25)\n",
    "            threshold = max(p25 * 0.5, 0.5)  # At least 0.5 for numerical stability\n",
    "            marker_thresholds[prot_name] = threshold\n",
    "            \n",
    "            # Classification: Below threshold is background\n",
    "            is_background = median_vals <= threshold\n",
    "            is_detected = ~is_background\n",
    "            \n",
    "            n_background = is_background.sum()\n",
    "            n_detected = is_detected.sum()\n",
    "            pct_detected = 100 * n_detected / len(median_vals)\n",
    "            \n",
    "            detection_stats[prot_name] = {\n",
    "                'n_background': n_background,\n",
    "                'n_detected': n_detected,\n",
    "                'pct_detected': pct_detected,\n",
    "                'threshold': threshold,\n",
    "                'p25': p25\n",
    "            }\n",
    "            \n",
    "            print(f\"{prot_name:<12} {p25:>8.1f} {threshold:>10.1f} {n_background:>12,} {n_detected:>12,} {pct_detected:>11.1f}%\")\n",
    "            \n",
    "            # Plot: Histogram of Median values\n",
    "            # Zoom to show distribution around threshold\n",
    "            max_plot = max(threshold * 3, 50)\n",
    "            median_zoomed = median_vals[median_vals <= max_plot]\n",
    "            bins = np.linspace(0, max_plot, 50)\n",
    "            ax.hist(median_zoomed, bins=bins, alpha=0.7, \n",
    "                    color='darkorange', edgecolor='white', linewidth=0.5)\n",
    "            ax.axvline(x=threshold, color='green', linestyle='--', linewidth=2, \n",
    "                       label=f'threshold={threshold:.0f}')\n",
    "            ax.set_title(f'{prot_name} ({pct_detected:.0f}% det)', fontsize=10)\n",
    "            ax.set_xlabel('Cell Median')\n",
    "            ax.legend(fontsize=7)\n",
    "        else:\n",
    "            print(f\"{prot_name:<12} {'column not found':>56}\")\n",
    "            ax.set_visible(False)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for j in range(n_features, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Cell Median Distributions with per-marker thresholds', fontsize=12, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    avg_threshold = np.mean(list(marker_thresholds.values()))\n",
    "    avg_detection = np.mean([s['pct_detected'] for s in detection_stats.values()])\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Background criterion: Cell Median <= per-marker threshold\")\n",
    "    print(f\"Formula: threshold = max(25th_percentile * 0.5, 0.5)\")\n",
    "    print(f\"Average threshold: {avg_threshold:.1f}\")\n",
    "    print(f\"Average detection rate: {avg_detection:.1f}%\")\n",
    "    print(f\"This adapts to high-background CODEX data where 'zero' isn't meaningful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DETECTION-AWARE normalization\n",
    "# Skip if raw CODEX data not available\n",
    "\n",
    "if not CODEX_RAW_AVAILABLE:\n",
    "    print(\"Skipping: Raw CODEX data not available (run from preprocessing to analyze)\")\n",
    "else:\n",
    "    # Visualize DETECTION-AWARE normalization\n",
    "    # Updated to use Cell Median-based detection with DATA-DRIVEN per-marker thresholds\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
    "    \n",
    "    feature_names = list(rna_protein_correspondence[:, 0])\n",
    "    protein_names = list(rna_protein_correspondence[:, 1])\n",
    "    n_features = rna_shared_raw.shape[1]\n",
    "    \n",
    "    # Define x_pos and width for bar charts\n",
    "    x_pos = np.arange(n_features)\n",
    "    width = 0.35\n",
    "    \n",
    "    # Pick a feature with moderate expression\n",
    "    detection_rates_rna = [(rna_shared_raw[:, i] > 0).mean() for i in range(n_features)]\n",
    "    good_features = [i for i, d in enumerate(detection_rates_rna) if 0.2 < d < 0.8]\n",
    "    if good_features:\n",
    "        best_feat_idx = good_features[len(good_features)//2]\n",
    "    else:\n",
    "        best_feat_idx = np.argmax(detection_rates_rna)\n",
    "    feat_name = feature_names[best_feat_idx]\n",
    "    prot_name = protein_names[best_feat_idx]\n",
    "    \n",
    "    # Build protein detection rates from Cell Median with DATA-DRIVEN thresholds\n",
    "    protein_to_median_col = {}\n",
    "    for prot in protein_names:\n",
    "        for col in codex_df.columns:\n",
    "            if prot in col and 'Cell:' in col and 'Median' in col:\n",
    "                protein_to_median_col[prot] = col\n",
    "                break\n",
    "    \n",
    "    # Calculate per-marker thresholds: threshold = max(p25 * 0.5, 0.5)\n",
    "    marker_thresholds = {}\n",
    "    for pname in protein_names:\n",
    "        if pname in protein_to_median_col:\n",
    "            median_vals = codex_df[protein_to_median_col[pname]].values\n",
    "            p25 = np.percentile(median_vals, 25)\n",
    "            marker_thresholds[pname] = max(p25 * 0.5, 0.5)\n",
    "        else:\n",
    "            marker_thresholds[pname] = 0.5  # Default fallback\n",
    "    \n",
    "    # Calculate detection rates: RNA uses >0, Protein uses Cell Median > per-marker threshold\n",
    "    rna_det_rates = [(rna_shared_raw[:, i] > 0).mean() * 100 for i in range(n_features)]\n",
    "    prot_det_rates = []\n",
    "    for i, pname in enumerate(protein_names):\n",
    "        if pname in protein_to_median_col:\n",
    "            median_vals = codex_df[protein_to_median_col[pname]].values\n",
    "            threshold = marker_thresholds[pname]\n",
    "            prot_det_rates.append((median_vals > threshold).mean() * 100)\n",
    "        else:\n",
    "            # Fallback to raw >0\n",
    "            prot_det_rates.append((protein_shared_raw[:, i] > 0).mean() * 100)\n",
    "    \n",
    "    rna_det = rna_det_rates[best_feat_idx]\n",
    "    prot_det = prot_det_rates[best_feat_idx]\n",
    "    prot_threshold = marker_thresholds.get(prot_name, 0.5)\n",
    "    \n",
    "    print(f\"Example feature: {feat_name} / {prot_name}\")\n",
    "    print(f\"  RNA detection: {rna_det:.1f}% ({int(rna_det/100 * rna_shared_raw.shape[0]):,} cells)\")\n",
    "    print(f\"  Protein detection (Cell Median > {prot_threshold:.0f}): {prot_det:.1f}% ({int(prot_det/100 * protein_shared_raw.shape[0]):,} cells)\")\n",
    "    \n",
    "    ZERO_VALUE = -2.5  # Must match value used in normalization\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 1: RNA transformation pipeline\n",
    "    # ============================================================\n",
    "    ax = axes[0, 0]\n",
    "    raw_vals = rna_shared_raw[:, best_feat_idx]\n",
    "    ax.hist(raw_vals, bins=50, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "    ax.set_title(f'RNA: Raw Counts\\n(zeros: {(raw_vals==0).mean()*100:.0f}%)', fontsize=10)\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Cells')\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    log_vals = rna_shared_after_log[:, best_feat_idx]\n",
    "    zeros = log_vals == 0\n",
    "    nonzeros = ~zeros\n",
    "    ax.hist(log_vals[nonzeros], bins=30, alpha=0.7, color='coral', edgecolor='white', label=f'Non-zero ({nonzeros.sum():,})')\n",
    "    if zeros.sum() > 0:\n",
    "        ax.axvline(x=0, color='gray', linestyle='--', linewidth=2, label=f'Zeros ({zeros.sum():,})')\n",
    "    ax.set_title('RNA: After log1p\\n(zeros at 0)', fontsize=10)\n",
    "    ax.set_xlabel('log1p(count)')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[0, 2]\n",
    "    norm_vals = rna_shared_after_scale[:, best_feat_idx]\n",
    "    nonzero_mask = norm_vals > ZERO_VALUE + 0.1\n",
    "    ax.hist(norm_vals[nonzero_mask], bins=30, alpha=0.7, color='forestgreen', edgecolor='white', \n",
    "            label=f'Detected ({nonzero_mask.sum():,})')\n",
    "    ax.axvline(x=ZERO_VALUE, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Not detected ({(~nonzero_mask).sum():,})')\n",
    "    ax.set_title('RNA: Detection-Aware Normalized\\n(zeros \u2192 fixed value)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[0, 3]\n",
    "    ax.axis('off')\n",
    "    ax.text(0.1, 0.85, 'RNA Pipeline:', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.70, '1. normalize_total (library size)', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.58, '2. log1p (variance stabilization)', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.46, '3. Detection-aware normalization:', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.34, '\u2022 Non-zeros \u2192 rank \u2192 normal quantiles', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.22, f'\u2022 Zeros \u2192 fixed value ({ZERO_VALUE})', fontsize=9, transform=ax.transAxes)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 2: Protein transformation pipeline\n",
    "    # ============================================================\n",
    "    ax = axes[1, 0]\n",
    "    raw_vals = protein_shared_raw[:, best_feat_idx]\n",
    "    # Show Cell Median-based detection with per-marker threshold\n",
    "    if prot_name in protein_to_median_col:\n",
    "        median_vals = codex_df[protein_to_median_col[prot_name]].values\n",
    "        threshold = marker_thresholds[prot_name]\n",
    "        is_bg = median_vals <= threshold\n",
    "        pct_bg = is_bg.mean() * 100\n",
    "    else:\n",
    "        pct_bg = (raw_vals == 0).mean() * 100\n",
    "    ax.hist(raw_vals, bins=50, alpha=0.7, color='darkorange', edgecolor='white')\n",
    "    ax.set_title(f'Protein: Raw MFI\\n(background: {pct_bg:.0f}% via Cell Median)', fontsize=10)\n",
    "    ax.set_xlabel('Mean Fluorescence Intensity')\n",
    "    ax.set_ylabel('Cells')\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    arcsinh_vals = protein_shared_after_arcsinh[:, best_feat_idx]\n",
    "    # Use Cell Median with per-marker threshold for zero classification\n",
    "    if prot_name in protein_to_median_col:\n",
    "        median_vals = codex_df[protein_to_median_col[prot_name]].values\n",
    "        threshold = marker_thresholds[prot_name]\n",
    "        zeros = median_vals <= threshold\n",
    "    else:\n",
    "        zeros = protein_shared_raw[:, best_feat_idx] == 0\n",
    "    nonzeros = ~zeros\n",
    "    ax.hist(arcsinh_vals[nonzeros], bins=30, alpha=0.7, color='purple', edgecolor='white', label=f'Detected ({nonzeros.sum():,})')\n",
    "    if zeros.sum() > 0:\n",
    "        # Show background cells as a separate histogram\n",
    "        ax.hist(arcsinh_vals[zeros], bins=30, alpha=0.5, color='gray', edgecolor='white', label=f'Background ({zeros.sum():,})')\n",
    "    ax.set_title(f'Protein: After arcsinh(x/cofactor)\\n(per-marker cofactors)', fontsize=10)\n",
    "    ax.set_xlabel('arcsinh(MFI/cofactor)')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[1, 2]\n",
    "    norm_vals = protein_shared_after[:, best_feat_idx]\n",
    "    nonzero_mask = norm_vals > ZERO_VALUE + 0.1\n",
    "    ax.hist(norm_vals[nonzero_mask], bins=30, alpha=0.7, color='forestgreen', edgecolor='white',\n",
    "            label=f'Detected ({nonzero_mask.sum():,})')\n",
    "    ax.axvline(x=ZERO_VALUE, color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Not detected ({(~nonzero_mask).sum():,})')\n",
    "    ax.set_title('Protein: Detection-Aware Normalized\\n(background \u2192 fixed value)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    ax = axes[1, 3]\n",
    "    ax.axis('off')\n",
    "    ax.text(0.1, 0.85, 'Protein Pipeline:', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.70, '1. arcsinh(x/cofactor) per marker', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.58, '\u2022 Cofactor = p25 * 2 (data-driven)', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.1, 0.46, '2. Detection via Cell Median:', fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.34, '\u2022 Threshold = p25 * 0.5 (per marker)', fontsize=9, transform=ax.transAxes)\n",
    "    ax.text(0.15, 0.22, '\u2022 Below threshold \u2192 background', fontsize=9, transform=ax.transAxes)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 3: Distribution comparison - NON-ZERO VALUES ONLY\n",
    "    # ============================================================\n",
    "    \n",
    "    # Get non-zero values only\n",
    "    rna_nonzero = rna_shared_after_scale[rna_shared_after_scale > ZERO_VALUE + 0.1]\n",
    "    prot_nonzero = protein_shared_after[protein_shared_after > ZERO_VALUE + 0.1]\n",
    "    \n",
    "    ax = axes[2, 0]\n",
    "    bins = np.linspace(-3, 3, 50)\n",
    "    ax.hist(rna_nonzero, bins=bins, alpha=0.6, density=True, label=f'RNA ({len(rna_nonzero):,})', color='steelblue')\n",
    "    ax.hist(prot_nonzero, bins=bins, alpha=0.6, density=True, label=f'Protein ({len(prot_nonzero):,})', color='darkorange')\n",
    "    ax.set_title('Non-Zero Values Only\\n(should overlap well)', fontsize=10)\n",
    "    ax.set_xlabel('Normalized value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    # Box plot of non-zero values\n",
    "    ax = axes[2, 1]\n",
    "    rna_sample = rna_nonzero[::max(1, len(rna_nonzero)//5000)]\n",
    "    prot_sample = prot_nonzero[::max(1, len(prot_nonzero)//5000)]\n",
    "    bp = ax.boxplot([rna_sample, prot_sample], labels=['RNA', 'Protein'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('steelblue')\n",
    "    bp['boxes'][1].set_facecolor('darkorange')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylabel('Normalized value (non-zero only)')\n",
    "    ax.set_title('Overall Distribution (Non-Zero Values)', fontsize=10)\n",
    "    \n",
    "    # Per-feature mean of NON-ZERO values (should be ~0)\n",
    "    ax = axes[2, 2]\n",
    "    rna_means_nz = []\n",
    "    prot_means_nz = []\n",
    "    for i in range(n_features):\n",
    "        rna_nz = rna_shared_after_scale[:, i][rna_shared_after_scale[:, i] > ZERO_VALUE + 0.1]\n",
    "        prot_nz = protein_shared_after[:, i][protein_shared_after[:, i] > ZERO_VALUE + 0.1]\n",
    "        rna_means_nz.append(rna_nz.mean() if len(rna_nz) > 0 else 0)\n",
    "        prot_means_nz.append(prot_nz.mean() if len(prot_nz) > 0 else 0)\n",
    "    \n",
    "    ax.bar(x_pos - width/2, rna_means_nz, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_means_nz, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Mean (non-zero only)')\n",
    "    ax.set_title('Per-Feature Mean (Non-Zero Values)', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    \n",
    "    # Per-feature std of NON-ZERO values (should be ~1)\n",
    "    ax = axes[2, 3]\n",
    "    rna_stds_nz = []\n",
    "    prot_stds_nz = []\n",
    "    for i in range(n_features):\n",
    "        rna_nz = rna_shared_after_scale[:, i][rna_shared_after_scale[:, i] > ZERO_VALUE + 0.1]\n",
    "        prot_nz = protein_shared_after[:, i][protein_shared_after[:, i] > ZERO_VALUE + 0.1]\n",
    "        rna_stds_nz.append(rna_nz.std() if len(rna_nz) > 1 else 0)\n",
    "        prot_stds_nz.append(prot_nz.std() if len(prot_nz) > 1 else 0)\n",
    "    \n",
    "    ax.bar(x_pos - width/2, rna_stds_nz, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_stds_nz, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.axhline(y=1, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Std Dev (non-zero only)')\n",
    "    ax.set_title('Per-Feature Std Dev (Non-Zero Values)', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Row 4: Detection rates and summary\n",
    "    # ============================================================\n",
    "    \n",
    "    # Detection rate comparison\n",
    "    ax = axes[3, 0]\n",
    "    ax.bar(x_pos - width/2, rna_det_rates, width, label='RNA', alpha=0.8, color='steelblue')\n",
    "    ax.bar(x_pos + width/2, prot_det_rates, width, label='Protein', alpha=0.8, color='darkorange')\n",
    "    ax.set_xlabel('Feature index')\n",
    "    ax.set_ylabel('Detection rate (%)')\n",
    "    ax.set_title('Per-Feature Detection Rate', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f[:6] for f in feature_names], rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    # Detection rate scatter\n",
    "    ax = axes[3, 1]\n",
    "    ax.scatter(rna_det_rates, prot_det_rates, s=50, alpha=0.7)\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        ax.annotate(fname[:6], (rna_det_rates[i], prot_det_rates[i]), fontsize=7)\n",
    "    ax.plot([0, 100], [0, 100], 'r--', alpha=0.5)\n",
    "    ax.set_xlabel('RNA detection rate (%)')\n",
    "    ax.set_ylabel('Protein detection rate (%)')\n",
    "    ax.set_title('Detection Rate Comparison', fontsize=10)\n",
    "    \n",
    "    # Empty placeholder\n",
    "    ax = axes[3, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Summary text\n",
    "    ax = axes[3, 3]\n",
    "    ax.axis('off')\n",
    "    avg_threshold = np.mean(list(marker_thresholds.values()))\n",
    "    summary = f\"\"\"DETECTION-AWARE NORMALIZATION SUMMARY\n",
    "    {\"=\"*45}\n",
    "    \n",
    "    Cell counts:\n",
    "      RNA:     {rna_shared_raw.shape[0]:>10,} cells\n",
    "      Protein: {protein_shared_raw.shape[0]:>10,} cells\n",
    "    \n",
    "    Detection method:\n",
    "      RNA: count > 0\n",
    "      Protein: Cell Median > per-marker threshold\n",
    "      Average threshold: {avg_threshold:.1f}\n",
    "    \n",
    "    Non-zero values after normalization:\n",
    "      RNA:     mean={np.mean(rna_means_nz):.3f}, std={np.mean(rna_stds_nz):.3f}\n",
    "      Protein: mean={np.mean(prot_means_nz):.3f}, std={np.mean(prot_stds_nz):.3f}\n",
    "    \n",
    "    Zero handling:\n",
    "      All \"not detected\" set to: {ZERO_VALUE}\n",
    "      (Below all detected values)\n",
    "    \"\"\"\n",
    "    ax.text(0.0, 0.95, summary, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Detection-Aware Normalization Results', fontsize=14, y=1.01)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KEY INSIGHT:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"RNA detection: count > 0\")\n",
    "    print(f\"Protein detection: Cell Median > per-marker threshold (avg: {avg_threshold:.1f})\")\n",
    "    print(\"This ensures 'not detected' is biologically meaningful in both modalities.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "rna_shared = rna_shared_adata.X.copy()\n",
    "if sparse.issparse(rna_shared):\n",
    "    rna_shared = rna_shared.toarray()\n",
    "    \n",
    "protein_shared = protein_shared_adata.X.copy()\n",
    "if sparse.issparse(protein_shared):\n",
    "    protein_shared = protein_shared.toarray()\n",
    "\n",
    "# Remove zero-variance features\n",
    "rna_std = rna_shared.std(axis=0)\n",
    "prot_std = protein_shared.std(axis=0)\n",
    "valid_mask = (rna_std > 1e-6) & (prot_std > 1e-6)\n",
    "\n",
    "if not valid_mask.all():\n",
    "    print(f\"Removing {(~valid_mask).sum()} zero-variance features\")\n",
    "    rna_shared = rna_shared[:, valid_mask]\n",
    "    protein_shared = protein_shared[:, valid_mask]\n",
    "    # Update correspondence\n",
    "    rna_protein_correspondence = rna_protein_correspondence[valid_mask]\n",
    "\n",
    "print(f\"\\nFinal shared arrays:\")\n",
    "print(f\"  rna_shared: {rna_shared.shape}\")\n",
    "print(f\"  protein_shared: {protein_shared.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze shared feature quality\n",
    "print(\"=\" * 60)\n",
    "print(\"SHARED FEATURE QUALITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get raw counts for analysis (before normalization)\n",
    "rna_raw_shared = rna_adata[:, rna_protein_correspondence[:, 0]].X\n",
    "if sparse.issparse(rna_raw_shared):\n",
    "    rna_raw_shared = rna_raw_shared.toarray()\n",
    "\n",
    "protein_raw_shared = protein_adata[:, rna_protein_correspondence[:, 1]].X\n",
    "if sparse.issparse(protein_raw_shared):\n",
    "    protein_raw_shared = protein_raw_shared.toarray()\n",
    "\n",
    "# Calculate statistics for each feature\n",
    "feature_stats = []\n",
    "for i, (rna_gene, prot_marker) in enumerate(rna_protein_correspondence):\n",
    "    rna_col = rna_raw_shared[:, i]\n",
    "    prot_col = protein_raw_shared[:, i]\n",
    "    \n",
    "    # % cells expressing\n",
    "    rna_pct_expressing = (rna_col > 0).sum() / len(rna_col) * 100\n",
    "    prot_pct_expressing = (prot_col > 0).sum() / len(prot_col) * 100\n",
    "    \n",
    "    feature_stats.append({\n",
    "        'RNA name': rna_gene,\n",
    "        'Protein': prot_marker,\n",
    "        'RNA_%_expressing': rna_pct_expressing,\n",
    "        'Prot_%_expressing': prot_pct_expressing,\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(feature_stats)\n",
    "stats_df = stats_df.sort_values('RNA_%_expressing', ascending=True)\n",
    "\n",
    "print(\"\\nFeature-by-feature statistics (sorted by RNA detection rate):\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY:\")\n",
    "avg_rna_detection = stats_df['RNA_%_expressing'].mean()\n",
    "avg_prot_detection = stats_df['Prot_%_expressing'].mean()\n",
    "print(f\"  Average RNA detection rate: {avg_rna_detection:.1f}% of cells\")\n",
    "print(f\"  Average Protein detection rate: {avg_prot_detection:.1f}% of cells\")\n",
    "\n",
    "# Warning for sparse features\n",
    "rare_features = stats_df[stats_df['RNA_%_expressing'] < 10]\n",
    "if len(rare_features) > 0:\n",
    "    print(f\"\\n  NOTE: {len(rare_features)} features detected in <10% of RNA cells\")\n",
    "    print(\"  These provide weaker signal for matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein active - use all markers (except DAPI)\n",
    "protein_markers_active = [m for m in protein_adata.var_names if m != 'DAPI']\n",
    "protein_adata_active = protein_adata[:, protein_markers_active].copy()\n",
    "\n",
    "# Scale if needed\n",
    "prot_mean = protein_adata_active.X.mean()\n",
    "if abs(prot_mean) > 0.1:\n",
    "    sc.pp.scale(protein_adata_active)\n",
    "    \n",
    "print(f\"Protein active: {protein_adata_active.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numpy arrays\n",
    "rna_active = rna_adata.X.copy()\n",
    "if sparse.issparse(rna_active):\n",
    "    rna_active = rna_active.toarray()\n",
    "\n",
    "protein_active = protein_adata_active.X.copy()\n",
    "if sparse.issparse(protein_active):\n",
    "    protein_active = protein_active.toarray()\n",
    "\n",
    "# Remove zero-variance features\n",
    "rna_active = rna_active[:, rna_active.std(axis=0) > 1e-6]\n",
    "protein_active = protein_active[:, protein_active.std(axis=0) > 1e-6]\n",
    "\n",
    "print(f\"\\nFinal active arrays:\")\n",
    "print(f\"  rna_active (HVGs): {rna_active.shape}\")\n",
    "print(f\"  protein_active: {protein_active.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL VALIDATION: Check array dimensions match\n",
    "print(\"=\" * 50)\n",
    "print(\"DIMENSION VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RNA shared cells:     {rna_shared.shape[0]}\")\n",
    "print(f\"RNA active cells:     {rna_active.shape[0]}\")\n",
    "print(f\"Protein shared cells: {protein_shared.shape[0]}\")\n",
    "print(f\"Protein active cells: {protein_active.shape[0]}\")\n",
    "print()\n",
    "\n",
    "assert rna_shared.shape[0] == rna_active.shape[0], \\\n",
    "    f\"RNA mismatch: shared={rna_shared.shape[0]}, active={rna_active.shape[0]}\"\n",
    "assert protein_shared.shape[0] == protein_active.shape[0], \\\n",
    "    f\"Protein mismatch: shared={protein_shared.shape[0]}, active={protein_active.shape[0]}\"\n",
    "assert rna_shared.shape[1] == protein_shared.shape[1], \\\n",
    "    f\"Shared feature mismatch: RNA={rna_shared.shape[1]}, Protein={protein_shared.shape[1]}\"\n",
    "\n",
    "print(\"All dimensions validated!\")\n",
    "print(f\"\\nIntegrating {rna_active.shape[0]} RNA cells with {protein_active.shape[0]} protein cells\")\n",
    "print(f\"Using {rna_shared.shape[1]} shared features for initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint for cross-modal integration\n",
    "# This allows skipping the MARIO section and going directly to MaxFuse\n",
    "\n",
    "checkpoint_dir = 'results/2_integration'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save arrays needed for MaxFuse\n",
    "np.save(f'{checkpoint_dir}/checkpoint_rna_shared.npy', rna_shared)\n",
    "np.save(f'{checkpoint_dir}/checkpoint_protein_shared.npy', protein_shared)\n",
    "np.save(f'{checkpoint_dir}/checkpoint_rna_active.npy', rna_active)\n",
    "np.save(f'{checkpoint_dir}/checkpoint_protein_active.npy', protein_active)\n",
    "\n",
    "# Save correspondence\n",
    "correspondence_checkpoint = pd.DataFrame(\n",
    "    rna_protein_correspondence, \n",
    "    columns=['rna_gene', 'protein_marker']\n",
    ")\n",
    "correspondence_checkpoint.to_csv(f'{checkpoint_dir}/checkpoint_correspondence.csv', index=False)\n",
    "\n",
    "print(f'Checkpoint saved to {checkpoint_dir}/')\n",
    "print(f'  - checkpoint_rna_shared.npy: {rna_shared.shape}')\n",
    "print(f'  - checkpoint_protein_shared.npy: {protein_shared.shape}')\n",
    "print(f'  - checkpoint_rna_active.npy: {rna_active.shape}')\n",
    "print(f'  - checkpoint_protein_active.npy: {protein_active.shape}')\n",
    "print(f'  - checkpoint_correspondence.csv')\n",
    "print(f'\\nYou can now skip to MaxFuse Integration (Step 7) if desired.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MARIO Integration (Optional - Same-Modality Data Only)\n",
    "\n",
    "**IMPORTANT**: MARIO is designed for **same-modality integration** (e.g., protein-protein).\n",
    "\n",
    "## When to Use MARIO\n",
    "- Both datasets measure the **same biological quantity** (e.g., CITE-seq vs CyTOF)\n",
    "- Shared features are the **same measurements** by different technologies\n",
    "- Values should be **correlated but not identical** between modalities\n",
    "\n",
    "## When to Skip MARIO\n",
    "- **Cross-modal integration** (e.g., RNA-seq vs protein/CODEX) \u2192 **Skip to MaxFuse**\n",
    "- Shared features represent **different biological measurements** (mRNA vs protein)\n",
    "- Canonical correlations are all ~1.0 (indicates data incompatibility)\n",
    "\n",
    "## Current Data Type\n",
    "This notebook integrates **RNA-seq with CODEX protein data** - a cross-modal scenario.\n",
    "\n",
    "**Recommendation**: Skip this section and proceed to **MaxFuse Integration (Step 7)**.\n",
    "\n",
    "---\n",
    "\n",
    "If you still want to run MARIO (e.g., for comparison or same-modality data), continue below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: MARIO - Matchability Test (Pre-Integration Diagnostic)\n",
    "\n",
    "Before running integration, we test whether the two datasets have meaningful correspondence.\n",
    "MARIO uses random sign flips to create a null distribution and computes p-values.\n",
    "\n",
    "- **Low p-value** (< 0.05): Datasets are matchable\n",
    "- **High p-value** (> 0.05): No significant correspondence detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Check for and handle NaN/Inf values that may result from normalization of sparse features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and handle NaN/Inf values before MARIO\n",
    "# Detection-aware normalization can produce NaN for problematic features\n",
    "\n",
    "print(\"Checking for NaN/Inf values in shared arrays...\")\n",
    "print(f\"  rna_shared: NaN={np.isnan(rna_shared).sum()}, Inf={np.isinf(rna_shared).sum()}\")\n",
    "print(f\"  protein_shared: NaN={np.isnan(protein_shared).sum()}, Inf={np.isinf(protein_shared).sum()}\")\n",
    "\n",
    "# Replace NaN/Inf with 0 (these are likely failed normalizations for sparse features)\n",
    "if np.isnan(rna_shared).any() or np.isinf(rna_shared).any():\n",
    "    print(\"\\nCleaning rna_shared...\")\n",
    "    rna_shared = np.nan_to_num(rna_shared, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "if np.isnan(protein_shared).any() or np.isinf(protein_shared).any():\n",
    "    print(\"Cleaning protein_shared...\")\n",
    "    protein_shared = np.nan_to_num(protein_shared, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Also check active arrays\n",
    "print(f\"\\n  rna_active: NaN={np.isnan(rna_active).sum()}, Inf={np.isinf(rna_active).sum()}\")\n",
    "print(f\"  protein_active: NaN={np.isnan(protein_active).sum()}, Inf={np.isinf(protein_active).sum()}\")\n",
    "\n",
    "if np.isnan(rna_active).any() or np.isinf(rna_active).any():\n",
    "    print(\"\\nCleaning rna_active...\")\n",
    "    rna_active = np.nan_to_num(rna_active, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "if np.isnan(protein_active).any() or np.isinf(protein_active).any():\n",
    "    print(\"Cleaning protein_active...\")\n",
    "    protein_active = np.nan_to_num(protein_active, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"\\nArrays cleaned and ready for integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample for MARIO (MARIO requires n1 <= n2, and for speed we subsample)\n",
    "np.random.seed(42)\n",
    "\n",
    "# MARIO needs RNA (smaller) to be df1 and Protein (larger) to be df2\n",
    "n_rna_subsample = min(2000, rna_shared.shape[0])\n",
    "n_prot_subsample = min(10000, protein_shared.shape[0])\n",
    "\n",
    "rna_idx_subsample = np.random.choice(rna_shared.shape[0], n_rna_subsample, replace=False)\n",
    "prot_idx_subsample = np.random.choice(protein_shared.shape[0], n_prot_subsample, replace=False)\n",
    "\n",
    "# Create DataFrames with overlapping column names (required by MARIO)\n",
    "shared_feature_names = [f\"feat_{i}\" for i in range(rna_shared.shape[1])]\n",
    "\n",
    "# Extract subsamples and ensure no NaN values\n",
    "rna_subsample = rna_shared[rna_idx_subsample].copy()\n",
    "prot_subsample = protein_shared[prot_idx_subsample].copy()\n",
    "\n",
    "# Final NaN check on subsamples\n",
    "rna_subsample = np.nan_to_num(rna_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "prot_subsample = np.nan_to_num(prot_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "rna_df_mario = pd.DataFrame(rna_subsample, columns=shared_feature_names)\n",
    "prot_df_mario = pd.DataFrame(prot_subsample, columns=shared_feature_names)\n",
    "\n",
    "print(f\"MARIO subsample sizes:\")\n",
    "print(f\"  RNA: {rna_df_mario.shape}\")\n",
    "print(f\"  Protein: {prot_df_mario.shape}\")\n",
    "print(f\"  NaN in RNA df: {rna_df_mario.isna().sum().sum()}\")\n",
    "print(f\"  NaN in Protein df: {prot_df_mario.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MARIO\n",
    "mario = Mario(rna_df_mario, prot_df_mario, normalization=True)\n",
    "\n",
    "# Specify matching parameters\n",
    "# n_matched_per_cell: how many protein cells to match with each RNA cell\n",
    "n_matched = max(1, n_prot_subsample // n_rna_subsample)\n",
    "mario.specify_matching_params(n_matched_per_cell=n_matched)\n",
    "\n",
    "print(f\"Matching {n_matched} protein cells per RNA cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance using overlapping features\n",
    "n_ovlp_components = min(15, rna_shared.shape[1] - 1)\n",
    "dist_ovlp, singular_vals = mario.compute_dist_ovlp(n_components=n_ovlp_components)\n",
    "\n",
    "print(f\"Distance matrix shape: {dist_ovlp.shape}\")\n",
    "print(f\"Singular values: {singular_vals[:5]}...\")\n",
    "\n",
    "# Plot singular values\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(singular_vals, 'bo-')\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Singular Value')\n",
    "plt.title('MARIO: Singular Values of Stacked Overlap Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial matching using overlap features\n",
    "print(\"Finding initial matching using overlap features...\")\n",
    "matching_ovlp = mario.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "# Count matched cells\n",
    "n_matched_cells = sum(1 for m in matching_ovlp if len(m) > 0)\n",
    "print(f\"Matched {n_matched_cells}/{len(matching_ovlp)} RNA cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add active features (all HVGs) for refined matching\n",
    "# For MARIO, we need DataFrames with:\n",
    "# - Overlapping columns (shared features) with same names\n",
    "# - Non-overlapping columns (active features) with different names\n",
    "\n",
    "# RNA: shared features + active features\n",
    "rna_active_subsample = rna_active[rna_idx_subsample].copy()\n",
    "rna_active_subsample = np.nan_to_num(rna_active_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "rna_active_names = [f\"rna_feat_{i}\" for i in range(rna_active_subsample.shape[1])]\n",
    "\n",
    "rna_df_full = pd.DataFrame(\n",
    "    np.hstack([rna_subsample, rna_active_subsample]),\n",
    "    columns=shared_feature_names + rna_active_names\n",
    ")\n",
    "\n",
    "# Protein: shared features + active features\n",
    "prot_active_subsample = protein_active[prot_idx_subsample].copy()\n",
    "prot_active_subsample = np.nan_to_num(prot_active_subsample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "prot_active_names = [f\"prot_feat_{i}\" for i in range(prot_active_subsample.shape[1])]\n",
    "\n",
    "prot_df_full = pd.DataFrame(\n",
    "    np.hstack([prot_subsample, prot_active_subsample]),\n",
    "    columns=shared_feature_names + prot_active_names\n",
    ")\n",
    "\n",
    "print(f\"Full DataFrames for MARIO:\")\n",
    "print(f\"  RNA: {rna_df_full.shape} ({len(shared_feature_names)} shared + {len(rna_active_names)} active)\")\n",
    "print(f\"  Protein: {prot_df_full.shape} ({len(shared_feature_names)} shared + {len(prot_active_names)} active)\")\n",
    "print(f\"  NaN check - RNA: {rna_df_full.isna().sum().sum()}, Protein: {prot_df_full.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new MARIO object with full features\n",
    "mario_full = Mario(rna_df_full, prot_df_full, normalization=False)\n",
    "mario_full.specify_matching_params(n_matched_per_cell=n_matched)\n",
    "\n",
    "# Compute distance using overlap features\n",
    "_ = mario_full.compute_dist_ovlp(n_components=n_ovlp_components)\n",
    "\n",
    "# Initial matching\n",
    "_ = mario_full.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "# Compute distance using ALL features (CCA refinement)\n",
    "# NOTE: Use conservative number of CCA components.\n",
    "# With few protein features relative to RNA features and matched samples,\n",
    "# CCA can find trivially perfect correlations if given too many components.\n",
    "# Rule of thumb: use min(n_shared - 1, sqrt(n_prot_active))\n",
    "n_prot_active = prot_df_full.shape[1] - len(shared_feature_names)\n",
    "n_cca_components = min(\n",
    "    len(shared_feature_names) - 1,  # No more than shared features\n",
    "    int(np.sqrt(n_prot_active)) + 1,  # Conservative based on protein features\n",
    "    8  # Hard cap for this data\n",
    ")\n",
    "n_cca_components = max(3, n_cca_components)  # At least 3 components\n",
    "print(f\"Using {n_cca_components} CCA components\")\n",
    "print(f\"  (shared features: {len(shared_feature_names)}, protein active: {n_prot_active})\")\n",
    "\n",
    "dist_all, cancor = mario_full.compute_dist_all('ovlp', n_components=n_cca_components)\n",
    "\n",
    "# Interpret canonical correlations\n",
    "print(f\"\\nCanonical correlations: {np.round(cancor, 4)}\")\n",
    "\n",
    "if np.allclose(cancor, 1.0, atol=0.01):\n",
    "    print(\"\\nNOTE: Canonical correlations are very high (~1.0).\")\n",
    "    print(\"This is common when protein features are few relative to matched samples.\")\n",
    "    print(\"The CCA can perfectly align matched pairs in this low-dimensional space.\")\n",
    "    print(\"Matching quality depends on how well CCA generalizes to unmatched cells.\")\n",
    "elif np.mean(cancor) > 0.7:\n",
    "    print(\"\\nGood: High canonical correlations indicate strong alignment.\")\n",
    "else:\n",
    "    print(\"\\nNote: Moderate correlations - may indicate weaker cross-modal alignment.\")\n",
    "\n",
    "# Plot canonical correlations\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(len(cancor)), cancor)\n",
    "plt.xlabel('CCA Component')\n",
    "plt.ylabel('Canonical Correlation')\n",
    "plt.title('MARIO: Canonical Correlations')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.axhline(y=0.7, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"Good threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match using all features\n",
    "matching_all = mario_full.match_cells('all', sparsity=None, mode='auto')\n",
    "\n",
    "n_matched_all = sum(1 for m in matching_all if len(m) > 0)\n",
    "print(f\"Matched {n_matched_all}/{len(matching_all)} RNA cells using all features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check canonical correlations before matchability test\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MATCHABILITY DIAGNOSTIC\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check the canonical correlations from the existing matching\n",
    "print(\"\\n1. OBSERVED CANONICAL CORRELATIONS:\")\n",
    "print(f\"   From compute_dist_all (stored): {cancor[:5] if 'cancor' in dir() else 'Not computed'}\")\n",
    "\n",
    "# Check data properties\n",
    "print(\"\\n2. DATA PROPERTIES:\")\n",
    "print(f\"   mario_full.df1 shape: {mario_full.df1.shape}\")\n",
    "print(f\"   mario_full.df2 shape: {mario_full.df2.shape}\")\n",
    "print(f\"   Overlap features: {len(mario_full.ovlp_features)}\")\n",
    "\n",
    "# Check for zero-variance features\n",
    "df1_std = mario_full.df1.std()\n",
    "df2_std = mario_full.df2.std()\n",
    "print(f\"\\n   df1 zero-variance features: {(df1_std < 1e-10).sum()}\")\n",
    "print(f\"   df2 zero-variance features: {(df2_std < 1e-10).sum()}\")\n",
    "\n",
    "# Check data scale\n",
    "print(\"\\n3. DATA SCALE:\")\n",
    "print(f\"   df1 mean: {mario_full.df1.values.mean():.4f}, std: {mario_full.df1.values.std():.4f}\")\n",
    "print(f\"   df2 mean: {mario_full.df2.values.mean():.4f}, std: {mario_full.df2.values.std():.4f}\")\n",
    "\n",
    "# CHECK MATCHING - this is critical\n",
    "print(\"\\n4. MATCHING STATISTICS:\")\n",
    "n_matched_ovlp = sum(1 for m in mario_full.matching['ovlp'] if len(m) > 0)\n",
    "n_matched_all = sum(1 for m in mario_full.matching['all'] if len(m) > 0)\n",
    "print(f\"   Cells matched (overlap): {n_matched_ovlp} / {mario_full.n1}\")\n",
    "print(f\"   Cells matched (all):     {n_matched_all} / {mario_full.n1}\")\n",
    "\n",
    "# Check the aligned data dimensions for CCA\n",
    "from mario import embed\n",
    "X_aligned = []\n",
    "Y_aligned = []\n",
    "for ii in range(mario_full.n1):\n",
    "    if len(mario_full.matching['ovlp'][ii]) > 0:\n",
    "        X_aligned.append(mario_full.df1.iloc[ii, :].values)\n",
    "        Y_aligned.append(mario_full.df2.iloc[mario_full.matching['ovlp'][ii]].mean(axis=0).values)\n",
    "\n",
    "X_aligned = np.array(X_aligned)\n",
    "Y_aligned = np.array(Y_aligned)\n",
    "print(f\"\\n5. CCA INPUT DIMENSIONS:\")\n",
    "print(f\"   X (RNA) aligned: {X_aligned.shape}\")\n",
    "print(f\"   Y (Protein) aligned: {Y_aligned.shape}\")\n",
    "print(f\"   Ratio features/samples (RNA): {X_aligned.shape[1]/X_aligned.shape[0]:.1f}\")\n",
    "\n",
    "# THE PROBLEM: CCA with features >> samples gives trivial perfect correlations!\n",
    "if X_aligned.shape[1] > X_aligned.shape[0]:\n",
    "    print(\"\\n   \u26a0\ufe0f  WARNING: More features than samples!\")\n",
    "    print(\"   CCA will overfit and give meaningless correlations of 1.0\")\n",
    "    print(\"   This is why matchability test returns p=1\")\n",
    "\n",
    "# Test CCA with ONLY overlap features\n",
    "print(\"\\n6. CCA WITH OVERLAP FEATURES ONLY:\")\n",
    "X_ovlp = mario_full.df1[mario_full.ovlp_features].iloc[[i for i in range(mario_full.n1) if len(mario_full.matching['ovlp'][i]) > 0]].values\n",
    "Y_ovlp = np.array([mario_full.df2[mario_full.ovlp_features].iloc[mario_full.matching['ovlp'][i]].mean(axis=0).values \n",
    "                   for i in range(mario_full.n1) if len(mario_full.matching['ovlp'][i]) > 0])\n",
    "print(f\"   X_ovlp shape: {X_ovlp.shape}\")\n",
    "print(f\"   Y_ovlp shape: {Y_ovlp.shape}\")\n",
    "\n",
    "try:\n",
    "    n_comp = min(5, X_ovlp.shape[1]-1, X_ovlp.shape[0]-1)\n",
    "    cancor_ovlp_only, _ = embed.get_cancor(X_ovlp, Y_ovlp, n_components=n_comp)\n",
    "    print(f\"   Canonical correlations (overlap only): {cancor_ovlp_only}\")\n",
    "    print(f\"   Mean: {np.mean(cancor_ovlp_only):.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run matchability test\n",
    "print(\"=\" * 60)\n",
    "print(\"MARIO MATCHABILITY TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nRunning statistical test for dataset matchability...\")\n",
    "print(\"(This uses random sign flips to create null distribution)\")\n",
    "print()\n",
    "\n",
    "# CRITICAL FIX: Clean NaN/Inf values in MARIO dataframes before matchability test\n",
    "# The matchability test internally uses CCA which cannot handle NaN values\n",
    "print(\"Cleaning MARIO dataframes for CCA compatibility...\")\n",
    "\n",
    "# Clean df1 (RNA) - aggressive column-by-column approach\n",
    "mario_full.df1 = mario_full.df1.copy()\n",
    "for col in mario_full.df1.columns:\n",
    "    mario_full.df1[col] = np.nan_to_num(mario_full.df1[col].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Clean df2 (Protein) - aggressive column-by-column approach\n",
    "mario_full.df2 = mario_full.df2.copy()\n",
    "for col in mario_full.df2.columns:\n",
    "    mario_full.df2[col] = np.nan_to_num(mario_full.df2[col].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Verify no NaN/Inf remain\n",
    "df1_clean = not (np.isnan(mario_full.df1.values).any() or np.isinf(mario_full.df1.values).any())\n",
    "df2_clean = not (np.isnan(mario_full.df2.values).any() or np.isinf(mario_full.df2.values).any())\n",
    "print(f\"  df1 clean: {df1_clean} (NaN: {np.isnan(mario_full.df1.values).sum()}, Inf: {np.isinf(mario_full.df1.values).sum()})\")\n",
    "print(f\"  df2 clean: {df2_clean} (NaN: {np.isnan(mario_full.df2.values).sum()}, Inf: {np.isinf(mario_full.df2.values).sum()})\")\n",
    "assert df1_clean and df2_clean, \"Failed to clean NaN/Inf values\"\n",
    "\n",
    "# Ensure both initial (ovlp) and refined (all) matching are complete\n",
    "print(\"Verifying initial and refined matching are complete...\")\n",
    "\n",
    "# Check if matching has been done, if not redo it\n",
    "if not hasattr(mario_full, 'matching_ovlp') or mario_full.matching_ovlp is None:\n",
    "    print(\"  Re-running initial matching (overlap features)...\")\n",
    "    mario_full.match_cells('ovlp', sparsity=None, mode='auto')\n",
    "\n",
    "if not hasattr(mario_full, 'matching_all') or mario_full.matching_all is None:\n",
    "    print(\"  Re-running refined matching (all features)...\")\n",
    "    mario_full.match_cells('all', sparsity=None, mode='auto')\n",
    "\n",
    "print(\"  Both matchings confirmed. Proceeding with matchability test...\\n\")\n",
    "\n",
    "# Note: This can take a few minutes\n",
    "# Reduce n_sim if it takes too long\n",
    "pval_ovlp, pval_all = mario_full.matchable(\n",
    "    n_sim=10,           # Number of simulations (increase for more accuracy)\n",
    "    top_k=5,            # Use top-k canonical correlations\n",
    "    flip_prob=0.3,      # Probability of sign flip\n",
    "    subsample_prop=1,   # Subsample for speed\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MATCHABILITY TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"P-value (overlap features only): {pval_ovlp:.4f}\")\n",
    "print(f\"P-value (all features):          {pval_all:.4f}\")\n",
    "print()\n",
    "\n",
    "if pval_ovlp < 0.05 or pval_all < 0.05:\n",
    "    print(\"RESULT: Datasets appear to be MATCHABLE (p < 0.05)\")\n",
    "    print(\"  The correspondence between modalities is statistically significant.\")\n",
    "else:\n",
    "    print(\"RESULT: Datasets may NOT be well-matched (p >= 0.05)\")\n",
    "    print(\"  Proceed with caution - results may be unreliable.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: MARIO - Interpolation (Optimal Weight Search)\n",
    "\n",
    "MARIO searches for the optimal weight between:\n",
    "- Distance from **overlap features only**\n",
    "- Distance from **all features** (via CCA)\n",
    "\n",
    "The optimal weight is selected based on canonical correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interpolation to find optimal weight\n",
    "print(\"Searching for optimal interpolation weight...\")\n",
    "print(\"(Testing weights from 0 to 1)\")\n",
    "print()\n",
    "\n",
    "best_wt, best_matching = mario_full.interpolate(\n",
    "    n_wts=10,     # Number of weights to try\n",
    "    top_k=5,      # Use top-k canonical correlations to evaluate\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal weight: {best_wt:.2f}\")\n",
    "print(f\"  (0 = use only overlap features, 1 = use only CCA features)\")\n",
    "\n",
    "n_matched_best = sum(1 for m in best_matching if len(m) > 0)\n",
    "print(f\"\\nMatched {n_matched_best}/{len(best_matching)} RNA cells with optimal weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bad matches using joint regularized clustering\n",
    "print(\"\\nFiltering bad matches using joint regularized clustering...\")\n",
    "\n",
    "n_clusters_filter = min(15, n_rna_subsample // 50)  # Aim for ~50 cells per cluster\n",
    "n_clusters_filter = max(5, n_clusters_filter)\n",
    "\n",
    "filtered_matching = mario_full.filter_bad_matches(\n",
    "    matching='wted',           # Use the interpolated matching\n",
    "    n_clusters=n_clusters_filter,\n",
    "    n_components=min(15, n_cca_components),\n",
    "    bad_prop=0.1,              # Remove ~10% of worst matches\n",
    "    max_iter=30,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "n_matched_filtered = sum(1 for m in filtered_matching if len(m) > 0)\n",
    "print(f\"\\nAfter filtering: {n_matched_filtered}/{len(filtered_matching)} RNA cells matched\")\n",
    "print(f\"Removed {n_matched_best - n_matched_filtered} bad matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: KNN matching for softer assignments\n",
    "knn_matching = mario_full.knn_matching(dist_mat='wted', k=5)\n",
    "\n",
    "print(f\"KNN matching: each RNA cell matched to {5} nearest protein cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CCA embedding for visualization\n",
    "from mario import embed\n",
    "\n",
    "# Align the datasets using the filtered matching\n",
    "X_aligned = []\n",
    "Y_aligned = []\n",
    "matched_rna_indices_mario = []\n",
    "matched_prot_indices_mario = []\n",
    "\n",
    "for i, matches in enumerate(filtered_matching):\n",
    "    if len(matches) > 0:\n",
    "        X_aligned.append(rna_df_full.iloc[i].values)\n",
    "        # Average the matched protein cells\n",
    "        Y_aligned.append(prot_df_full.iloc[matches].mean(axis=0).values)\n",
    "        matched_rna_indices_mario.append(rna_idx_subsample[i])\n",
    "        matched_prot_indices_mario.append(prot_idx_subsample[matches[0]])  # Take first match\n",
    "\n",
    "X_aligned = np.array(X_aligned)\n",
    "Y_aligned = np.array(Y_aligned)\n",
    "\n",
    "print(f\"Aligned arrays: RNA {X_aligned.shape}, Protein {Y_aligned.shape}\")\n",
    "\n",
    "# Fit CCA for embedding\n",
    "embed_dim = min(20, X_aligned.shape[1], Y_aligned.shape[1])\n",
    "cancor_embed, cca = embed.get_cancor(X_aligned, Y_aligned, n_components=embed_dim)\n",
    "\n",
    "# Get CCA scores\n",
    "rna_cca_mario, prot_cca_mario = cca.transform(X_aligned, Y_aligned)\n",
    "\n",
    "print(f\"MARIO CCA embedding: {rna_cca_mario.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MARIO results\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Combine embeddings\n",
    "combined_mario = np.vstack([rna_cca_mario, prot_cca_mario])\n",
    "labels_mario = ['RNA'] * len(rna_cca_mario) + ['Protein'] * len(prot_cca_mario)\n",
    "\n",
    "# Run t-SNE (faster than UMAP for small datasets)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "embedding_2d = tsne.fit_transform(combined_mario[:, :10])  # Use first 10 CCA components\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in ['RNA', 'Protein']:\n",
    "    mask = np.array(labels_mario) == label\n",
    "    plt.scatter(embedding_2d[mask, 0], embedding_2d[mask, 1], \n",
    "                label=label, alpha=0.5, s=10)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('MARIO: Joint Embedding (t-SNE of CCA scores)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MaxFuse Integration (Recommended for Cross-Modal Data)\n",
    "\n",
    "MaxFuse is specifically designed for **cross-modal integration** with:\n",
    "- **Weak linkage**: Few or uninformative shared features\n",
    "- **Different modalities**: RNA-seq, CODEX/protein, ATAC-seq, etc.\n",
    "- **Scalable architecture**: Batch processing with pivot propagation\n",
    "\n",
    "## Key Features\n",
    "1. **Graph-based smoothing**: Reduces noise before matching\n",
    "2. **Iterative CCA refinement**: Improves alignment quality\n",
    "3. **Pivot propagation**: Scales to large datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint data if MARIO section was skipped\n",
    "# This cell is idempotent - safe to run even if data already loaded\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from maxfuse import Fusor\n",
    "\n",
    "checkpoint_dir = 'results/2_integration'\n",
    "\n",
    "# Check if we need to load from checkpoint\n",
    "need_checkpoint = False\n",
    "try:\n",
    "    # Check if required variables exist and have data\n",
    "    _ = rna_shared.shape\n",
    "    _ = protein_shared.shape\n",
    "    _ = rna_active.shape\n",
    "    _ = protein_active.shape\n",
    "    print('Data already loaded - using existing arrays.')\n",
    "except NameError:\n",
    "    need_checkpoint = True\n",
    "    print('Data not found - loading from checkpoint...')\n",
    "\n",
    "if need_checkpoint:\n",
    "    # Load arrays from checkpoint\n",
    "    rna_shared = np.load(f'{checkpoint_dir}/checkpoint_rna_shared.npy')\n",
    "    protein_shared = np.load(f'{checkpoint_dir}/checkpoint_protein_shared.npy')\n",
    "    rna_active = np.load(f'{checkpoint_dir}/checkpoint_rna_active.npy')\n",
    "    protein_active = np.load(f'{checkpoint_dir}/checkpoint_protein_active.npy')\n",
    "    \n",
    "    # Load correspondence\n",
    "    correspondence_df = pd.read_csv(f'{checkpoint_dir}/checkpoint_correspondence.csv')\n",
    "    rna_protein_correspondence = correspondence_df.values\n",
    "    \n",
    "    print(f'Loaded from checkpoint:')\n",
    "    print(f'  rna_shared: {rna_shared.shape}')\n",
    "    print(f'  protein_shared: {protein_shared.shape}')\n",
    "    print(f'  rna_active: {rna_active.shape}')\n",
    "    print(f'  protein_active: {protein_active.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: MaxFuse Integration\n",
    "\n",
    "MaxFuse performs the integration in several stages:\n",
    "1. Split data into batches for scalability\n",
    "2. Construct k-NN graphs and cluster cells\n",
    "3. Find initial pivot matches using shared features\n",
    "4. Refine pivots using CCA on all features\n",
    "5. Propagate matching to all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fusor - let MaxFuse cluster automatically\n",
    "fusor = Fusor(\n",
    "    shared_arr1=rna_shared,\n",
    "    shared_arr2=protein_shared,\n",
    "    active_arr1=rna_active,\n",
    "    active_arr2=protein_active,\n",
    "    labels1=None,  # Let MaxFuse cluster\n",
    "    labels2=None,\n",
    "    method='centroid_shrinkage'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate appropriate batching parameters\n",
    "n_rna = rna_active.shape[0]\n",
    "n_prot = protein_active.shape[0]\n",
    "ratio = n_prot / n_rna\n",
    "\n",
    "print(f\"RNA cells: {n_rna}\")\n",
    "print(f\"Protein cells: {n_prot}\")\n",
    "print(f\"Ratio (protein/RNA): {ratio:.1f}\")\n",
    "\n",
    "# Batching parameters\n",
    "max_outward = min(8000, n_rna)\n",
    "matching_ratio = max(10, int(ratio) + 5)  # Adjusted for data ratio\n",
    "metacell_sz = 2  # Metacell aggregation helps with noise\n",
    "\n",
    "print(f\"\\nBatching parameters:\")\n",
    "print(f\"  max_outward_size: {max_outward}\")\n",
    "print(f\"  matching_ratio: {matching_ratio}\")\n",
    "print(f\"  metacell_size: {metacell_sz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusor.split_into_batches(\n",
    "    max_outward_size=max_outward,\n",
    "    matching_ratio=matching_ratio,\n",
    "    metacell_size=metacell_sz,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot singular values to determine SVD components\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "fusor.plot_singular_values(target='active_arr1', n_components=50)\n",
    "axes[0].set_title('RNA Active - Singular Values')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "fusor.plot_singular_values(target='active_arr2', n_components=min(23, protein_active.shape[1]-1))\n",
    "axes[1].set_title('Protein Active - Singular Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SVD components based on data dimensions\n",
    "n_prot_features = protein_active.shape[1]\n",
    "n_rna_features = rna_active.shape[1]\n",
    "n_shared = rna_shared.shape[1]\n",
    "\n",
    "svd_comp1_graph = min(40, n_rna_features - 1)\n",
    "svd_comp2_graph = min(15, n_prot_features - 1)\n",
    "\n",
    "print(f\"Graph construction SVD components:\")\n",
    "print(f\"  RNA: {svd_comp1_graph}\")\n",
    "print(f\"  Protein: {svd_comp2_graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct graphs with automatic clustering\n",
    "fusor.construct_graphs(\n",
    "    n_neighbors1=15,\n",
    "    n_neighbors2=15,\n",
    "    svd_components1=svd_comp1_graph,\n",
    "    svd_components2=svd_comp2_graph,\n",
    "    resolution1=2.0,   # Higher resolution = more clusters = finer smoothing\n",
    "    resolution2=2.0,\n",
    "    resolution_tol=0.1,\n",
    "    leiden_runs=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Get cluster labels from first batch\n",
    "labels1_b0 = fusor._labels1[0]\n",
    "labels2_b0 = fusor._labels2[0]\n",
    "\n",
    "# RNA cluster sizes\n",
    "ax = axes[0]\n",
    "unique, counts = np.unique(labels1_b0, return_counts=True)\n",
    "ax.bar(range(len(counts)), sorted(counts, reverse=True))\n",
    "ax.set_xlabel('Cluster rank')\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_title(f'RNA Clusters (n={len(unique)})')\n",
    "ax.axhline(y=np.mean(counts), color='r', linestyle='--', label=f'Mean: {np.mean(counts):.0f}')\n",
    "ax.legend()\n",
    "\n",
    "# Protein cluster sizes\n",
    "ax = axes[1]\n",
    "unique, counts = np.unique(labels2_b0, return_counts=True)\n",
    "ax.bar(range(len(counts)), sorted(counts, reverse=True))\n",
    "ax.set_xlabel('Cluster rank')\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_title(f'Protein Clusters (n={len(unique)})')\n",
    "ax.axhline(y=np.mean(counts), color='r', linestyle='--', label=f'Mean: {np.mean(counts):.0f}')\n",
    "ax.legend()\n",
    "\n",
    "# Summary stats\n",
    "ax = axes[2]\n",
    "ax.axis('off')\n",
    "stats_text = f'''Graph Construction Summary\n",
    "{\"=\"*40}\n",
    "\n",
    "RNA (Batch 0):\n",
    "  Clusters: {len(np.unique(labels1_b0))}\n",
    "  Cells: {len(labels1_b0)}\n",
    "  Mean cluster size: {np.mean(np.bincount(labels1_b0)):.1f}\n",
    "\n",
    "Protein (Batch 0):\n",
    "  Clusters: {len(np.unique(labels2_b0))}\n",
    "  Cells: {len(labels2_b0)}\n",
    "  Mean cluster size: {np.mean(np.bincount(labels2_b0)):.1f}\n",
    "'''\n",
    "ax.text(0.1, 0.9, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find initial pivots with smoothing for weak linkage\n",
    "svd_shared1 = min(25, n_shared - 1)\n",
    "svd_shared2 = min(20, n_shared - 1)\n",
    "print(f\"Using {svd_shared1}/{svd_shared2} SVD components for shared features\")\n",
    "\n",
    "fusor.find_initial_pivots(\n",
    "    wt1=0.3,  # Smoothing weight\n",
    "    wt2=0.3,\n",
    "    svd_components1=svd_shared1,\n",
    "    svd_components2=svd_shared2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize initial pivot matching\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Get initial matching from first batch\n",
    "init_match = fusor._init_matching[0]\n",
    "init_rows, init_cols, init_scores = init_match\n",
    "\n",
    "# Score distribution\n",
    "ax = axes[0]\n",
    "ax.hist(init_scores, bins=50, edgecolor='white', alpha=0.7)\n",
    "ax.axvline(np.mean(init_scores), color='r', linestyle='--', \n",
    "           label=f'Mean: {np.mean(init_scores):.3f}')\n",
    "ax.axvline(np.median(init_scores), color='g', linestyle='--',\n",
    "           label=f'Median: {np.median(init_scores):.3f}')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Initial Pivot Scores')\n",
    "ax.legend()\n",
    "\n",
    "# Matches per RNA cell\n",
    "ax = axes[1]\n",
    "matches_per_rna = np.bincount(init_rows)\n",
    "ax.hist(matches_per_rna[matches_per_rna > 0], bins=20, edgecolor='white', alpha=0.7)\n",
    "ax.set_xlabel('Matches per RNA cell')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Matching Density (RNA)')\n",
    "\n",
    "# Summary\n",
    "ax = axes[2]\n",
    "ax.axis('off')\n",
    "n_rna_matched = len(np.unique(init_rows))\n",
    "n_prot_matched = len(np.unique(init_cols))\n",
    "stats = f'''Initial Pivot Matching\n",
    "{\"=\"*40}\n",
    "\n",
    "Total matches: {len(init_scores):,}\n",
    "Unique RNA matched: {n_rna_matched:,}\n",
    "Unique Protein matched: {n_prot_matched:,}\n",
    "\n",
    "Score statistics:\n",
    "  Min:    {np.min(init_scores):.4f}\n",
    "  Max:    {np.max(init_scores):.4f}\n",
    "  Mean:   {np.mean(init_scores):.4f}\n",
    "  Median: {np.median(init_scores):.4f}\n",
    "  Std:    {np.std(init_scores):.4f}\n",
    "'''\n",
    "ax.text(0.1, 0.9, stats, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check canonical correlations\n",
    "cca_comp_check = min(15, n_prot_features - 1)\n",
    "fusor.plot_canonical_correlations(\n",
    "    svd_components1=min(30, n_rna_features - 1),\n",
    "    svd_components2=None,\n",
    "    cca_components=cca_comp_check\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine pivots using CCA\n",
    "cca_components = min(25, n_prot_features - 1)\n",
    "\n",
    "fusor.refine_pivots(\n",
    "    wt1=0.3,\n",
    "    wt2=0.3,\n",
    "    svd_components1=min(40, n_rna_features - 1),\n",
    "    svd_components2=None,  # Keep all protein features\n",
    "    cca_components=cca_components,\n",
    "    n_iters=1,\n",
    "    filter_prop=0.0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare initial vs refined matching\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Get refined matching\n",
    "refined_match = fusor._refined_matching[0]\n",
    "ref_rows, ref_cols, ref_scores = refined_match\n",
    "\n",
    "# Score comparison\n",
    "ax = axes[0]\n",
    "ax.hist(init_scores, bins=50, alpha=0.5, label='Initial', edgecolor='white')\n",
    "ax.hist(ref_scores, bins=50, alpha=0.5, label='Refined', edgecolor='white')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Score Distribution: Initial vs Refined')\n",
    "ax.legend()\n",
    "\n",
    "# Score improvement\n",
    "ax = axes[1]\n",
    "ax.boxplot([init_scores, ref_scores], labels=['Initial', 'Refined'])\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Score Comparison')\n",
    "\n",
    "# Summary\n",
    "ax = axes[2]\n",
    "ax.axis('off')\n",
    "stats = f'''CCA Refinement Results\n",
    "{\"=\"*40}\n",
    "\n",
    "                Initial    Refined\n",
    "Matches:     {len(init_scores):>10,}  {len(ref_scores):>10,}\n",
    "Mean score:  {np.mean(init_scores):>10.4f}  {np.mean(ref_scores):>10.4f}\n",
    "Median:      {np.median(init_scores):>10.4f}  {np.median(ref_scores):>10.4f}\n",
    "Std:         {np.std(init_scores):>10.4f}  {np.std(ref_scores):>10.4f}\n",
    "\n",
    "Score change: {np.mean(ref_scores) - np.mean(init_scores):+.4f}\n",
    "'''\n",
    "ax.text(0.1, 0.9, stats, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bad pivots\n",
    "# NOTE: Using conservative filtering (20%) to retain more matches\n",
    "# Increase filter_prop if too many low-quality matches remain\n",
    "pivot_filter_prop = 0.2  # Remove bottom 20% (was 50%)\n",
    "\n",
    "fusor.filter_bad_matches(\n",
    "    target='pivot',\n",
    "    filter_prop=pivot_filter_prop,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFiltered {pivot_filter_prop*100:.0f}% of lowest-scoring pivots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pivot filtering results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Get remaining indices\n",
    "remaining_idx = fusor._remaining_indices_in_refined_matching[0]\n",
    "kept_scores = ref_scores[remaining_idx]\n",
    "removed_scores = np.delete(ref_scores, remaining_idx)\n",
    "\n",
    "# Score distributions: kept vs removed\n",
    "ax = axes[0]\n",
    "ax.hist(kept_scores, bins=30, alpha=0.7, label=f'Kept ({len(kept_scores)})', color='green', edgecolor='white')\n",
    "if len(removed_scores) > 0:\n",
    "    ax.hist(removed_scores, bins=30, alpha=0.7, label=f'Removed ({len(removed_scores)})', color='red', edgecolor='white')\n",
    "ax.axvline(np.mean(kept_scores), color='darkgreen', linestyle='--')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Pivot Filtering: Kept vs Removed')\n",
    "ax.legend()\n",
    "\n",
    "# Summary pie chart\n",
    "ax = axes[1]\n",
    "sizes = [len(kept_scores), len(removed_scores)]\n",
    "labels = [f'Kept\\n{len(kept_scores):,}', f'Removed\\n{len(removed_scores):,}']\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "pct_removed = 100 * len(removed_scores) / (len(kept_scores) + len(removed_scores))\n",
    "ax.set_title(f'Pivot Filter Results\\n({pct_removed:.0f}% removed)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Pivot filtering: {len(kept_scores):,} kept, {len(removed_scores):,} removed\")\n",
    "if len(removed_scores) > 0:\n",
    "    print(f\"Mean score - Kept: {np.mean(kept_scores):.4f}, Removed: {np.mean(removed_scores):.4f}\")\n",
    "else:\n",
    "    print(f\"Mean score - Kept: {np.mean(kept_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate to all cells\n",
    "fusor.propagate(\n",
    "    svd_components1=min(40, n_rna_features - 1),\n",
    "    svd_components2=None,\n",
    "    wt1=0.7,\n",
    "    wt2=0.7,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize propagation results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Get propagated matching\n",
    "prop_match = fusor._propagated_matching[0]\n",
    "prop_rows, prop_cols, prop_scores = prop_match\n",
    "\n",
    "# Score distribution\n",
    "ax = axes[0]\n",
    "ax.hist(prop_scores, bins=50, edgecolor='white', alpha=0.7, color='purple')\n",
    "ax.axvline(np.mean(prop_scores), color='r', linestyle='--',\n",
    "           label=f'Mean: {np.mean(prop_scores):.3f}')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Propagated Matching Scores')\n",
    "ax.legend()\n",
    "\n",
    "# Coverage: pivot vs propagated\n",
    "ax = axes[1]\n",
    "pivot_rna = len(np.unique(ref_rows[remaining_idx]))\n",
    "prop_rna = len(np.unique(prop_rows))\n",
    "total_rna = rna_active.shape[0]\n",
    "\n",
    "categories = ['Pivot\\nMatches', 'Propagated\\nMatches', 'Total\\nRNA Cells']\n",
    "values = [pivot_rna, prop_rna, total_rna]\n",
    "colors = ['#3498db', '#9b59b6', '#95a5a6']\n",
    "bars = ax.bar(categories, values, color=colors, edgecolor='white')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Coverage Expansion')\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "            f'{val:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Summary\n",
    "ax = axes[2]\n",
    "ax.axis('off')\n",
    "prop_prot = len(np.unique(prop_cols))\n",
    "total_prot = protein_active.shape[0]\n",
    "stats = f'''Propagation Summary\n",
    "{\"=\"*40}\n",
    "\n",
    "Propagated matches: {len(prop_scores):,}\n",
    "\n",
    "RNA coverage:\n",
    "  Pivot:      {pivot_rna:>8,} ({100*pivot_rna/total_rna:.1f}%)\n",
    "  Propagated: {prop_rna:>8,} ({100*prop_rna/total_rna:.1f}%)\n",
    "  Total:      {total_rna:>8,}\n",
    "\n",
    "Protein coverage:\n",
    "  Propagated: {prop_prot:>8,} ({100*prop_prot/total_prot:.1f}%)\n",
    "  Total:      {total_prot:>8,}\n",
    "'''\n",
    "ax.text(0.1, 0.9, stats, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter propagated matches\n",
    "# NOTE: Using conservative filtering (10%) to maximize coverage\n",
    "propagate_filter_prop = 0.1  # Remove bottom 10% (was 30%)\n",
    "\n",
    "fusor.filter_bad_matches(\n",
    "    target='propagated',\n",
    "    filter_prop=propagate_filter_prop,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFiltered {propagate_filter_prop*100:.0f}% of lowest-scoring propagated matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full matching\n",
    "full_matching = fusor.get_matching(order=(2, 1), target='full_data')\n",
    "\n",
    "print(f\"\\nMaxFuse Full matching results:\")\n",
    "print(f\"  Total matches: {len(full_matching[0])}\")\n",
    "print(f\"  Unique RNA cells: {len(np.unique(full_matching[0]))}\")\n",
    "print(f\"  Unique Protein cells: {len(np.unique(full_matching[1]))}\")\n",
    "print(f\"  Score range: [{min(full_matching[2]):.3f}, {max(full_matching[2]):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply score threshold to remove negative/low-quality matches\n",
    "MIN_SCORE_THRESHOLD = 0.0  # Remove anti-correlated matches\n",
    "\n",
    "# Get original stats\n",
    "n_original = len(full_matching[0])\n",
    "scores = np.array(full_matching[2])\n",
    "\n",
    "# Filter by threshold\n",
    "mask = scores >= MIN_SCORE_THRESHOLD\n",
    "full_matching_filtered = (\n",
    "    np.array(full_matching[0])[mask],\n",
    "    np.array(full_matching[1])[mask],\n",
    "    scores[mask]\n",
    ")\n",
    "\n",
    "n_filtered = len(full_matching_filtered[0])\n",
    "n_removed = n_original - n_filtered\n",
    "\n",
    "print(f\"Score threshold filtering (min score >= {MIN_SCORE_THRESHOLD}):\")\n",
    "print(f\"  Original matches: {n_original:,}\")\n",
    "print(f\"  Removed (score < {MIN_SCORE_THRESHOLD}): {n_removed:,} ({100*n_removed/n_original:.1f}%)\")\n",
    "print(f\"  Remaining matches: {n_filtered:,}\")\n",
    "print(f\"\")\n",
    "print(f\"Score statistics after filtering:\")\n",
    "print(f\"  Min:    {np.min(full_matching_filtered[2]):.4f}\")\n",
    "print(f\"  Max:    {np.max(full_matching_filtered[2]):.4f}\")\n",
    "print(f\"  Mean:   {np.mean(full_matching_filtered[2]):.4f}\")\n",
    "print(f\"  Median: {np.median(full_matching_filtered[2]):.4f}\")\n",
    "\n",
    "# Update full_matching to use filtered version\n",
    "full_matching = full_matching_filtered\n",
    "\n",
    "# Visualize what was removed\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "if n_removed > 0:\n",
    "    ax.hist(scores[~mask], bins=30, alpha=0.7, color='red', label=f'Removed ({n_removed:,})', edgecolor='white')\n",
    "ax.hist(scores[mask], bins=30, alpha=0.7, color='green', label=f'Kept ({n_filtered:,})', edgecolor='white')\n",
    "ax.axvline(MIN_SCORE_THRESHOLD, color='black', linestyle='--', linewidth=2, label=f'Threshold ({MIN_SCORE_THRESHOLD})')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Score Threshold Filtering')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "if n_removed > 0:\n",
    "    sizes = [n_filtered, n_removed]\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    labels = [f'Kept\\n{n_filtered:,}', f'Removed\\n{n_removed:,}']\n",
    "    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    ax.set_title('Score Threshold Results')\n",
    "else:\n",
    "    ax.text(0.5, 0.5, f'All {n_filtered:,} matches\\nkept (score >= {MIN_SCORE_THRESHOLD})', \n",
    "            ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle='round', facecolor='#2ecc71', alpha=0.3))\n",
    "    ax.set_title('Score Threshold Results')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate unmatched RNA cells\n",
    "print(\"=\" * 60)\n",
    "print(\"UNMATCHED RNA CELL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find matched and unmatched RNA cells\n",
    "matched_rna_idx = np.unique(full_matching[0])\n",
    "all_rna_idx = np.arange(rna_active.shape[0])\n",
    "unmatched_rna_idx = np.setdiff1d(all_rna_idx, matched_rna_idx)\n",
    "\n",
    "n_matched = len(matched_rna_idx)\n",
    "n_unmatched = len(unmatched_rna_idx)\n",
    "n_total = rna_active.shape[0]\n",
    "\n",
    "print(f\"\\nRNA Cell Coverage:\")\n",
    "print(f\"  Matched:   {n_matched:,} ({100*n_matched/n_total:.1f}%)\")\n",
    "print(f\"  Unmatched: {n_unmatched:,} ({100*n_unmatched/n_total:.1f}%)\")\n",
    "print(f\"  Total:     {n_total:,}\")\n",
    "\n",
    "# Save unmatched indices for further analysis\n",
    "unmatched_rna_indices = unmatched_rna_idx\n",
    "\n",
    "if n_unmatched == 0:\n",
    "    print(\"\\n*** All RNA cells matched! ***\")\n",
    "    print(\"No unmatched analysis needed.\")\n",
    "else:\n",
    "    # Compare feature distributions: matched vs unmatched\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Shared feature means\n",
    "    ax = axes[0, 0]\n",
    "    matched_shared_mean = rna_shared[matched_rna_idx].mean(axis=1)\n",
    "    unmatched_shared_mean = rna_shared[unmatched_rna_idx].mean(axis=1)\n",
    "    ax.hist(matched_shared_mean, bins=30, alpha=0.6, label='Matched', color='green', density=True)\n",
    "    ax.hist(unmatched_shared_mean, bins=30, alpha=0.6, label='Unmatched', color='red', density=True)\n",
    "    ax.set_xlabel('Mean shared feature value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Shared Features: Matched vs Unmatched')\n",
    "    ax.legend()\n",
    "\n",
    "    # Shared feature variance\n",
    "    ax = axes[0, 1]\n",
    "    matched_shared_var = rna_shared[matched_rna_idx].var(axis=1)\n",
    "    unmatched_shared_var = rna_shared[unmatched_rna_idx].var(axis=1)\n",
    "    ax.hist(matched_shared_var, bins=30, alpha=0.6, label='Matched', color='green', density=True)\n",
    "    ax.hist(unmatched_shared_var, bins=30, alpha=0.6, label='Unmatched', color='red', density=True)\n",
    "    ax.set_xlabel('Variance of shared features')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Feature Variance: Matched vs Unmatched')\n",
    "    ax.legend()\n",
    "\n",
    "    # Detection rate (non-zero features)\n",
    "    ax = axes[0, 2]\n",
    "    ZERO_VAL = -2.5  # From detection-aware normalization\n",
    "    matched_detection = (rna_shared[matched_rna_idx] > ZERO_VAL + 0.1).mean(axis=1)\n",
    "    unmatched_detection = (rna_shared[unmatched_rna_idx] > ZERO_VAL + 0.1).mean(axis=1)\n",
    "    ax.hist(matched_detection, bins=30, alpha=0.6, label='Matched', color='green', density=True)\n",
    "    ax.hist(unmatched_detection, bins=30, alpha=0.6, label='Unmatched', color='red', density=True)\n",
    "    ax.set_xlabel('Fraction of detected features')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Detection Rate: Matched vs Unmatched')\n",
    "    ax.legend()\n",
    "\n",
    "    # Active feature mean\n",
    "    ax = axes[1, 0]\n",
    "    matched_active_mean = rna_active[matched_rna_idx].mean(axis=1)\n",
    "    unmatched_active_mean = rna_active[unmatched_rna_idx].mean(axis=1)\n",
    "    ax.hist(matched_active_mean, bins=30, alpha=0.6, label='Matched', color='green', density=True)\n",
    "    ax.hist(unmatched_active_mean, bins=30, alpha=0.6, label='Unmatched', color='red', density=True)\n",
    "    ax.set_xlabel('Mean active feature value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Active Features: Matched vs Unmatched')\n",
    "    ax.legend()\n",
    "\n",
    "    # Active feature variance  \n",
    "    ax = axes[1, 1]\n",
    "    matched_active_var = rna_active[matched_rna_idx].var(axis=1)\n",
    "    unmatched_active_var = rna_active[unmatched_rna_idx].var(axis=1)\n",
    "    ax.hist(matched_active_var, bins=30, alpha=0.6, label='Matched', color='green', density=True)\n",
    "    ax.hist(unmatched_active_var, bins=30, alpha=0.6, label='Unmatched', color='red', density=True)\n",
    "    ax.set_xlabel('Variance of active features')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Active Variance: Matched vs Unmatched')\n",
    "    ax.legend()\n",
    "\n",
    "    # Summary statistics\n",
    "    ax = axes[1, 2]\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Statistical comparison\n",
    "    from scipy import stats\n",
    "    t_stat_shared, p_shared = stats.ttest_ind(matched_shared_mean, unmatched_shared_mean)\n",
    "    t_stat_detect, p_detect = stats.ttest_ind(matched_detection, unmatched_detection)\n",
    "\n",
    "    summary = f\"\"\"Unmatched Cell Characteristics\n",
    "{\"=\"*45}\n",
    "\n",
    "Shared feature mean:\n",
    "  Matched:   {np.mean(matched_shared_mean):.4f}\n",
    "  Unmatched: {np.mean(unmatched_shared_mean):.4f}\n",
    "  p-value:   {p_shared:.2e}\n",
    "\n",
    "Detection rate:\n",
    "  Matched:   {np.mean(matched_detection):.2%}\n",
    "  Unmatched: {np.mean(unmatched_detection):.2%}\n",
    "  p-value:   {p_detect:.2e}\n",
    "\n",
    "Interpretation:\n",
    "\"\"\"\n",
    "\n",
    "    if np.mean(unmatched_detection) < np.mean(matched_detection) - 0.05:\n",
    "        summary += \"  Unmatched cells have LOWER detection\\n\"\n",
    "        summary += \"  (sparse profiles harder to match)\"\n",
    "    elif np.mean(unmatched_shared_mean) < np.mean(matched_shared_mean) - 0.1:\n",
    "        summary += \"  Unmatched cells have LOWER expression\\n\"\n",
    "        summary += \"  (low signal harder to match)\"\n",
    "    else:\n",
    "        summary += \"  No clear pattern - may be cell type\\n\"\n",
    "        summary += \"  specific (check clustering)\"\n",
    "\n",
    "    ax.text(0.05, 0.95, summary, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nUnmatched RNA cell indices saved to 'unmatched_rna_indices'\")\n",
    "print(f\"Use these indices to investigate in notebook 3 (visualization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive final matching visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Score distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(full_matching[2], bins=50, edgecolor='white', alpha=0.7, color='#2ecc71')\n",
    "ax.axvline(np.mean(full_matching[2]), color='r', linestyle='--',\n",
    "           label=f'Mean: {np.mean(full_matching[2]):.3f}')\n",
    "ax.axvline(np.median(full_matching[2]), color='orange', linestyle='--',\n",
    "           label=f'Median: {np.median(full_matching[2]):.3f}')\n",
    "ax.set_xlabel('Matching Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Final Matching Score Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# Matches per RNA cell\n",
    "ax = axes[0, 1]\n",
    "rna_match_counts = np.bincount(full_matching[0], minlength=rna_active.shape[0])\n",
    "ax.hist(rna_match_counts[rna_match_counts > 0], bins=30, edgecolor='white', alpha=0.7)\n",
    "ax.set_xlabel('Protein matches per RNA cell')\n",
    "ax.set_ylabel('RNA cells')\n",
    "ax.set_title(f'Matching Density\\n(mean: {np.mean(rna_match_counts[rna_match_counts > 0]):.1f})')\n",
    "\n",
    "# Matches per Protein cell\n",
    "ax = axes[0, 2]\n",
    "prot_match_counts = np.bincount(full_matching[1], minlength=protein_active.shape[0])\n",
    "ax.hist(prot_match_counts[prot_match_counts > 0], bins=30, edgecolor='white', alpha=0.7, color='orange')\n",
    "ax.set_xlabel('RNA matches per Protein cell')\n",
    "ax.set_ylabel('Protein cells')\n",
    "ax.set_title(f'Reverse Matching Density\\n(mean: {np.mean(prot_match_counts[prot_match_counts > 0]):.1f})')\n",
    "\n",
    "# Coverage summary\n",
    "ax = axes[1, 0]\n",
    "n_rna_matched = len(np.unique(full_matching[0]))\n",
    "n_prot_matched = len(np.unique(full_matching[1]))\n",
    "categories = ['RNA', 'Protein']\n",
    "matched = [n_rna_matched, n_prot_matched]\n",
    "total = [rna_active.shape[0], protein_active.shape[0]]\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, matched, width, label='Matched', color='#2ecc71')\n",
    "bars2 = ax.bar(x + width/2, total, width, label='Total', color='#95a5a6', alpha=0.7)\n",
    "ax.set_ylabel('Cells')\n",
    "ax.set_title('Coverage Summary')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "for bar, val in zip(bars1, matched):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "            f'{val:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Score vs index (quality across matches)\n",
    "ax = axes[1, 1]\n",
    "sorted_scores = np.sort(full_matching[2])[::-1]\n",
    "ax.plot(sorted_scores, linewidth=0.5)\n",
    "ax.axhline(np.mean(full_matching[2]), color='r', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Match rank')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Sorted Match Scores')\n",
    "ax.fill_between(range(len(sorted_scores)), sorted_scores, alpha=0.3)\n",
    "\n",
    "# Final summary text\n",
    "ax = axes[1, 2]\n",
    "ax.axis('off')\n",
    "coverage_rna = 100 * n_rna_matched / rna_active.shape[0]\n",
    "coverage_prot = 100 * n_prot_matched / protein_active.shape[0]\n",
    "summary = f'''MAXFUSE INTEGRATION SUMMARY\n",
    "{\"=\"*45}\n",
    "\n",
    "Total matches: {len(full_matching[0]):,}\n",
    "\n",
    "RNA cells:\n",
    "  Matched: {n_rna_matched:,} / {rna_active.shape[0]:,} ({coverage_rna:.1f}%)\n",
    "  Avg matches/cell: {len(full_matching[0])/n_rna_matched:.1f}\n",
    "\n",
    "Protein cells:\n",
    "  Matched: {n_prot_matched:,} / {protein_active.shape[0]:,} ({coverage_prot:.1f}%)\n",
    "  Avg matches/cell: {len(full_matching[0])/n_prot_matched:.1f}\n",
    "\n",
    "Score statistics:\n",
    "  Mean:   {np.mean(full_matching[2]):.4f}\n",
    "  Median: {np.median(full_matching[2]):.4f}\n",
    "  Std:    {np.std(full_matching[2]):.4f}\n",
    "  Min:    {np.min(full_matching[2]):.4f}\n",
    "  Max:    {np.max(full_matching[2]):.4f}\n",
    "'''\n",
    "ax.text(0.05, 0.95, summary, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Integration Results\n",
    "\n",
    "Save integration outputs for use in subsequent visualization notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save integration results to results directory\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json as json_module\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results/2_integration'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save matching results (filtered by score threshold)\n",
    "matching_data = {\n",
    "    'rna_indices': full_matching[0],\n",
    "    'protein_indices': full_matching[1],\n",
    "    'scores': full_matching[2]\n",
    "}\n",
    "with open(f'{results_dir}/maxfuse_matching.pkl', 'wb') as f:\n",
    "    pickle.dump(matching_data, f)\n",
    "print(f'Saved MaxFuse matching: {len(full_matching[0]):,} matches')\n",
    "\n",
    "# Save as CSV for easy inspection\n",
    "matching_df = pd.DataFrame({\n",
    "    'rna_idx': full_matching[0],\n",
    "    'protein_idx': full_matching[1],\n",
    "    'score': full_matching[2]\n",
    "})\n",
    "matching_df.to_csv(f'{results_dir}/maxfuse_matching.csv', index=False)\n",
    "\n",
    "# Save unmatched RNA indices for further analysis\n",
    "np.save(f'{results_dir}/unmatched_rna_indices.npy', unmatched_rna_indices)\n",
    "print(f'Saved unmatched RNA indices: {len(unmatched_rna_indices):,} cells')\n",
    "\n",
    "# Save normalized arrays used for integration\n",
    "np.save(f'{results_dir}/rna_shared.npy', rna_shared)\n",
    "np.save(f'{results_dir}/rna_active.npy', rna_active)\n",
    "np.save(f'{results_dir}/protein_shared.npy', protein_shared)\n",
    "np.save(f'{results_dir}/protein_active.npy', protein_active)\n",
    "print(f'Saved normalized arrays')\n",
    "\n",
    "# Save correspondence table\n",
    "correspondence_df = pd.DataFrame(\n",
    "    rna_protein_correspondence, \n",
    "    columns=['rna_gene', 'protein_marker']\n",
    ")\n",
    "correspondence_df.to_csv(f'{results_dir}/correspondence.csv', index=False)\n",
    "\n",
    "# Save integration parameters\n",
    "n_matched_rna = len(np.unique(full_matching[0]))\n",
    "n_matched_prot = len(np.unique(full_matching[1]))\n",
    "integration_params = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'method': 'maxfuse',\n",
    "    'score_threshold': MIN_SCORE_THRESHOLD,\n",
    "    'fusor_params': {\n",
    "        'max_outward_size': max_outward,\n",
    "        'matching_ratio': matching_ratio,\n",
    "        'smoothing_method': fusor.method,\n",
    "        'n_shared_features': rna_shared.shape[1],\n",
    "        'cca_components': cca_components,\n",
    "        'pivot_filter_prop': pivot_filter_prop,\n",
    "        'propagate_filter_prop': propagate_filter_prop\n",
    "    },\n",
    "    'data_shapes': {\n",
    "        'rna_cells': rna_active.shape[0],\n",
    "        'protein_cells': protein_active.shape[0],\n",
    "        'rna_active_features': rna_active.shape[1],\n",
    "        'protein_active_features': protein_active.shape[1],\n",
    "        'shared_features': rna_shared.shape[1]\n",
    "    },\n",
    "    'matching_stats': {\n",
    "        'total_matches': len(full_matching[0]),\n",
    "        'unique_rna_matched': n_matched_rna,\n",
    "        'unique_protein_matched': n_matched_prot,\n",
    "        'rna_coverage_pct': 100 * n_matched_rna / rna_active.shape[0],\n",
    "        'protein_coverage_pct': 100 * n_matched_prot / protein_active.shape[0],\n",
    "        'unmatched_rna_cells': len(unmatched_rna_indices),\n",
    "        'mean_score': float(np.mean(full_matching[2])),\n",
    "        'min_score': float(np.min(full_matching[2])),\n",
    "        'max_score': float(np.max(full_matching[2]))\n",
    "    }\n",
    "}\n",
    "with open(f'{results_dir}/integration_params.json', 'w') as f:\n",
    "    json_module.dump(integration_params, f, indent=2)\n",
    "\n",
    "print(f'\\nAll outputs saved to {results_dir}/')\n",
    "print(f'  - maxfuse_matching.pkl (pickle)')\n",
    "print(f'  - maxfuse_matching.csv')\n",
    "print(f'  - unmatched_rna_indices.npy')\n",
    "print(f'  - rna_shared.npy, rna_active.npy')\n",
    "print(f'  - protein_shared.npy, protein_active.npy')\n",
    "print(f'  - correspondence.csv')\n",
    "print(f'  - integration_params.json')\n",
    "print(f'\\nRun 3_visualization.ipynb next.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wiakr9nznjh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RNA data to check what genes are available\n",
    "rna_adata = sc.read_h5ad('/home/smith6jt/maxfuse/results/1_preprocessing/rna_adata.h5ad')\n",
    "rna_genes = set(rna_adata.var_names)\n",
    "\n",
    "print(f\"RNA data has {len(rna_genes)} genes\")\n",
    "\n",
    "# Check which of the new mappings have their genes in RNA data\n",
    "print(\"\\nChecking new mappings against RNA data:\")\n",
    "for protein, gene in new_mappings:\n",
    "    if gene.startswith(\"Ignore\"):\n",
    "        print(f\"  {protein}: {gene} (skipped)\")\n",
    "        continue\n",
    "    \n",
    "    # Handle multiple gene options (separated by /)\n",
    "    gene_options = gene.split('/')\n",
    "    found = any(g in rna_genes for g in gene_options)\n",
    "    status = \"\u2713 Found\" if found else \"\u2717 NOT FOUND\"\n",
    "    print(f\"  {protein} -> {gene}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psrp4u3rb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reload data\n",
    "rna_adata = sc.read_h5ad('/home/smith6jt/maxfuse/results/1_preprocessing/rna_adata.h5ad')\n",
    "protein_adata = sc.read_h5ad('/home/smith6jt/maxfuse/results/1_preprocessing/protein_adata.h5ad')\n",
    "rna_genes = set(rna_adata.var_names)\n",
    "\n",
    "print(f\"RNA data has {len(rna_genes)} genes\")\n",
    "print(f\"Protein data has {len(protein_adata.var_names)} proteins\")\n",
    "\n",
    "# The new mappings I added\n",
    "new_mappings = [\n",
    "    (\"DAPI\", \"Ignore: DNA stain\"),\n",
    "    (\"IAPP\", \"IAPP\"),\n",
    "    (\"IDO1\", \"IDO1\"),\n",
    "    (\"INS\", \"INS\"),\n",
    "    (\"Ker8-18\", \"KRT8/KRT18\"),\n",
    "    (\"iNOS\", \"NOS2\"),\n",
    "    (\"M2Gal3\", \"LGALS3\"),\n",
    "    (\"B3TUBB\", \"TUBB3\"),\n",
    "    (\"PCNA\", \"PCNA\"),\n",
    "    (\"Granzyme B\", \"GZMB\"),\n",
    "    (\"HLA-A\", \"HLA-A\"),\n",
    "    (\"VISTA\", \"VSIR\"),\n",
    "    (\"Pan-Cytokeratin\", \"Ignore: too many genes\"),\n",
    "    (\"LAG3\", \"LAG3\"),\n",
    "    (\"SST\", \"SST\"),\n",
    "    (\"TCF-1\", \"TCF7\"),\n",
    "    (\"TOX\", \"TOX\"),\n",
    "    (\"Caveolin\", \"CAV1\"),\n",
    "    (\"ICOS\", \"ICOS\"),\n",
    "    (\"EpCAM\", \"EPCAM\"),\n",
    "    (\"Keratin 5\", \"KRT5\"),\n",
    "    (\"GCG\", \"GCG\"),\n",
    "    (\"Beta-actin\", \"ACTB\"),\n",
    "    (\"Bcl-2\", \"BCL2\"),\n",
    "    (\"MPO\", \"MPO\"),\n",
    "    (\"Iba1\", \"AIF1\"),\n",
    "    (\"SOX2\", \"SOX2\"),\n",
    "    (\"TP63\", \"TP63\"),\n",
    "]\n",
    "\n",
    "# Check which of the new mappings have their genes in RNA data\n",
    "print(\"\\nChecking new mappings against RNA data:\")\n",
    "not_found = []\n",
    "for protein, gene in new_mappings:\n",
    "    if gene.startswith(\"Ignore\"):\n",
    "        print(f\"  {protein}: {gene} (skipped)\")\n",
    "        continue\n",
    "    \n",
    "    # Handle multiple gene options (separated by /)\n",
    "    gene_options = gene.split('/')\n",
    "    found_genes = [g for g in gene_options if g in rna_genes]\n",
    "    \n",
    "    if found_genes:\n",
    "        print(f\"  {protein} -> {gene}: \u2713 Found ({', '.join(found_genes)})\")\n",
    "    else:\n",
    "        print(f\"  {protein} -> {gene}: \u2717 NOT IN RNA DATA\")\n",
    "        not_found.append((protein, gene))\n",
    "\n",
    "print(f\"\\n{len(not_found)} proteins have genes NOT in RNA data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h5mvu3dc0eu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fully simulate the notebook's matching logic\n",
    "conversion_df = pd.read_csv('/home/smith6jt/maxfuse/data/protein_gene_conversion.csv', encoding='utf-8-sig')\n",
    "\n",
    "proteins_in_adata = list(protein_adata.var_names)\n",
    "\n",
    "# Build a lookup dictionary (case-insensitive)\n",
    "protein_to_gene = {}\n",
    "for _, row in conversion_df.iterrows():\n",
    "    protein_to_gene[row['Protein name'].lower()] = row['RNA name']\n",
    "\n",
    "# Try to match each protein\n",
    "matched_pairs = []\n",
    "unmatched = []\n",
    "\n",
    "for marker in proteins_in_adata:\n",
    "    marker_lower = marker.lower()\n",
    "    \n",
    "    if marker_lower in protein_to_gene:\n",
    "        rna_name = protein_to_gene[marker_lower]\n",
    "        \n",
    "        # Skip \"Ignore\" entries\n",
    "        if rna_name.startswith('Ignore'):\n",
    "            unmatched.append((marker, f\"Ignored: {rna_name}\"))\n",
    "            continue\n",
    "        \n",
    "        # Handle multiple gene options\n",
    "        gene_options = rna_name.split('/')\n",
    "        found_gene = None\n",
    "        for gene in gene_options:\n",
    "            if gene in rna_genes:\n",
    "                found_gene = gene\n",
    "                break\n",
    "        \n",
    "        if found_gene:\n",
    "            matched_pairs.append((found_gene, marker))\n",
    "        else:\n",
    "            unmatched.append((marker, f\"{rna_name} (not in RNA data)\"))\n",
    "    else:\n",
    "        unmatched.append((marker, \"Not in conversion table\"))\n",
    "\n",
    "print(f\"Total proteins: {len(proteins_in_adata)}\")\n",
    "print(f\"Matched pairs: {len(matched_pairs)}\")\n",
    "print(f\"Unmatched: {len(unmatched)}\")\n",
    "\n",
    "print(\"\\nUnmatched proteins:\")\n",
    "for prot, reason in unmatched:\n",
    "    print(f\"  {prot}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ns4co3p6n08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for specific genes that should be common\n",
    "check_genes = ['MS4A1', 'FOXP3', 'CDH2', 'IAPP', 'NOS2', 'SST', 'GCG', 'MPO', 'SOX2', 'TP63']\n",
    "\n",
    "print(\"Checking for genes in RNA data:\")\n",
    "for gene in check_genes:\n",
    "    found = gene in rna_genes\n",
    "    # Also check for case variations\n",
    "    case_variations = [g for g in rna_genes if g.upper() == gene.upper()]\n",
    "    print(f\"  {gene}: {'\u2713 Found' if found else '\u2717 Not found'} {case_variations if case_variations else ''}\")\n",
    "\n",
    "# Search for partial matches\n",
    "print(\"\\nSearching for partial matches:\")\n",
    "for gene in check_genes:\n",
    "    matches = [g for g in rna_genes if gene.lower() in g.lower()]\n",
    "    if matches:\n",
    "        print(f\"  {gene}: {matches[:5]}\")  # Show first 5 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaq63wufm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how many genes were in the raw data vs filtered\n",
    "# Load the lognorm version (before any subsetting for HVGs)\n",
    "rna_lognorm = sc.read_h5ad('/home/smith6jt/maxfuse/results/1_preprocessing/rna_adata_lognorm.h5ad')\n",
    "\n",
    "lognorm_genes = set(rna_lognorm.var_names)\n",
    "print(f\"rna_adata.h5ad: {len(rna_genes)} genes\")\n",
    "print(f\"rna_adata_lognorm.h5ad: {len(lognorm_genes)} genes\")\n",
    "\n",
    "# Check if the missing genes are in the lognorm version\n",
    "print(\"\\nChecking if missing genes exist in rna_adata_lognorm:\")\n",
    "for gene in check_genes:\n",
    "    found_hvg = gene in rna_genes\n",
    "    found_lognorm = gene in lognorm_genes\n",
    "    print(f\"  {gene}: HVG={found_hvg}, lognorm={found_lognorm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s87st8r1tuo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw RNA data to check for these genes\n",
    "from scipy.io import mmread\n",
    "import gzip\n",
    "\n",
    "# Load raw gene names\n",
    "with gzip.open('/home/smith6jt/maxfuse/data/raw_feature_bc_matrix/features.tsv.gz', 'rt') as f:\n",
    "    raw_features = [line.strip().split('\\t') for line in f]\n",
    "\n",
    "raw_gene_ids = [f[0] for f in raw_features]\n",
    "raw_gene_names = [f[1] for f in raw_features]\n",
    "\n",
    "print(f\"Raw RNA data has {len(raw_gene_names)} genes\")\n",
    "\n",
    "# Check for the missing genes\n",
    "missing_genes = ['MS4A1', 'FOXP3', 'CDH2', 'IAPP', 'NOS2', 'SST', 'GCG', 'MPO', 'SOX2', 'TP63']\n",
    "\n",
    "print(\"\\nSearching for missing genes in raw data:\")\n",
    "found_indices = {}\n",
    "for gene in missing_genes:\n",
    "    if gene in raw_gene_names:\n",
    "        idx = raw_gene_names.index(gene)\n",
    "        found_indices[gene] = idx\n",
    "        print(f\"  {gene}: \u2713 Found at index {idx}\")\n",
    "    else:\n",
    "        # Check case variations\n",
    "        matches = [(i, g) for i, g in enumerate(raw_gene_names) if g.upper() == gene.upper()]\n",
    "        if matches:\n",
    "            idx, name = matches[0]\n",
    "            found_indices[gene] = idx\n",
    "            print(f\"  {gene}: \u2713 Found as '{name}' at index {idx}\")\n",
    "        else:\n",
    "            print(f\"  {gene}: \u2717 Not in raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kszyfwe8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw matrix to check expression\n",
    "print(\"Loading raw matrix...\")\n",
    "raw_matrix = mmread('/home/smith6jt/maxfuse/data/raw_feature_bc_matrix/matrix.mtx.gz').tocsc()\n",
    "print(f\"Raw matrix shape: {raw_matrix.shape} (genes x cells)\")\n",
    "\n",
    "# Check expression for each missing gene\n",
    "print(\"\\nExpression stats for missing genes in RAW data:\")\n",
    "print(f\"{'Gene':<10} {'Cells>0':>10} {'% cells':>10} {'Total UMI':>12} {'Max UMI':>10}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for gene in missing_genes:\n",
    "    idx = found_indices[gene]\n",
    "    gene_counts = raw_matrix[idx, :].toarray().flatten()\n",
    "    n_cells_expressing = (gene_counts > 0).sum()\n",
    "    pct_cells = 100 * n_cells_expressing / raw_matrix.shape[1]\n",
    "    total_umi = gene_counts.sum()\n",
    "    max_umi = gene_counts.max()\n",
    "    print(f\"{gene:<10} {n_cells_expressing:>10,} {pct_cells:>9.3f}% {total_umi:>12,.0f} {max_umi:>10,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rc6o32n02s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check how many of these expressing cells passed QC filtering\n",
    "# The cell filter keeps cells with: 100 <= UMI < 100000, 200 <= genes < 8000, MT% < 39.5\n",
    "\n",
    "# Load barcodes\n",
    "with gzip.open('/home/smith6jt/maxfuse/data/raw_feature_bc_matrix/barcodes.tsv.gz', 'rt') as f:\n",
    "    raw_barcodes = [line.strip() for line in f]\n",
    "\n",
    "# Calculate per-cell metrics on raw data\n",
    "print(\"Calculating cell QC metrics...\")\n",
    "cell_total_counts = np.array(raw_matrix.sum(axis=0)).flatten()\n",
    "cell_n_genes = np.array((raw_matrix > 0).sum(axis=0)).flatten()\n",
    "\n",
    "# MT genes\n",
    "mt_genes = [i for i, g in enumerate(raw_gene_names) if g.startswith('MT-')]\n",
    "mt_counts = np.array(raw_matrix[mt_genes, :].sum(axis=0)).flatten()\n",
    "pct_mt = np.where(cell_total_counts > 0, 100 * mt_counts / cell_total_counts, 0)\n",
    "\n",
    "# Apply same filters as preprocessing\n",
    "MIN_COUNTS, MAX_COUNTS = 100, 100000\n",
    "MIN_GENES, MAX_GENES = 200, 8000\n",
    "MAX_MT_PCT = 39.5\n",
    "\n",
    "cell_pass_qc = (\n",
    "    (cell_total_counts >= MIN_COUNTS) &\n",
    "    (cell_total_counts < MAX_COUNTS) &\n",
    "    (cell_n_genes >= MIN_GENES) &\n",
    "    (cell_n_genes < MAX_GENES) &\n",
    "    (pct_mt < MAX_MT_PCT)\n",
    ")\n",
    "\n",
    "print(f\"Cells passing QC: {cell_pass_qc.sum():,} / {len(cell_pass_qc):,}\")\n",
    "\n",
    "# Check each gene - how many expressing cells pass QC?\n",
    "print(\"\\nExpression in QC-passed cells:\")\n",
    "print(f\"{'Gene':<10} {'Raw cells':>10} {'QC cells':>10} {'Filtered?':>12}\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for gene in missing_genes:\n",
    "    idx = found_indices[gene]\n",
    "    gene_counts = raw_matrix[idx, :].toarray().flatten()\n",
    "    \n",
    "    # Cells expressing this gene\n",
    "    expressing = gene_counts > 0\n",
    "    n_raw = expressing.sum()\n",
    "    \n",
    "    # Of those, how many pass QC?\n",
    "    n_qc = (expressing & cell_pass_qc).sum()\n",
    "    \n",
    "    filtered = \"YES\" if n_qc < 3 else \"no\"\n",
    "    print(f\"{gene:<10} {n_raw:>10,} {n_qc:>10,} {filtered:>12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ogfofwfckg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check protein detection rates for the \"missing\" markers\n",
    "missing_proteins = ['IAPP', 'E-cadherin', 'iNOS', 'FOXP3', 'CD20', 'SST', 'GCG', 'MPO', 'SOX2', 'TP63']\n",
    "\n",
    "print(\"Protein detection rates in CODEX data:\")\n",
    "print(f\"{'Protein':<15} {'Detection %':>12} {'Mean expr':>12}\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "for prot in missing_proteins:\n",
    "    if prot in protein_adata.var_names:\n",
    "        expr = protein_adata[:, prot].X.flatten()\n",
    "        detection = (expr > 0).mean() * 100\n",
    "        mean_expr = expr.mean()\n",
    "        print(f\"{prot:<15} {detection:>11.1f}% {mean_expr:>12.2f}\")\n",
    "    else:\n",
    "        print(f\"{prot:<15} Not found in protein_adata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qqzrnm4co7j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the CODEX data source\n",
    "import os\n",
    "\n",
    "# List data files to identify tissue\n",
    "data_files = os.listdir('/home/smith6jt/maxfuse/data/')\n",
    "print(\"Data files:\")\n",
    "for f in sorted(data_files):\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Check the CODEX filename pattern\n",
    "codex_files = [f for f in data_files if f.endswith('.tsv') or 'codex' in f.lower() or 'CC' in f]\n",
    "print(f\"\\nCODEX-related files: {codex_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwroqwn1qgq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 6551_cells.csv to understand the tissue\n",
    "cells_df = pd.read_csv('/home/smith6jt/maxfuse/data/6551_cells.csv', nrows=5)\n",
    "print(\"Columns in 6551_cells.csv:\")\n",
    "print(cells_df.columns.tolist()[:20])  # First 20 columns\n",
    "\n",
    "# Check if there's tissue info in the preprocessing notebook params\n",
    "import json\n",
    "params_file = '/home/smith6jt/maxfuse/results/1_preprocessing/preprocessing_params.json'\n",
    "if os.path.exists(params_file):\n",
    "    with open(params_file) as f:\n",
    "        params = json.load(f)\n",
    "    print(f\"\\nPreprocessing params:\")\n",
    "    print(json.dumps(params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yohyyvrecib",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of RNA genes we need to protect (from conversion table)\n",
    "conversion_df = pd.read_csv('/home/smith6jt/maxfuse/data/protein_gene_conversion.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Extract all gene names (handling multiple options separated by /)\n",
    "protected_genes = set()\n",
    "for rna_name in conversion_df['RNA name']:\n",
    "    if pd.isna(rna_name) or rna_name.startswith('Ignore'):\n",
    "        continue\n",
    "    for gene in rna_name.split('/'):\n",
    "        gene = gene.strip()\n",
    "        if gene:\n",
    "            protected_genes.add(gene)\n",
    "\n",
    "print(f\"Protected genes from conversion table: {len(protected_genes)}\")\n",
    "\n",
    "# Check which of these exist in raw data\n",
    "raw_gene_set = set(raw_gene_names)\n",
    "protected_in_raw = protected_genes & raw_gene_set\n",
    "print(f\"Protected genes found in raw RNA data: {len(protected_in_raw)}\")\n",
    "\n",
    "# The missing ones\n",
    "missing_protected = protected_genes - raw_gene_set\n",
    "if missing_protected:\n",
    "    print(f\"\\nProtected genes NOT in raw data ({len(missing_protected)}):\")\n",
    "    for g in sorted(missing_protected)[:10]:\n",
    "        print(f\"  {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjjmdn66u1m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the fix: filter genes but preserve marker genes\n",
    "# This is what needs to go in notebook 1_preprocessing.ipynb\n",
    "\n",
    "# Reload raw matrix for demonstration\n",
    "print(\"Demonstrating marker-preserving gene filter...\")\n",
    "\n",
    "# Standard filter: min_cells=3\n",
    "standard_gene_counts = np.array((raw_matrix > 0).sum(axis=1)).flatten()\n",
    "standard_keep = standard_gene_counts >= 3\n",
    "print(f\"Standard filter (min_cells=3): {standard_keep.sum():,} genes\")\n",
    "\n",
    "# Find indices of protected genes in raw data\n",
    "protected_indices = set()\n",
    "for gene in protected_in_raw:\n",
    "    if gene in raw_gene_names:\n",
    "        protected_indices.add(raw_gene_names.index(gene))\n",
    "\n",
    "print(f\"Protected marker genes: {len(protected_indices)}\")\n",
    "\n",
    "# Combined filter: keep if (min_cells >= 3) OR (is protected marker)\n",
    "protected_mask = np.zeros(len(raw_gene_names), dtype=bool)\n",
    "protected_mask[list(protected_indices)] = True\n",
    "\n",
    "combined_keep = standard_keep | protected_mask\n",
    "print(f\"Combined filter (standard OR protected): {combined_keep.sum():,} genes\")\n",
    "\n",
    "# How many marker genes are rescued?\n",
    "rescued = protected_mask & ~standard_keep\n",
    "print(f\"\\nMarker genes rescued by protection: {rescued.sum()}\")\n",
    "\n",
    "# Show which ones\n",
    "rescued_genes = [raw_gene_names[i] for i in range(len(raw_gene_names)) if rescued[i]]\n",
    "print(f\"Rescued genes: {rescued_genes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfwp4hoaw0r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the marker-preserving filter logic\n",
    "# Simulate what the updated notebook cell will do\n",
    "\n",
    "# We already have rna_adata loaded with 33538 genes (raw)\n",
    "# Let's simulate the full pipeline\n",
    "\n",
    "from scipy.io import mmread\n",
    "import gzip\n",
    "\n",
    "# Reload raw data\n",
    "print(\"Loading raw data...\")\n",
    "rna_mtx = mmread('/home/smith6jt/maxfuse/data/raw_feature_bc_matrix/matrix.mtx.gz')\n",
    "with gzip.open('/home/smith6jt/maxfuse/data/raw_feature_bc_matrix/features.tsv.gz', 'rt') as f:\n",
    "    raw_features = [line.strip().split('\\t') for line in f]\n",
    "raw_gene_names = [f[1] for f in raw_features]\n",
    "\n",
    "rna_adata_test = ad.AnnData(rna_mtx.T.tocsr(), dtype=np.float32)\n",
    "rna_adata_test.var_names = raw_gene_names\n",
    "rna_adata_test.var_names_make_unique()\n",
    "\n",
    "# Calculate QC metrics\n",
    "rna_adata_test.var['mt'] = rna_adata_test.var_names.str.startswith('MT-')\n",
    "sc.pp.calculate_qc_metrics(rna_adata_test, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "print(f\"Raw: {rna_adata_test.shape}\")\n",
    "\n",
    "# Apply cell filters (same as notebook)\n",
    "sc.pp.filter_cells(rna_adata_test, min_counts=100)\n",
    "sc.pp.filter_cells(rna_adata_test, min_genes=46)\n",
    "rna_adata_test = rna_adata_test[rna_adata_test.obs['total_counts'] < 92731, :].copy()\n",
    "rna_adata_test = rna_adata_test[rna_adata_test.obs['n_genes_by_counts'] < 7066, :].copy()\n",
    "rna_adata_test = rna_adata_test[rna_adata_test.obs['pct_counts_mt'] < 39.5, :].copy()\n",
    "\n",
    "print(f\"After cell filters: {rna_adata_test.shape}\")\n",
    "\n",
    "# Now test marker-preserving gene filter\n",
    "conversion_df = pd.read_csv('/home/smith6jt/maxfuse/data/protein_gene_conversion.csv', encoding='utf-8-sig')\n",
    "\n",
    "protected_genes = set()\n",
    "for rna_name in conversion_df['RNA name']:\n",
    "    if pd.isna(rna_name) or str(rna_name).startswith('Ignore'):\n",
    "        continue\n",
    "    for gene in str(rna_name).split('/'):\n",
    "        gene = gene.strip()\n",
    "        if gene:\n",
    "            protected_genes.add(gene)\n",
    "\n",
    "print(f\"\\nProtected genes from conversion table: {len(protected_genes)}\")\n",
    "\n",
    "protected_in_data = protected_genes & set(rna_adata_test.var_names)\n",
    "print(f\"Protected genes found in filtered RNA data: {len(protected_in_data)}\")\n",
    "\n",
    "# Calculate cells per gene\n",
    "n_cells_per_gene = np.array((rna_adata_test.X > 0).sum(axis=0)).flatten()\n",
    "\n",
    "standard_keep = n_cells_per_gene >= 3\n",
    "protected_mask = np.array([g in protected_in_data for g in rna_adata_test.var_names])\n",
    "combined_keep = standard_keep | protected_mask\n",
    "\n",
    "rescued_mask = protected_mask & ~standard_keep\n",
    "n_rescued = rescued_mask.sum()\n",
    "rescued_gene_names = [g for g, r in zip(rna_adata_test.var_names, rescued_mask) if r]\n",
    "\n",
    "print(f\"\\nStandard filter (min_cells=3): {standard_keep.sum():,} genes\")\n",
    "print(f\"Combined filter (standard OR protected): {combined_keep.sum():,} genes\")\n",
    "print(f\"Marker genes rescued: {n_rescued}\")\n",
    "print(f\"Rescued genes: {rescued_gene_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9avdpzrhe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter and check how many protein-gene pairs we get\n",
    "rna_adata_test = rna_adata_test[:, combined_keep].copy()\n",
    "print(f\"Final RNA data with marker preservation: {rna_adata_test.shape}\")\n",
    "\n",
    "# Now simulate the integration matching\n",
    "proteins_in_adata = list(protein_adata.var_names)\n",
    "rna_genes_new = set(rna_adata_test.var_names)\n",
    "\n",
    "# Build lookup\n",
    "protein_to_gene = {}\n",
    "for _, row in conversion_df.iterrows():\n",
    "    protein_to_gene[row['Protein name'].lower()] = row['RNA name']\n",
    "\n",
    "# Try to match\n",
    "matched_pairs_new = []\n",
    "unmatched_new = []\n",
    "\n",
    "for marker in proteins_in_adata:\n",
    "    marker_lower = marker.lower()\n",
    "    \n",
    "    if marker_lower in protein_to_gene:\n",
    "        rna_name = protein_to_gene[marker_lower]\n",
    "        \n",
    "        if pd.isna(rna_name) or str(rna_name).startswith('Ignore'):\n",
    "            unmatched_new.append((marker, f\"Ignored: {rna_name}\"))\n",
    "            continue\n",
    "        \n",
    "        gene_options = str(rna_name).split('/')\n",
    "        found_gene = None\n",
    "        for gene in gene_options:\n",
    "            if gene.strip() in rna_genes_new:\n",
    "                found_gene = gene.strip()\n",
    "                break\n",
    "        \n",
    "        if found_gene:\n",
    "            matched_pairs_new.append((found_gene, marker))\n",
    "        else:\n",
    "            unmatched_new.append((marker, f\"{rna_name} (not in RNA data)\"))\n",
    "    else:\n",
    "        unmatched_new.append((marker, \"Not in conversion table\"))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"COMPARISON: Before vs After marker preservation\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Before (standard min_cells=3): 47 matched pairs\")\n",
    "print(f\"After (marker-preserving):     {len(matched_pairs_new)} matched pairs\")\n",
    "print(f\"Improvement:                   +{len(matched_pairs_new) - 47} pairs\")\n",
    "\n",
    "print(f\"\\nUnmatched proteins ({len(unmatched_new)}):\")\n",
    "for prot, reason in unmatched_new:\n",
    "    print(f\"  {prot}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hxkjqlq2yf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine protein intensity distributions to understand background\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the protein data\n",
    "protein_adata = sc.read_h5ad('/home/smith6jt/maxfuse/results/1_preprocessing/protein_adata.h5ad')\n",
    "\n",
    "print(\"Protein intensity statistics:\")\n",
    "print(f\"{'Marker':<20} {'Min':>10} {'5%':>10} {'Median':>10} {'95%':>10} {'Max':>10}\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "for marker in protein_adata.var_names[:15]:  # First 15 markers\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    print(f\"{marker:<20} {vals.min():>10.1f} {np.percentile(vals, 5):>10.1f} \"\n",
    "          f\"{np.median(vals):>10.1f} {np.percentile(vals, 95):>10.1f} {vals.max():>10.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ueg8uovhouj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different arcsinh cofactors and their effect on detection\n",
    "# The issue: with cofactor=5, even background values (5th percentile) become \"detected\"\n",
    "\n",
    "print(\"Effect of different cofactors on background vs signal separation:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Pick a few representative markers\n",
    "test_markers = ['IAPP', 'CD68', 'SMA', 'CD20', 'SST', 'GCG']\n",
    "cofactors = [5, 50, 150, 500]\n",
    "\n",
    "for marker in test_markers:\n",
    "    if marker not in protein_adata.var_names:\n",
    "        continue\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p5, p50, p95 = np.percentile(vals, [5, 50, 95])\n",
    "    \n",
    "    print(f\"\\n{marker}: raw 5%={p5:.1f}, median={p50:.1f}, 95%={p95:.1f}\")\n",
    "    \n",
    "    for cofactor in cofactors:\n",
    "        transformed = np.arcsinh(vals / cofactor)\n",
    "        t5, t50, t95 = np.percentile(transformed, [5, 50, 95])\n",
    "        \n",
    "        # Estimate \"detection\" using a threshold\n",
    "        # With arcsinh, values < ~0.5 could be considered background\n",
    "        pct_above_05 = (transformed > 0.5).mean() * 100\n",
    "        pct_above_1 = (transformed > 1.0).mean() * 100\n",
    "        \n",
    "        print(f\"  cofactor={cofactor:>3}: arcsinh 5%={t5:.2f}, med={t50:.2f}, 95%={t95:.2f} | \"\n",
    "              f\">0.5: {pct_above_05:.0f}%, >1.0: {pct_above_1:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x1p3vb5nwk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also try background subtraction approach\n",
    "# Subtract per-marker background (e.g., 5th or 10th percentile) before arcsinh\n",
    "\n",
    "print(\"Background subtraction + arcsinh approach:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for marker in test_markers:\n",
    "    if marker not in protein_adata.var_names:\n",
    "        continue\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    \n",
    "    # Background subtraction options\n",
    "    bg_5 = np.percentile(vals, 5)\n",
    "    bg_10 = np.percentile(vals, 10)\n",
    "    \n",
    "    # Subtract background, clip to 0\n",
    "    vals_sub5 = np.clip(vals - bg_5, 0, None)\n",
    "    vals_sub10 = np.clip(vals - bg_10, 0, None)\n",
    "    \n",
    "    print(f\"\\n{marker}: raw bg(5%)={bg_5:.1f}, bg(10%)={np.percentile(vals, 10):.1f}\")\n",
    "    \n",
    "    # After background subtraction, use standard cofactor=5\n",
    "    for name, vals_sub in [(\"sub 5%\", vals_sub5), (\"sub 10%\", vals_sub10)]:\n",
    "        transformed = np.arcsinh(vals_sub / 5)\n",
    "        pct_zero = (vals_sub == 0).mean() * 100\n",
    "        pct_above_05 = (transformed > 0.5).mean() * 100\n",
    "        t50 = np.median(transformed[transformed > 0]) if (transformed > 0).any() else 0\n",
    "        \n",
    "        print(f\"  {name}: {pct_zero:.0f}% zeros, {pct_above_05:.0f}% >0.5 (median of non-zero: {t50:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yuzwagyai97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try data-driven cofactor: use median intensity as cofactor\n",
    "# This normalizes each marker relative to its own scale\n",
    "\n",
    "print(\"Data-driven cofactor approach (cofactor = marker median):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for marker in test_markers:\n",
    "    if marker not in protein_adata.var_names:\n",
    "        continue\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    \n",
    "    # Use median as cofactor\n",
    "    cofactor_median = np.median(vals)\n",
    "    # Use 75th percentile as cofactor  \n",
    "    cofactor_p75 = np.percentile(vals, 75)\n",
    "    \n",
    "    print(f\"\\n{marker}: median={cofactor_median:.1f}, p75={np.percentile(vals, 75):.1f}\")\n",
    "    \n",
    "    for name, cof in [(\"median\", cofactor_median), (\"p75\", cofactor_p75)]:\n",
    "        transformed = np.arcsinh(vals / cof)\n",
    "        t5, t50, t95 = np.percentile(transformed, [5, 50, 95])\n",
    "        pct_above_05 = (transformed > 0.5).mean() * 100\n",
    "        pct_above_1 = (transformed > 1.0).mean() * 100\n",
    "        \n",
    "        print(f\"  cof={name}: 5%={t5:.2f}, med={t50:.2f}, 95%={t95:.2f} | >0.5: {pct_above_05:.0f}%, >1.0: {pct_above_1:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfqmn4b8bej",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze this dataset's intensity distribution to derive a formula\n",
    "# Goal: formula that gives ~150 for this data, ~5 for typical CyTOF data\n",
    "\n",
    "# Get all protein values\n",
    "all_protein_vals = protein_adata.X.flatten()\n",
    "\n",
    "print(\"Current dataset intensity statistics:\")\n",
    "print(f\"  Min: {all_protein_vals.min():.1f}\")\n",
    "print(f\"  5th percentile: {np.percentile(all_protein_vals, 5):.1f}\")\n",
    "print(f\"  10th percentile: {np.percentile(all_protein_vals, 10):.1f}\")\n",
    "print(f\"  25th percentile: {np.percentile(all_protein_vals, 25):.1f}\")\n",
    "print(f\"  Median: {np.median(all_protein_vals):.1f}\")\n",
    "print(f\"  75th percentile: {np.percentile(all_protein_vals, 75):.1f}\")\n",
    "print(f\"  95th percentile: {np.percentile(all_protein_vals, 95):.1f}\")\n",
    "print(f\"  Max: {all_protein_vals.max():.1f}\")\n",
    "\n",
    "# Per-marker medians\n",
    "marker_medians = [np.median(protein_adata[:, m].X.flatten()) for m in protein_adata.var_names]\n",
    "print(f\"\\n  Median of marker medians: {np.median(marker_medians):.1f}\")\n",
    "print(f\"  Mean of marker medians: {np.mean(marker_medians):.1f}\")\n",
    "\n",
    "# For CyTOF data, typical values after transformation are 0-10 range\n",
    "# arcsinh(x/5) with x~25 gives ~2.3\n",
    "# For this CODEX data, median is ~170, so arcsinh(170/5) = 4.2 (too compressed)\n",
    "# We want arcsinh(170/150) = 0.99 (better dynamic range)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Formula derivation:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "For arcsinh transformation to work well:\n",
    "- Background (5th percentile) should map to ~0.1-0.3\n",
    "- Signal (median-95th) should map to ~0.5-2.0\n",
    "\n",
    "arcsinh(x/c) \u2248 0.2 when x/c \u2248 0.2, so c \u2248 5*x for 5th percentile\n",
    "\n",
    "Proposed formula: COFACTOR = 5th_percentile * 5\n",
    "\"\"\")\n",
    "\n",
    "# Test the formula\n",
    "p5_global = np.percentile(all_protein_vals, 5)\n",
    "proposed_cofactor = p5_global * 5\n",
    "\n",
    "print(f\"5th percentile of all values: {p5_global:.1f}\")\n",
    "print(f\"Proposed cofactor (5th_pct * 5): {proposed_cofactor:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qpm63srexef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-marker cofactor calculation\n",
    "# Formula: cofactor = 5th_percentile * k, where k is a scaling factor\n",
    "\n",
    "print(\"Per-marker cofactor analysis:\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Marker':<18} {'5th%':>8} {'Median':>8} {'95th%':>8} | {'cof=5':>8} {'cof=p5*5':>8} {'cof=p5*10':>8}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "results = []\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    p50 = np.median(vals)\n",
    "    p95 = np.percentile(vals, 95)\n",
    "    \n",
    "    # Test different cofactor formulas\n",
    "    # Detection rate (>0.5 after arcsinh) for each\n",
    "    for cof_name, cof in [(\"cof=5\", 5), (\"cof=p5*5\", p5*5), (\"cof=p5*10\", p5*10)]:\n",
    "        cof = max(cof, 1)  # Avoid division by zero\n",
    "        transformed = np.arcsinh(vals / cof)\n",
    "        det_rate = (transformed > 0.5).mean() * 100\n",
    "        results.append({\n",
    "            'marker': marker, 'p5': p5, 'p50': p50, 'p95': p95,\n",
    "            'cof_name': cof_name, 'cofactor': cof, 'det_rate': det_rate\n",
    "        })\n",
    "\n",
    "# Print summary for first 15 markers\n",
    "for marker in protein_adata.var_names[:15]:\n",
    "    marker_results = [r for r in results if r['marker'] == marker]\n",
    "    p5 = marker_results[0]['p5']\n",
    "    p50 = marker_results[0]['p50']\n",
    "    p95 = marker_results[0]['p95']\n",
    "    det_5 = [r['det_rate'] for r in marker_results if r['cof_name'] == 'cof=5'][0]\n",
    "    det_p5x5 = [r['det_rate'] for r in marker_results if r['cof_name'] == 'cof=p5*5'][0]\n",
    "    det_p5x10 = [r['det_rate'] for r in marker_results if r['cof_name'] == 'cof=p5*10'][0]\n",
    "    \n",
    "    print(f\"{marker:<18} {p5:>8.1f} {p50:>8.1f} {p95:>8.1f} | {det_5:>7.0f}% {det_p5x5:>7.0f}% {det_p5x10:>7.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bz1zn2otqu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try median-based formula: cofactor = median / k\n",
    "# For CyTOF: median ~5-10, cofactor=5 means k=1-2\n",
    "# For CODEX: median ~200, cofactor=150 means k~1.3\n",
    "\n",
    "print(\"Testing median-based formula: cofactor = median / k\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Marker':<18} {'Median':>8} | {'cof=med':>10} {'cof=med/2':>10} {'cof=med/1.5':>10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for marker in protein_adata.var_names[:15]:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p50 = np.median(vals)\n",
    "    \n",
    "    det_rates = {}\n",
    "    for k, name in [(1, 'cof=med'), (2, 'cof=med/2'), (1.5, 'cof=med/1.5')]:\n",
    "        cof = max(p50 / k, 1)\n",
    "        transformed = np.arcsinh(vals / cof)\n",
    "        det_rates[name] = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    print(f\"{marker:<18} {p50:>8.1f} | {det_rates['cof=med']:>9.0f}% {det_rates['cof=med/2']:>9.0f}% {det_rates['cof=med/1.5']:>9.0f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"For CyTOF comparison (typical values):\")\n",
    "print(\"  If median ~5, cofactor=median gives cof=5 \u2713\")\n",
    "print(\"  If median ~200, cofactor=median gives cof=200\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gwt3tywmrnq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's think about this differently\n",
    "# The key insight: cofactor=5 works for CyTOF because typical values are ~0-50\n",
    "# For this CODEX data, typical values are ~0-500+\n",
    "\n",
    "# What if: cofactor = data scale indicator\n",
    "# For CyTOF: 95th percentile ~50, so cofactor = 95th/10 = 5\n",
    "# For CODEX: 95th percentile ~1500, so cofactor = 95th/10 = 150\n",
    "\n",
    "print(\"Testing 95th percentile-based formula: cofactor = p95 / 10\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "all_markers_results = []\n",
    "\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    p50 = np.median(vals)\n",
    "    p95 = np.percentile(vals, 95)\n",
    "    \n",
    "    # Formula: cofactor = p95 / 10\n",
    "    cof = p95 / 10\n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    # Also compute what arcsinh values the percentiles map to\n",
    "    arcsinh_p5 = np.arcsinh(p5 / cof)\n",
    "    arcsinh_p50 = np.arcsinh(p50 / cof)\n",
    "    arcsinh_p95 = np.arcsinh(p95 / cof)\n",
    "    \n",
    "    all_markers_results.append({\n",
    "        'marker': marker, 'p5': p5, 'p50': p50, 'p95': p95, \n",
    "        'cofactor': cof, 'det_rate': det_rate,\n",
    "        'arcsinh_p5': arcsinh_p5, 'arcsinh_p50': arcsinh_p50, 'arcsinh_p95': arcsinh_p95\n",
    "    })\n",
    "\n",
    "print(f\"{'Marker':<18} {'p95':>8} {'Cofactor':>10} | {'as(p5)':>8} {'as(p50)':>8} {'as(p95)':>8} | {'Det%':>6}\")\n",
    "print(\"-\" * 90)\n",
    "for r in all_markers_results[:15]:\n",
    "    print(f\"{r['marker']:<18} {r['p95']:>8.1f} {r['cofactor']:>10.1f} | \"\n",
    "          f\"{r['arcsinh_p5']:>8.2f} {r['arcsinh_p50']:>8.2f} {r['arcsinh_p95']:>8.2f} | {r['det_rate']:>5.0f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary:\")\n",
    "avg_det = np.mean([r['det_rate'] for r in all_markers_results])\n",
    "avg_arcsinh_p5 = np.mean([r['arcsinh_p5'] for r in all_markers_results])\n",
    "avg_arcsinh_p50 = np.mean([r['arcsinh_p50'] for r in all_markers_results])\n",
    "print(f\"  Average detection rate: {avg_det:.1f}%\")\n",
    "print(f\"  Average arcsinh(5th pct): {avg_arcsinh_p5:.2f}\")\n",
    "print(f\"  Average arcsinh(median): {avg_arcsinh_p50:.2f}\")\n",
    "print(\"\\nFormula: COFACTOR = 95th_percentile / 10\")\n",
    "print(\"For CyTOF (p95~50): cofactor = 5\")\n",
    "print(\"For this CODEX (p95~1500): cofactor = 150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3m8o12doomk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more aggressive scaling\n",
    "# Goal: arcsinh(background) < 0.5, arcsinh(high signal) ~ 2-3\n",
    "\n",
    "print(\"Comparing formulas:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "formulas = [\n",
    "    (\"p95/10\", lambda p5, p50, p95: p95/10),\n",
    "    (\"p95/5\", lambda p5, p50, p95: p95/5),\n",
    "    (\"p50\", lambda p5, p50, p95: p50),\n",
    "    (\"p50*2\", lambda p5, p50, p95: p50*2),\n",
    "]\n",
    "\n",
    "print(f\"{'Marker':<15}\", end=\"\")\n",
    "for name, _ in formulas:\n",
    "    print(f\" | {name:^18}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * 100)\n",
    "\n",
    "summary_stats = {name: [] for name, _ in formulas}\n",
    "\n",
    "for marker in protein_adata.var_names[:12]:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    p50 = np.median(vals)\n",
    "    p95 = np.percentile(vals, 95)\n",
    "    \n",
    "    print(f\"{marker:<15}\", end=\"\")\n",
    "    \n",
    "    for name, formula in formulas:\n",
    "        cof = max(formula(p5, p50, p95), 1)\n",
    "        transformed = np.arcsinh(vals / cof)\n",
    "        det_rate = (transformed > 0.5).mean() * 100\n",
    "        arcsinh_p5 = np.arcsinh(p5 / cof)\n",
    "        \n",
    "        print(f\" | cof={cof:>5.0f} det={det_rate:>3.0f}%\", end=\"\")\n",
    "        summary_stats[name].append(det_rate)\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Average detection rates:\")\n",
    "for name, rates in summary_stats.items():\n",
    "    print(f\"  {name}: {np.mean(rates):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tnzt9z8bkir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: we need BOTH cofactor and threshold to be data-driven\n",
    "# \n",
    "# For CyTOF (median ~5): cofactor=5 means values at median give arcsinh(1)=0.88\n",
    "# So the implicit \"detection\" is roughly \"above median\"\n",
    "#\n",
    "# Let's use: cofactor = median, and detection threshold = arcsinh(1) \u2248 0.88\n",
    "# This means \"detected\" = value > median (consistent interpretation)\n",
    "\n",
    "print(\"Data-driven approach: cofactor = median, threshold = arcsinh(1)\")\n",
    "print(\"This means 'detected' \u2248 'above median intensity'\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "THRESHOLD = np.arcsinh(1)  # \u2248 0.88\n",
    "\n",
    "print(f\"\\nThreshold: arcsinh(1) = {THRESHOLD:.3f}\")\n",
    "print(f\"{'Marker':<18} {'Median':>10} {'Cofactor':>10} | {'Det (>0.5)':>12} {'Det (>0.88)':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for marker in protein_adata.var_names[:15]:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p50 = np.median(vals)\n",
    "    \n",
    "    cof = p50\n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    \n",
    "    det_05 = (transformed > 0.5).mean() * 100\n",
    "    det_088 = (transformed > THRESHOLD).mean() * 100\n",
    "    \n",
    "    print(f\"{marker:<18} {p50:>10.1f} {cof:>10.1f} | {det_05:>11.0f}% {det_088:>11.0f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Verification for CyTOF-like data:\")\n",
    "print(\"  If median=5, cofactor=5\")\n",
    "print(\"  arcsinh(5/5) = arcsinh(1) = 0.88 (at threshold)\")\n",
    "print(\"  So ~50% of cells detected (those above median) \u2713\")\n",
    "print(\"\\nFor this CODEX data:\")\n",
    "print(\"  median~200, cofactor=200\") \n",
    "print(\"  arcsinh(200/200) = 0.88 (at threshold)\")\n",
    "print(\"  ~50% detection (those above median) \u2713\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bhoauupe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better approach: cofactor = median, but use a lower threshold\n",
    "# This way markers with actual signal will show higher detection\n",
    "# \n",
    "# Key: arcsinh(0.5) \u2248 0.48, so threshold=0.5 means \"above 0.5*median\"\n",
    "\n",
    "print(\"Final formula: cofactor = median, threshold = 0.5\")\n",
    "print(\"'Detected' means value > 0.52 * median (arcsinh(0.52) \u2248 0.5)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "results_final = []\n",
    "\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p50 = np.median(vals)\n",
    "    \n",
    "    # Cofactor = median\n",
    "    cof = p50\n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    \n",
    "    # Detection at threshold 0.5\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    # Also compute the arcsinh of key percentiles\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    p95 = np.percentile(vals, 95)\n",
    "    \n",
    "    results_final.append({\n",
    "        'marker': marker,\n",
    "        'median': p50,\n",
    "        'cofactor': cof,\n",
    "        'det_rate': det_rate,\n",
    "        'arcsinh_p5': np.arcsinh(p5/cof),\n",
    "        'arcsinh_p95': np.arcsinh(p95/cof)\n",
    "    })\n",
    "\n",
    "print(f\"{'Marker':<18} {'Median':>8} {'Det%':>8} | {'as(p5)':>8} {'as(p95)':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for r in results_final[:20]:\n",
    "    print(f\"{r['marker']:<18} {r['median']:>8.1f} {r['det_rate']:>7.0f}% | {r['arcsinh_p5']:>8.2f} {r['arcsinh_p95']:>8.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Average detection rate: {np.mean([r['det_rate'] for r in results_final]):.1f}%\")\n",
    "print(f\"Detection range: {min(r['det_rate'] for r in results_final):.0f}% - {max(r['det_rate'] for r in results_final):.0f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FORMULA SUMMARY:\")\n",
    "print(\"  COFACTOR = median(marker_values)\")\n",
    "print(\"  For CyTOF (median~5): cofactor \u2248 5\")\n",
    "print(\"  For CODEX (median~200): cofactor \u2248 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ep4x228l25i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find a formula that maps:\n",
    "# CyTOF (low values) -> cofactor ~5\n",
    "# CODEX (high values) -> cofactor ~150\n",
    "\n",
    "# Try different percentile-based formulas\n",
    "print(\"Finding the right formula:\")\n",
    "print(\"Target: CyTOF (p75~50) -> cof=5, CODEX (p75~500) -> cof=150\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For this CODEX data, calculate what divisor gives ~150 for different percentiles\n",
    "for pct in [50, 75, 90, 95]:\n",
    "    pct_vals = [np.percentile(protein_adata[:, m].X.flatten(), pct) for m in protein_adata.var_names]\n",
    "    avg_pct = np.mean(pct_vals)\n",
    "    \n",
    "    # What divisor gives cofactor=150 for this percentile?\n",
    "    divisor_for_150 = avg_pct / 150\n",
    "    # What divisor gives cofactor=5 assuming CyTOF has values ~10x lower?\n",
    "    divisor_for_5_cytof = (avg_pct / 10) / 5  # Assuming CyTOF is 10x lower\n",
    "    \n",
    "    print(f\"p{pct}: avg={avg_pct:.0f}, divisor for cof=150: {divisor_for_150:.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Proposed formula: COFACTOR = 75th_percentile / 3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test this formula\n",
    "for marker in protein_adata.var_names[:15]:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p75 = np.percentile(vals, 75)\n",
    "    cof = p75 / 3\n",
    "    \n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    print(f\"{marker:<18} p75={p75:>8.1f} cof={cof:>6.1f} det={det_rate:>3.0f}%\")\n",
    "\n",
    "# Average cofactor\n",
    "avg_cof = np.mean([np.percentile(protein_adata[:, m].X.flatten(), 75) / 3 for m in protein_adata.var_names])\n",
    "print(f\"\\nAverage cofactor: {avg_cof:.0f}\")\n",
    "print(f\"For CyTOF with p75~50: cofactor = 50/3 = {50/3:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3oyov7elj0w",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about it differently:\n",
    "# The cofactor should be proportional to the BACKGROUND level, not signal\n",
    "# Background = lower percentiles (5th, 10th)\n",
    "# \n",
    "# For CyTOF: background ~1, cofactor=5 means 5x background\n",
    "# For CODEX: background ~30, we want cofactor ~150, that's 5x background\n",
    "\n",
    "print(\"Testing: COFACTOR = 10th_percentile * 5\")\n",
    "print(\"Rationale: cofactor should be ~5x the background level\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p10 = np.percentile(vals, 10)\n",
    "    cof = max(p10 * 5, 5)  # Minimum cofactor of 5\n",
    "    \n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    results.append({'marker': marker, 'p10': p10, 'cof': cof, 'det': det_rate})\n",
    "\n",
    "print(f\"{'Marker':<18} {'p10':>8} {'Cofactor':>10} {'Det%':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for r in results[:20]:\n",
    "    print(f\"{r['marker']:<18} {r['p10']:>8.1f} {r['cof']:>10.1f} {r['det']:>7.0f}%\")\n",
    "\n",
    "avg_cof = np.mean([r['cof'] for r in results])\n",
    "avg_det = np.mean([r['det'] for r in results])\n",
    "print(f\"\\nAverage cofactor: {avg_cof:.0f}\")\n",
    "print(f\"Average detection: {avg_det:.0f}%\")\n",
    "print(f\"\\nFor CyTOF with p10~1: cofactor = 1*5 = 5 \u2713\")\n",
    "print(f\"For this CODEX with p10~30: cofactor = 30*5 = {30*5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duamx14vwhm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The issue: p10 varies too much between markers (3 to 300)\n",
    "# Solution: use geometric mean of p10 and p50 as a balanced estimate\n",
    "\n",
    "print(\"Testing: COFACTOR = sqrt(p10 * p50) (geometric mean)\")\n",
    "print(\"This balances background level with signal level\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p10 = np.percentile(vals, 10)\n",
    "    p50 = np.median(vals)\n",
    "    \n",
    "    # Geometric mean of background (p10) and typical signal (p50)\n",
    "    cof = np.sqrt(p10 * p50)\n",
    "    cof = max(cof, 5)  # Minimum cofactor of 5\n",
    "    \n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    results.append({'marker': marker, 'p10': p10, 'p50': p50, 'cof': cof, 'det': det_rate})\n",
    "\n",
    "print(f\"{'Marker':<18} {'p10':>8} {'p50':>8} {'Cofactor':>10} {'Det%':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for r in results[:20]:\n",
    "    print(f\"{r['marker']:<18} {r['p10']:>8.1f} {r['p50']:>8.1f} {r['cof']:>10.1f} {r['det']:>7.0f}%\")\n",
    "\n",
    "avg_cof = np.mean([r['cof'] for r in results])\n",
    "avg_det = np.mean([r['det'] for r in results])\n",
    "det_range = (min(r['det'] for r in results), max(r['det'] for r in results))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Average cofactor: {avg_cof:.0f}\")\n",
    "print(f\"Average detection: {avg_det:.0f}%\")\n",
    "print(f\"Detection range: {det_range[0]:.0f}% - {det_range[1]:.0f}%\")\n",
    "\n",
    "print(f\"\\nFormula verification:\")\n",
    "print(f\"  For CyTOF (p10=1, p50=5): cof = sqrt(1*5) = {np.sqrt(1*5):.1f}\")\n",
    "print(f\"  For CODEX (p10=50, p50=200): cof = sqrt(50*200) = {np.sqrt(50*200):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5x4sr0sr3bp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try: COFACTOR = 25th_percentile * 1.5\n",
    "# This should give ~5 for CyTOF and ~150 for CODEX\n",
    "\n",
    "print(\"Testing: COFACTOR = p25 * 1.5\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p25 = np.percentile(vals, 25)\n",
    "    \n",
    "    cof = p25 * 1.5\n",
    "    cof = max(cof, 5)  # Minimum cofactor of 5\n",
    "    \n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    \n",
    "    # Also check what arcsinh value the 5th percentile maps to\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    arcsinh_p5 = np.arcsinh(p5 / cof)\n",
    "    \n",
    "    results.append({'marker': marker, 'p25': p25, 'cof': cof, 'det': det_rate, 'arcsinh_p5': arcsinh_p5})\n",
    "\n",
    "print(f\"{'Marker':<18} {'p25':>8} {'Cofactor':>10} {'as(p5)':>8} {'Det%':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for r in results[:20]:\n",
    "    print(f\"{r['marker']:<18} {r['p25']:>8.1f} {r['cof']:>10.1f} {r['arcsinh_p5']:>8.2f} {r['det']:>7.0f}%\")\n",
    "\n",
    "avg_cof = np.mean([r['cof'] for r in results])\n",
    "avg_det = np.mean([r['det'] for r in results])\n",
    "avg_arcsinh_p5 = np.mean([r['arcsinh_p5'] for r in results])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Average cofactor: {avg_cof:.0f}\")\n",
    "print(f\"Average detection: {avg_det:.0f}%\")\n",
    "print(f\"Average arcsinh(5th pct): {avg_arcsinh_p5:.2f}\")\n",
    "\n",
    "print(f\"\\nFormula verification:\")\n",
    "print(f\"  For CyTOF (p25~3): cof = 3 * 1.5 = {3*1.5}\")\n",
    "print(f\"  For CODEX (p25~90): cof = 90 * 1.5 = {90*1.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg7kg60ggum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final formula: COFACTOR = p25 * 2\n",
    "# This should give:\n",
    "# - CyTOF (p25~2-3): cofactor = 4-6 \u2248 5 \u2713\n",
    "# - CODEX (p25~75): cofactor = 150 \u2713\n",
    "\n",
    "print(\"FINAL FORMULA: COFACTOR = 25th_percentile * 2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "for marker in protein_adata.var_names:\n",
    "    vals = protein_adata[:, marker].X.flatten()\n",
    "    p5 = np.percentile(vals, 5)\n",
    "    p25 = np.percentile(vals, 25)\n",
    "    p50 = np.median(vals)\n",
    "    p95 = np.percentile(vals, 95)\n",
    "    \n",
    "    cof = p25 * 2\n",
    "    cof = max(cof, 5)  # Minimum cofactor of 5\n",
    "    \n",
    "    transformed = np.arcsinh(vals / cof)\n",
    "    det_rate = (transformed > 0.5).mean() * 100\n",
    "    arcsinh_p5 = np.arcsinh(p5 / cof)\n",
    "    \n",
    "    results.append({\n",
    "        'marker': marker, 'p25': p25, 'cof': cof, \n",
    "        'det': det_rate, 'arcsinh_p5': arcsinh_p5\n",
    "    })\n",
    "\n",
    "print(f\"{'Marker':<18} {'p25':>8} {'Cofactor':>10} {'as(p5)':>8} {'Det%':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for r in results[:20]:\n",
    "    print(f\"{r['marker']:<18} {r['p25']:>8.1f} {r['cof']:>10.1f} {r['arcsinh_p5']:>8.2f} {r['det']:>7.0f}%\")\n",
    "\n",
    "avg_cof = np.mean([r['cof'] for r in results])\n",
    "avg_det = np.mean([r['det'] for r in results])\n",
    "avg_arcsinh_p5 = np.mean([r['arcsinh_p5'] for r in results])\n",
    "det_range = (min(r['det'] for r in results), max(r['det'] for r in results))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"SUMMARY:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Average cofactor: {avg_cof:.0f}\")\n",
    "print(f\"  Average detection: {avg_det:.0f}%\")\n",
    "print(f\"  Detection range: {det_range[0]:.0f}% - {det_range[1]:.0f}%\")\n",
    "print(f\"  Average arcsinh(background): {avg_arcsinh_p5:.2f} (below 0.5 threshold \u2713)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FORMULA VERIFICATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  For CyTOF-like data (p25 ~ 2.5):  cofactor = 2.5 * 2 = 5  \u2713\")\n",
    "print(f\"  For this CODEX data (p25 ~ 75):   cofactor = 75 * 2 = 150 \u2713\")\n",
    "print(f\"\\n  Formula: COFACTOR = percentile(marker, 25) * 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kintegrate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}