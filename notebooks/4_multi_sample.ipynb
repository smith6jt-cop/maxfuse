{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Multi-Sample Integration with MaxFuse\n",
    "\n",
    "This notebook demonstrates how to process **multiple samples** through the MaxFuse integration pipeline.\n",
    "\n",
    "## Use Cases\n",
    "- Integrating CODEX data from multiple tissue sections\n",
    "- Processing time-course or condition comparisons\n",
    "- Batch processing for high-throughput studies\n",
    "\n",
    "## Workflow Overview\n",
    "1. Define sample metadata and paths\n",
    "2. Create wrapper functions for preprocessing\n",
    "3. Process each sample through integration\n",
    "4. Combine results across samples\n",
    "5. (Optional) Batch effect correction\n",
    "\n",
    "**Prerequisites**: Ensure preprocessing.ipynb and integration.ipynb patterns are understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport anndata as ad\nfrom scipy.io import mmread\nfrom scipy import sparse\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import from maxfuse package\nfrom maxfuse import Fusor, Mario\nfrom maxfuse.core import model as mf_model\nfrom maxfuse.mario.match import pipelined_mario\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Plot settings\nplt.rcParams['figure.figsize'] = [10, 8]\nplt.rcParams['figure.dpi'] = 100\n\nprint(f\"MaxFuse loaded\")\nprint(f\"Scanpy version: {sc.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Step 1: Define Sample Metadata\n",
    "\n",
    "Create a configuration dictionary for each sample with paths to data files.\n",
    "This allows batch processing with sample-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Define sample configurations\n# Modify paths and parameters for your specific samples\n\nSAMPLES = {\n    'sample_1': {\n        'name': 'Spleen_Section_1',\n        'codex_path': '../data/sample1_cells.tsv',\n        'rna_matrix_path': '../data/sample1_raw_feature_bc_matrix/',\n        'protein_gene_map': '../data/protein_gene_conversion.csv',\n        # QC thresholds (adjust per sample if needed)\n        'min_umi': 500,\n        'max_umi': 25000,\n        'min_genes': 200,\n        'max_mt_pct': 25,\n    },\n    'sample_2': {\n        'name': 'Spleen_Section_2',\n        'codex_path': '../data/sample2_cells.tsv',\n        'rna_matrix_path': '../data/sample2_raw_feature_bc_matrix/',\n        'protein_gene_map': '../data/protein_gene_conversion.csv',\n        'min_umi': 500,\n        'max_umi': 25000,\n        'min_genes': 200,\n        'max_mt_pct': 25,\n    },\n    # Add more samples as needed\n}\n\n# Results directory\nRESULTS_DIR = Path('../results/multi_sample')\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Configured {len(SAMPLES)} samples:\")\nfor sample_id, config in SAMPLES.items():\n    print(f\"  - {sample_id}: {config['name']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Define Preprocessing Functions\n",
    "\n",
    "Wrapper functions encapsulate the preprocessing logic from `preprocessing.ipynb` for reuse across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_codex_data(tsv_path, sample_name=None):\n",
    "    \"\"\"\n",
    "    Load CODEX data from QuPath TSV export.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tsv_path : str\n",
    "        Path to CODEX TSV file\n",
    "    sample_name : str, optional\n",
    "        Name to add to obs for sample tracking\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        Protein expression with spatial coordinates\n",
    "    \"\"\"\n",
    "    print(f\"Loading CODEX data from: {tsv_path}\")\n",
    "    codex_df = pd.read_csv(tsv_path, sep='\\t')\n",
    "    \n",
    "    # Extract marker columns (Cell: *: Mean)\n",
    "    marker_cols = [col for col in codex_df.columns \n",
    "                   if col.startswith('Cell:') and col.endswith(': Mean')]\n",
    "    \n",
    "    # Parse marker names\n",
    "    marker_names = []\n",
    "    for col in marker_cols:\n",
    "        marker = col.split(':')[1].strip().split('(')[0].strip()\n",
    "        marker_names.append(marker)\n",
    "    \n",
    "    # Create expression matrix\n",
    "    protein_matrix = codex_df[marker_cols].values\n",
    "    \n",
    "    # Extract spatial coordinates\n",
    "    x_col = [col for col in codex_df.columns if 'Centroid X' in col][0]\n",
    "    y_col = [col for col in codex_df.columns if 'Centroid Y' in col][0]\n",
    "    x_coords = codex_df[x_col].values\n",
    "    y_coords = codex_df[y_col].values\n",
    "    \n",
    "    # Create AnnData\n",
    "    adata = ad.AnnData(protein_matrix.astype(np.float32))\n",
    "    adata.var_names = marker_names\n",
    "    adata.obs['X_centroid'] = x_coords\n",
    "    adata.obs['Y_centroid'] = y_coords\n",
    "    adata.obs_names = [f\"cell_{i}\" for i in range(adata.n_obs)]\n",
    "    \n",
    "    if sample_name:\n",
    "        adata.obs['sample'] = sample_name\n",
    "    \n",
    "    print(f\"  Loaded {adata.n_obs:,} cells, {adata.n_vars} markers\")\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rna_data(matrix_path, sample_name=None, \n",
    "                  min_counts=500, max_counts=25000, \n",
    "                  min_genes=200, max_mt_pct=25):\n",
    "    \"\"\"\n",
    "    Load and filter raw 10x RNA-seq data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix_path : str\n",
    "        Path to directory containing matrix.mtx.gz, features.tsv.gz, barcodes.tsv.gz\n",
    "    sample_name : str, optional\n",
    "        Name to add to obs for sample tracking\n",
    "    min_counts, max_counts : int\n",
    "        UMI count thresholds\n",
    "    min_genes : int\n",
    "        Minimum genes detected per cell\n",
    "    max_mt_pct : float\n",
    "        Maximum mitochondrial percentage\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        Filtered RNA expression data\n",
    "    \"\"\"\n",
    "    print(f\"Loading RNA data from: {matrix_path}\")\n",
    "    \n",
    "    # Load raw matrix\n",
    "    mtx_path = Path(matrix_path)\n",
    "    rna_mtx = mmread(mtx_path / 'matrix.mtx.gz')\n",
    "    rna_names = pd.read_csv(mtx_path / 'features.tsv.gz', sep='\\t', header=None)[1].to_numpy()\n",
    "    rna_barcodes = pd.read_csv(mtx_path / 'barcodes.tsv.gz', header=None)[0].values\n",
    "    \n",
    "    adata = ad.AnnData(rna_mtx.T.tocsr(), dtype=np.float32)\n",
    "    adata.var_names = rna_names\n",
    "    adata.var_names_make_unique()\n",
    "    adata.obs_names = rna_barcodes\n",
    "    \n",
    "    print(f\"  Raw: {adata.n_obs:,} barcodes\")\n",
    "    \n",
    "    # Calculate QC metrics\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    \n",
    "    # Apply filters\n",
    "    sc.pp.filter_cells(adata, min_counts=min_counts)\n",
    "    sc.pp.filter_cells(adata, min_genes=min_genes)\n",
    "    adata = adata[adata.obs['total_counts'] < max_counts, :].copy()\n",
    "    adata = adata[adata.obs['pct_counts_mt'] < max_mt_pct, :].copy()\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    \n",
    "    if sample_name:\n",
    "        adata.obs['sample'] = sample_name\n",
    "    \n",
    "    print(f\"  Filtered: {adata.n_obs:,} cells, {adata.n_vars:,} genes\")\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_correspondence(protein_adata, rna_adata, mapping_path):\n",
    "    \"\"\"\n",
    "    Build protein-gene correspondence for integration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    protein_adata : AnnData\n",
    "        Protein expression data\n",
    "    rna_adata : AnnData  \n",
    "        RNA expression data\n",
    "    mapping_path : str\n",
    "        Path to protein-gene mapping CSV\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (shared_proteins, shared_genes) - indices of matching features\n",
    "    \"\"\"\n",
    "    mapping_df = pd.read_csv(mapping_path)\n",
    "    \n",
    "    shared_proteins = []\n",
    "    shared_genes = []\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        protein = row['protein']\n",
    "        gene = row['gene']\n",
    "        \n",
    "        if protein in protein_adata.var_names and gene in rna_adata.var_names:\n",
    "            shared_proteins.append(list(protein_adata.var_names).index(protein))\n",
    "            shared_genes.append(list(rna_adata.var_names).index(gene))\n",
    "    \n",
    "    print(f\"  Shared features: {len(shared_proteins)} protein-gene pairs\")\n",
    "    return shared_proteins, shared_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Define Integration Function\n",
    "\n",
    "Wrap the MaxFuse integration pipeline for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_maxfuse_integration(protein_adata, rna_adata, shared_protein_idx, shared_gene_idx,\n",
    "                            n_batches=2, n_neighbors=15, leiden_resolution=0.8,\n",
    "                            n_components=20, verbose=True):\n",
    "    \"\"\"\n",
    "    Run MaxFuse integration pipeline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    protein_adata : AnnData\n",
    "        Protein expression data (CODEX)\n",
    "    rna_adata : AnnData\n",
    "        RNA expression data\n",
    "    shared_protein_idx : list\n",
    "        Indices of shared protein features\n",
    "    shared_gene_idx : list\n",
    "        Indices of shared gene features  \n",
    "    n_batches : int\n",
    "        Number of batches for splitting large datasets\n",
    "    n_neighbors : int\n",
    "        Number of neighbors for graph construction\n",
    "    leiden_resolution : float\n",
    "        Resolution for Leiden clustering\n",
    "    n_components : int\n",
    "        Number of CCA components\n",
    "    verbose : bool\n",
    "        Print progress messages\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Integration results including matching and embeddings\n",
    "    \"\"\"\n",
    "    from maxfuse import utils as mf_utils\n",
    "    \n",
    "    # Normalize data\n",
    "    if verbose:\n",
    "        print(\"Normalizing data...\")\n",
    "    \n",
    "    # RNA: log-normalize\n",
    "    rna_norm = rna_adata.copy()\n",
    "    sc.pp.normalize_total(rna_norm, target_sum=1e4)\n",
    "    sc.pp.log1p(rna_norm)\n",
    "    \n",
    "    # Protein: asinh transform\n",
    "    protein_norm = np.arcsinh(protein_adata.X / 5)\n",
    "    \n",
    "    # Extract shared and active features\n",
    "    rna_shared = rna_norm.X[:, shared_gene_idx]\n",
    "    if sparse.issparse(rna_shared):\n",
    "        rna_shared = rna_shared.toarray()\n",
    "    \n",
    "    protein_shared = protein_norm[:, shared_protein_idx]\n",
    "    \n",
    "    # Active features: highly variable genes\n",
    "    sc.pp.highly_variable_genes(rna_norm, n_top_genes=2000)\n",
    "    hvg_idx = rna_norm.var['highly_variable'].values\n",
    "    rna_active = rna_norm.X[:, hvg_idx]\n",
    "    if sparse.issparse(rna_active):\n",
    "        rna_active = rna_active.toarray()\n",
    "    \n",
    "    protein_active = protein_norm.copy()\n",
    "    \n",
    "    # Initialize Fusor\n",
    "    if verbose:\n",
    "        print(\"Initializing MaxFuse...\")\n",
    "    \n",
    "    fusor = mf_model.Fusor(\n",
    "        shared_arr1=rna_shared,\n",
    "        shared_arr2=protein_shared,\n",
    "        active_arr1=rna_active,\n",
    "        active_arr2=protein_active,\n",
    "    )\n",
    "    \n",
    "    # Split into batches\n",
    "    fusor.split_into_batches(\n",
    "        n_batches1=n_batches,\n",
    "        n_batches2=n_batches\n",
    "    )\n",
    "    \n",
    "    # Construct graphs\n",
    "    if verbose:\n",
    "        print(\"Constructing graphs...\")\n",
    "    fusor.construct_graphs(\n",
    "        n_neighbors1=n_neighbors,\n",
    "        n_neighbors2=n_neighbors,\n",
    "        leiden_resolution1=leiden_resolution,\n",
    "        leiden_resolution2=leiden_resolution\n",
    "    )\n",
    "    \n",
    "    # Find initial pivots\n",
    "    if verbose:\n",
    "        print(\"Finding initial pivots...\")\n",
    "    fusor.find_initial_pivots(\n",
    "        wt_on_active=0.0,\n",
    "        svd_components1=30,\n",
    "        svd_components2=20\n",
    "    )\n",
    "    \n",
    "    # Refine pivots\n",
    "    if verbose:\n",
    "        print(\"Refining pivots...\")\n",
    "    fusor.refine_pivots(\n",
    "        n_iters=3,\n",
    "        cca_components=n_components\n",
    "    )\n",
    "    \n",
    "    # Filter bad matches\n",
    "    fusor.filter_bad_matches(\n",
    "        target='pivot',\n",
    "        filter_prop=0.2\n",
    "    )\n",
    "    \n",
    "    # Propagate to non-pivot cells\n",
    "    if verbose:\n",
    "        print(\"Propagating matches...\")\n",
    "    fusor.propagate(svd_components1=30, svd_components2=20)\n",
    "    \n",
    "    # Get results\n",
    "    matching = fusor.get_matching(target='full_data')\n",
    "    embedding1, embedding2 = fusor.get_embedding(target='full_data', cca_components=n_components)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Integration complete: {len(matching[0]):,} matches\")\n",
    "    \n",
    "    return {\n",
    "        'matching': matching,\n",
    "        'embedding_rna': embedding1,\n",
    "        'embedding_protein': embedding2,\n",
    "        'fusor': fusor\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Process All Samples\n",
    "\n",
    "Loop through samples and run the complete pipeline for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for all sample results\n",
    "all_results = {}\n",
    "all_protein_adata = {}\n",
    "all_rna_adata = {}\n",
    "\n",
    "for sample_id, config in SAMPLES.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {config['name']} ({sample_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if files exist (skip if not)\n",
    "    if not Path(config['codex_path']).exists():\n",
    "        print(f\"  SKIPPED: CODEX file not found at {config['codex_path']}\")\n",
    "        continue\n",
    "    if not Path(config['rna_matrix_path']).exists():\n",
    "        print(f\"  SKIPPED: RNA matrix not found at {config['rna_matrix_path']}\")\n",
    "        continue\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\n[1/4] Loading data...\")\n",
    "    protein_adata = load_codex_data(config['codex_path'], sample_name=config['name'])\n",
    "    rna_adata = load_rna_data(\n",
    "        config['rna_matrix_path'], \n",
    "        sample_name=config['name'],\n",
    "        min_counts=config['min_umi'],\n",
    "        max_counts=config['max_umi'],\n",
    "        min_genes=config['min_genes'],\n",
    "        max_mt_pct=config['max_mt_pct']\n",
    "    )\n",
    "    \n",
    "    # Build correspondence\n",
    "    print(\"\\n[2/4] Building correspondence...\")\n",
    "    shared_protein_idx, shared_gene_idx = build_correspondence(\n",
    "        protein_adata, rna_adata, config['protein_gene_map']\n",
    "    )\n",
    "    \n",
    "    # Run integration\n",
    "    print(\"\\n[3/4] Running MaxFuse integration...\")\n",
    "    results = run_maxfuse_integration(\n",
    "        protein_adata, rna_adata,\n",
    "        shared_protein_idx, shared_gene_idx,\n",
    "        n_batches=2, n_neighbors=15\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\n[4/4] Saving results...\")\n",
    "    sample_dir = RESULTS_DIR / sample_id\n",
    "    sample_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save matching\n",
    "    matching = results['matching']\n",
    "    matching_df = pd.DataFrame({\n",
    "        'rna_idx': matching[0],\n",
    "        'protein_idx': matching[1],\n",
    "        'distance': matching[2]\n",
    "    })\n",
    "    matching_df.to_csv(sample_dir / 'matching.csv', index=False)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(sample_dir / 'embedding_rna.npy', results['embedding_rna'])\n",
    "    np.save(sample_dir / 'embedding_protein.npy', results['embedding_protein'])\n",
    "    \n",
    "    # Store in memory for combined analysis\n",
    "    all_results[sample_id] = results\n",
    "    all_protein_adata[sample_id] = protein_adata\n",
    "    all_rna_adata[sample_id] = rna_adata\n",
    "    \n",
    "    print(f\"  Saved to: {sample_dir}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Completed processing {len(all_results)} samples\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 5: Combine Results Across Samples\n",
    "\n",
    "Merge AnnData objects and embeddings for cross-sample analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine protein data across samples\n",
    "if len(all_protein_adata) > 1:\n",
    "    # Concatenate AnnData objects\n",
    "    protein_combined = ad.concat(\n",
    "        list(all_protein_adata.values()),\n",
    "        join='outer',\n",
    "        label='sample',\n",
    "        keys=list(all_protein_adata.keys())\n",
    "    )\n",
    "    \n",
    "    print(f\"Combined protein data: {protein_combined.shape}\")\n",
    "    print(f\"Samples: {protein_combined.obs['sample'].value_counts().to_dict()}\")\n",
    "elif len(all_protein_adata) == 1:\n",
    "    protein_combined = list(all_protein_adata.values())[0]\n",
    "    print(f\"Single sample: {protein_combined.shape}\")\n",
    "else:\n",
    "    print(\"No samples processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine RNA data across samples\n",
    "if len(all_rna_adata) > 1:\n",
    "    rna_combined = ad.concat(\n",
    "        list(all_rna_adata.values()),\n",
    "        join='outer',\n",
    "        label='sample',\n",
    "        keys=list(all_rna_adata.keys())\n",
    "    )\n",
    "    \n",
    "    print(f\"Combined RNA data: {rna_combined.shape}\")\n",
    "    print(f\"Samples: {rna_combined.obs['sample'].value_counts().to_dict()}\")\n",
    "elif len(all_rna_adata) == 1:\n",
    "    rna_combined = list(all_rna_adata.values())[0]\n",
    "    print(f\"Single sample: {rna_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embeddings with sample offset tracking\n",
    "if len(all_results) > 0:\n",
    "    embeddings_list = []\n",
    "    sample_labels = []\n",
    "    \n",
    "    for sample_id, results in all_results.items():\n",
    "        emb = results['embedding_protein']\n",
    "        embeddings_list.append(emb)\n",
    "        sample_labels.extend([sample_id] * len(emb))\n",
    "    \n",
    "    combined_embedding = np.vstack(embeddings_list)\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    print(f\"Combined embedding shape: {combined_embedding.shape}\")\n",
    "    print(f\"Sample distribution: {pd.Series(sample_labels).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 6: Cross-Sample Visualization\n",
    "\n",
    "Visualize combined results to assess batch effects and integration quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute UMAP on combined embedding\n",
    "if len(all_results) > 0 and combined_embedding.shape[0] > 100:\n",
    "    from sklearn.decomposition import PCA\n",
    "    import umap\n",
    "    \n",
    "    # Subsample if too large\n",
    "    max_cells = 50000\n",
    "    if combined_embedding.shape[0] > max_cells:\n",
    "        idx = np.random.choice(combined_embedding.shape[0], max_cells, replace=False)\n",
    "        emb_sub = combined_embedding[idx]\n",
    "        labels_sub = sample_labels[idx]\n",
    "    else:\n",
    "        emb_sub = combined_embedding\n",
    "        labels_sub = sample_labels\n",
    "    \n",
    "    # UMAP\n",
    "    print(\"Computing UMAP...\")\n",
    "    reducer = umap.UMAP(n_neighbors=30, min_dist=0.3, random_state=42)\n",
    "    umap_coords = reducer.fit_transform(emb_sub)\n",
    "    \n",
    "    # Plot by sample\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    unique_samples = np.unique(labels_sub)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_samples)))\n",
    "    \n",
    "    for i, sample in enumerate(unique_samples):\n",
    "        mask = labels_sub == sample\n",
    "        ax.scatter(umap_coords[mask, 0], umap_coords[mask, 1], \n",
    "                   c=[colors[i]], s=1, alpha=0.5, label=sample)\n",
    "    \n",
    "    ax.set_xlabel('UMAP1')\n",
    "    ax.set_ylabel('UMAP2')\n",
    "    ax.set_title('Combined Embedding - Colored by Sample')\n",
    "    ax.legend(markerscale=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'combined_umap_by_sample.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Saved: combined_umap_by_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 7: (Optional) Batch Effect Correction\n",
    "\n",
    "If samples show strong batch effects, apply correction using Harmony or similar methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Harmony batch correction\n",
    "# Uncomment if batch effects are observed in the UMAP above\n",
    "\n",
    "# try:\n",
    "#     import harmonypy as hm\n",
    "#     \n",
    "#     print(\"Running Harmony batch correction...\")\n",
    "#     harmony_out = hm.run_harmony(\n",
    "#         combined_embedding, \n",
    "#         pd.DataFrame({'sample': sample_labels}), \n",
    "#         'sample'\n",
    "#     )\n",
    "#     combined_embedding_corrected = harmony_out.Z_corr.T\n",
    "#     \n",
    "#     # Recompute UMAP with corrected embedding\n",
    "#     print(\"Computing UMAP on corrected embedding...\")\n",
    "#     umap_corrected = reducer.fit_transform(combined_embedding_corrected)\n",
    "#     \n",
    "#     # Plot comparison\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#     \n",
    "#     for ax, coords, title in zip(\n",
    "#         axes, \n",
    "#         [umap_coords, umap_corrected],\n",
    "#         ['Before Harmony', 'After Harmony']\n",
    "#     ):\n",
    "#         for i, sample in enumerate(unique_samples):\n",
    "#             mask = labels_sub == sample\n",
    "#             ax.scatter(coords[mask, 0], coords[mask, 1], \n",
    "#                        c=[colors[i]], s=1, alpha=0.5, label=sample)\n",
    "#         ax.set_title(title)\n",
    "#         ax.legend(markerscale=10)\n",
    "#     \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(RESULTS_DIR / 'harmony_comparison.png', dpi=150)\n",
    "#     plt.show()\n",
    "#     \n",
    "# except ImportError:\n",
    "#     print(\"harmonypy not installed. Install with: pip install harmonypy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 8: Summary Statistics\n",
    "\n",
    "Generate summary table of all processed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "\n",
    "for sample_id in all_results.keys():\n",
    "    protein_adata = all_protein_adata[sample_id]\n",
    "    rna_adata = all_rna_adata[sample_id]\n",
    "    results = all_results[sample_id]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Sample': sample_id,\n",
    "        'CODEX Cells': protein_adata.n_obs,\n",
    "        'RNA Cells': rna_adata.n_obs,\n",
    "        'Protein Markers': protein_adata.n_vars,\n",
    "        'RNA Genes': rna_adata.n_vars,\n",
    "        'Matches': len(results['matching'][0]),\n",
    "        'Match Rate': f\"{100*len(results['matching'][0])/min(protein_adata.n_obs, rna_adata.n_obs):.1f}%\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nMulti-Sample Integration Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(RESULTS_DIR / 'summary.csv', index=False)\n",
    "print(f\"\\nSaved summary to: {RESULTS_DIR / 'summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After multi-sample integration:\n",
    "1. **Cell type annotation**: Transfer labels using the combined embedding\n",
    "2. **Differential analysis**: Compare cell type proportions across samples\n",
    "3. **Spatial analysis**: Use region-aware matching (see analysis.ipynb)\n",
    "4. **Export for visualization**: Save combined results for external tools\n",
    "\n",
    "See `visualization.ipynb` and `analysis.ipynb` for downstream analysis workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}